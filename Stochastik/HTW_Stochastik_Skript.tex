\newcommand{\customDir}{../}
\input{\customDir _LaTeX_master/LaTeX_master_setup.sty}

%\setboolean{twosided}{true}
%\setCustomDocumentClass{scrartcl}
%\setCustomDesign{htw}
%\setCustomSlidePath{Folien}

\setCustomTitle{Stochastik}
\setCustomSubtitle{Vorlesungsskript}
\setCustomAuthor{Falk-Jonatan Strube}
%\setCustomNoteA{TitlepageNoteBeforeAuthor}
\setCustomNoteB{Vorlesung von Prof. Dr. Schwarzenberger}

%\setcustomSignature{\footnotesize{\textcolor{darkgray}{Mitschrift von\\ \customAuthor}}	% Formatierung der Signatur in der Fußzeile
%\setcustomTitleAuthor{\textcolor{darkgray}{Mitschrift von #1}}	% Formatierung des Autors auf dem Titelblatt

\input{\customDir _LaTeX_master/LaTeX_master.sty}
\input{\customDir _LaTeX_master/LaTeX_master_macros.sty}

\setlist[enumerate,1]{label=(\arabic*)}
\renewenvironment{anumerate}{\begin{enumerate}[label=(\alph*)]}{\end{enumerate}} % Alphabetische Aufzählung


%\bibliography{\customDir _Literatur/HTW_Literatur.bib}
\begin{document}

%\selectlanguage{english}
\maketitle
\newpage
\tableofcontents
\newpage

\chapter*{Vorbemerkung}
Lernraum: Dienstag 17:00 S327, S329

\chapter*{Stochastik}

\section*{Was ist Stochastik}
Stochastik…
\begin{itemize}
\item … kommt etymologisch aus dem Griechischem; Bedeutung: „Kunst des Vermutens“
\item … beschäftigt sich mit der Beschreibung und dem Untersuchen von zufälligen Ereignissen (z.B. Lotto, Wurf eines Würfels, Lebensdauer einer Glühbirne, …)
\item … beinhaltet die Teilgebiete
\begin{itemize}
\item Wahrscheinlichkeitsrechnung:\\
Zu Grunde liegende Gesetzmäßigkeit des Zufalls bekannt. Frage nach Wahrscheinlichkeiten „interessanter“ Ereignisse

Bsp. Würfel: Jede Seite fällt mit Wahrscheinlichkeit $\frac{1}{6}$. \\
Wie groß ist die Wahrscheinlichkeit, dass unter $10$ Würfen mindestens $4$ mal 6 kommt? 
\item Statistik:\\
Zur Grunde liegende Gesetzmäßigkeit des Zufalls ist unbekannt. Idee: Nutze Stichproben/Daten um diese Gesetzmäßigkeiten zu erkennen.

Bsp.: Gesamtproduktion $100\,000$ Teile, Stichprobe von $100$ Teilen enthält $2$ defekte. \\
Kann davon ausgegangen werden, dass die Fehlerquote von $1\%$ nicht eingehalten wird?
\end{itemize}
\end{itemize}

\chapter{Wahrscheinlichkeitsrechnung}
\section{Zufallsexperimente, Ereignisse und Wahrscheinlichkeiten}
\subsection{Zufallsexperimente und Ereignisse}
Erster wichtiger Begriff:
\cparagraph{Definition}
Ein \emph{Zufallsexperiment} ist ein Vorgang
\begin{itemize}
\item der beliebig oft unter gleichartigen Bedingungen wiederholt werden kann und
\item dessen Ergebnis nicht mit Sicherheit vorhergesagt werden kann
\end{itemize}
$\Omega:=$ Ergebnismenge (oder Ergebnisraum) ist die Menge aller möglichen Ergebnisse

\cparagraph{Bemerkung} Drei wichtige Fälle
\begin{itemize}
\item $\Omega$ endlich, d.h. $\Omega=\{\omega_1,\omega_2,\dots,\omega_n\}$
\item $\Omega$ abzählbar unendlich, d.h. $\Omega=\{\omega_1,\omega_2,\dots\}$ (Ereignisse lassen sich mit den natürlichen Zahlen aufzählen)\footnote{zu natürlichen Zahlen (in dieser VL): $\NN=\{1,2,3,\dots\}, \; \NN_0=\{0,1,2,3,\dots\}$}
\item $\Omega$ überabzählbar unendlich, d.h. $\Omega=\RR$ oder $\Omega [0,1)$
\end{itemize}

\cparagraph{Beispiel} 
\begin{itemize}
\item Würfel: $\Omega=\{1,2,3,4,5,6\}$
\item Anzahl der defekten Glühbirnen in einer Stichprobe von 100 Stück: $\Omega=\{0,1,2,\dots,100\}$
\item Anzahl der Anrufe im Call-Center zwischen 8:00 und 9:00
\begin{enumerate}
\item Möglichkeit 1: $\Omega = \{0,1,2,\dots\}=\NN_0$
\item Möglichkeit 2: $\Omega = \{\omega_1,\omega_2,\dots, \omega_{100}\}$ mit $w_i =\begin{cases}
i \text{ Anrufe, falls }i\leq 99\\
100 \text{ oder mehr Anrufe, falls }i=100
\end{cases}$
\end{enumerate}
\item Downloadzeit einer Datei: $\Omega = (0,\infty)$
\end{itemize}
Wir interessieren uns oft nicht allein für das Eintreten von einem $w\in \Omega$, sondern dafür ob ein $w$ aus einer gewissen Teilmenge aus $\Omega$ eingetreten ist (z.B. sind weniger als $3$ Glühbirnen defekt). Daher:
\cparagraph{Definition} Ein \emph{zufälliges Ereignis} $A$ ist eine Teilmenge des Ergebnisraums $\Omega$. 

Spezielle Ereignisse:
\begin{itemize}
\item $A = \emptyset$ \tab … das unmögliche Ereignis ($\omega\in \emptyset$ tritt nie ein)
\item $A=\Omega$ \tab … das sichere Ereignis ($\omega \in \Omega$ tritt immer ein)
\item $A=\{\omega\}$ \tab … Elementarereignis (für ein $\omega \in \Omega$)
\item $\bar A = \Omega \setminus A$ \tab … Gegenereignis zu $A$
\end{itemize}
Sprechweise: „Das Ereignis $A$ tritt ein“, falls ein $\omega \in A$ beobachtet wird.

\cparagraph{Beispiel} (Würfel)\\
$A=\{\text{„gerade Zahl fällt“}\}$\\
$\Rightarrow A=\{2,4,6\} \subseteq \Omega = \{1,\dots,6\}$\\
Gegenereignis: $\bar A = \{1,3,5\}$

\cparagraph{Bemerkung} Da Ereignisse Teilmengen von $\Omega$ sind, lassen sich alle Rechenoperationen für Mengen anwenden. Seien $A,B \subseteq \Omega$.
\begin{itemize}
\item $A \subseteq B$ … $A$ ist Teilereignis von $B$
\item $A=B$, gleiche Ereignisse
\item Durchschnitt: $A \cap B$, „$A$ und $B$“ (beide Ereignisse treten gleichzeitig ein)
\item Vereinigung: $A \cup B$, „$A$ oder $B$“ (entweder $A$ oder $B$ treten ein)
\item Differenz: $A \setminus B$, „$A$ ohne $B$“ ($A$ tritt ein, $B$ aber nicht)
\item Negation/Gegenereignis: $\bar A = \Omega\setminus A$ ($A$ tritt nicht ein)
\item gilt $A \cap B = \emptyset$, so heißen $A$ und $B$ \emph{unvereinbar/disjunkt}.
\end{itemize}

\cparagraph{Beispiel} (Würfel)\\
$\Omega = \{1,\dots,6\}$,\\
$A=\{2,4,6\},\; B=\{2,3,5\},\; C =\{1,3\}$\\
Bestimme: $A \cup B$, $A \cap B$, $A \cap C$, $C \cup \bar C$\\
$A \cup B = \{2,3,4,5,6\}$\\
$A \cap B = \{2\}$\\
$A \cap C = \emptyset$\\
$C \cup \bar C = \Omega$

\cparagraph{Satz} (Rechenregeln) Es seien $A$, $B$ und $C$ Ereignisse. Dann gilt:
\begin{itemize}
\item $A \cap B = B \cap A \quad A \cup B = B \cup A$ \tab(Kommutativgesetz)
\item $A \cap (B \cap C)=(A \cap B) \cap C$\\
$A \cup (B \cup C) = (A \cup B ) \cup C$ \tab\tab (Assoziativgesetze)
\item $A \cap (B \cup C) = (A \cap B) \cup (A \cap C)$\\
$A \cup(B \cap C) = (A \cup B) \cap (A \cup C)$ \tab (Distributivgesetze)
\item $\overline{A\cap B} = \bar A \cup \bar B$\\
$\overline{A \cup B} = \bar A \cap \bar B$ \tab\tab (De Morgansche Regeln)
\item aus $A \subseteq B$ folgt $\bar B \subseteq \bar A$ und $A\setminus B=A \cap \bar B$
\end{itemize}

\cparagraph{Definition} Sei $\Omega$ eine Menge. Ein Mengensystem $\cA\subseteq \cP(\Omega)$ heißt $\sigma$-Algebra, falls gilt
\begin{itemize}
\item $\Omega \in \cA$
\item $A \in \cA \Rightarrow \bar A \in \cA$
\item $A_1, A_2, A_3, \dots \in \cA \Rightarrow \bigcap_{i=1}^\infty A_i \in \cA$
\end{itemize}
(Sprich: die Menge, alle Komplemente und die Schnitte und Vereinigungen aller Teilmengen müssen in $\cA$ liegen [Mächtigkeit der $\sigma$-Algebra ist bei einer endlichen Grundmenge immer eine 2er-Potenz!])

\cparagraph{Bemerkung} Sei $\cA$ eine $\sigma$-Algebra auf $\Omega$. Dann gilt:
\begin{itemize}
\item $\emptyset \in \cA$
\item $A, B \in \cA \Rightarrow A \setminus B \in \cA$
\item $A_1, A_2,A_3,\dots \in \cA \Rightarrow \bigcup_{i=1}^\infty A_i \in \cA$
\end{itemize}

\cparagraph{Beispiel} (Würfel)
\begin{itemize}
\item $\cA=\{\{1\},\{2\},\emptyset, \{1,2\}, \{3,4,5,6\}, \{2,3,4,5,6\}, \{1,3,4,5,6\}, \underset{=\Omega}{\{1,2,3,4,5,6\} }\}$ ist eine $\sigma$-Algebra über $\Omega=\{1,\dots,6\}$
\item $\cA=\{A \;|\; A \subseteq \Omega\} = \cP(\Omega)$ ist auch ein $\sigma$-Algebra
\end{itemize}

\cparagraph{Bemerkung} Besteht $\Omega$ aus $n$ Elementen, so enthält $\cP(\Omega)$ genau $2^n$ Elemente.

\subsection{Definition der Wahrscheinlichkeit}

Ziel: Ordne zufälligem Ereignis $A$ eine Wahrscheinlichkeit $\PP(A)$ zu, die die Chance beurteilt, dass $A$ eintritt.

\cparagraph{Definition} (Kolmogorov 1933)\\
Gegeben sei eine Ereignismenge $\Omega$ und eine $\sigma$-Algebra $\cA$. Eine Funktion $\PP : \cA \to [0,1]$ heißt \emph{Wahrscheinlichkeitsmaß auf $(\Omega,\cA)$}, falls
\begin{enumerate}
\item $\PP (\Omega) =1$
\item für paarweise disjunkte $A_i \in \cA, \; i=1,2,\dots$ (d.h. $A_i \cap A_J = \emptyset$ falls $i \not = j$) gilt $\PP(A_1 \cup A_2 \cup \dots ) = \PP(A_1)+\PP(A_2)+\dots$.
\end{enumerate}
Weitere Bezeichnungen:
\begin{itemize}
\item $\PP(A)$ … Wahrscheinlichkeit des Ereignisses $A$
\item $(\Omega,\cA, \PP)$ … Wahrscheinlichkeitsraum / Wahrscheinlichkeitsmodell
\end{itemize}

\cparagraph{Bemerkung} (Allgemeines Vorgehen, Vereinfacht Darstellung)
\begin{enumerate}
\item Theoretische Untersuchungen (Kombinatorik, physikalische Gesetze); Beobachtung der relativen Häufigkeit (deskriptive Statistik)
\item Schritt (1) liefert für gewisse Grundereignisse die Wahrscheinlichkeiten (exakt oder zumindest näherungsweise)
\item Bestimmen der Wahrscheinlichkeiten für alle interessierenden Ereignisse (mittels Rechenregeln, siehe später)
\end{enumerate}

\cparagraph{Satz} Seien $A,B,C$ sowie $A_1, A_2, \dots ,A_n$ zufällige Ereignisse. Dann gilt:
\begin{anumerate}
\item $\PP(\emptyset)=0$
\item $\PP(\bar A) = 1 - \PP (A)$
\item $A \subseteq B \Rightarrow \PP(A) \subseteq \PP (B)$
\item $\PP(A \cup B)=\PP(A)+\PP(B)-\PP(A \cap B)$\\
$\PP ( A \cup B \cup C) = \PP(A) + \PP(B) + \PP(C)-\PP(A \cap B) - \PP(A\cap C) - \PP(B\cap C ) + \PP(A \cap B \cap C)$\\
(Gut zu veranschaulichen durch Venn-Diagramme)
\end{anumerate}
Es gilt sogar der Additionssatz:
\cparagraph{Satz} Seien $A_1, \dots, A_n$ zufällige Ereignisse. Dann gilt: \\
$\PP(A_1 \cup \dots \cup A_n)=\sum_{i=1}^n \PP(A_i)-\sum_{i<j} \PP(A_i \cap A_j) + \sum_{i<j<k}\PP(A_i \cap A_j \cap A_k) - \dots + (-1)^{n+1} \PP(A_1\cap A_1 \cap \dots \cap A_n)$

\subsection{Laplacesches Modell}
Nun wollen wir ein spezielles, einfaches, aber oft sehr nützliches WK-Maß einführen.
\cparagraph{Definition} Ein WK-Modell $(\Omega, \cA, \PP)$ heißt \emph{Laplacesches Modell}, falls $\Omega = \{\omega_1, \omega_2, \dots , \omega_n\}$ endlich ist, $\cA = \cP ( \Omega)$ und $\PP(\{\omega_1\})=P(\{\omega_2\})=\dots = \PP(\{\omega_n\})=\frac{1}{n}$ gilt.

\cparagraph{Bemerkung} für beliebiges $A \in \cA$ gilt im Laplaceschen Modell:\\
$\PP(A) = \frac{|A|}{|\Omega|}=\frac{m}{n}$, wobei $m=|A|$ die Anzahl der Elemente in $A$ ist (und $|\Omega|=n$).\\
Also $\PP(A)=\frac{\text{Anzahl der günstigen Elementarereignisse}}{\text{Anzahl der möglichen Elementarereignisse}}$.\\
Man sagt auch: $\PP$ ist dann die diskrete Gleichverteilung auf $\Omega$.

\cparagraph{Beispiel}
\begin{anumerate}
\item (fairer Würfel) Wie groß ist die WK eine Zahl größer $4$ zu würfeln?\\
$\Omega = \{1,2,3,4,5,6\}$, $A=\{5,6\}$ und es gilt $\PP(\{1\})=\PP(\{2\})=\dots=\PP(\{6\})=\frac{1}{6}$\\
Daher: $\PP(A) = \frac{|A|}{|\Omega|}=\frac{2}{6}=\frac{1}{3}$
\item (2 faire Würfel) Wie groß ist die WK mit 2 Würfeln mindestens eine 11 zu würfeln?
\begin{align*}
\Omega=\{ & (1,1), (1,2), \dots , (1,6)\\
&\vdots\\
&(6,1), (6,2), \dots , (6,6)\}
\end{align*}
$A=\{(6,5), (5,6), (6,6)\}$ und es gilt $\PP(\{(i,j)\})=\frac{1}{36}$ für beliebiges $i,j \in \{1,\dots,6\}$. Also liegt Laplace Modell vor.\\
Daher gilt: $\PP(A) = \frac{3}{36}= \frac{1}{12}$.
\end{anumerate}
Um in Laplace-Modellen die Größe (Mächtigkeit) von Ereignissen zu bestimmen, sind oft spezielle „Abzähltricks“ sinnvoll. Diese liefert die Kombinatorik.

\subsection{Kombinatorik}
Fragestellung: Wie viele Möglichkeiten gibt es aus einer $n$-elementigen Menge $k$ Elemente auszuwählen? Dabei sind die Spielregeln zu klären:
\begin{itemize}
\item Spielt die Reihenfolge eine Rolle?
\item Dürfen Elemente mehrfach ausgewählt werden (mit Zurücklegen oder ohne)?
\end{itemize}

\cparagraph{Satz} In einer Urne befinden sich $n$ (voneinander unterscheidbare) Elemente. Wir ziehen $k$ davon…
\begin{anumerate}
\item … mit Zurücklegen, unter Berücksichtigung der Reihenfolge, dann gibt es
\[\bar v_n^k = n^k\]
viele Möglichkeiten (Variation von $n$ Elementen zur $k$-ten Klasse mit Wiederholungen).
\item … ohne Zurücklegen, unter Berücksichtigung der Reihenfolge, dann gibt es
\[v_n^k=n\cdot (n-1) \cdot (n-2) \cdot \dots \cdot (n-(k-1))=\frac{n!}{(n-k)!}\]
viele Möglichkeiten (Variation von $n$ Elementen zur $k$-ten Klasse ohne Wiederholungen).
\item … mit Zurücklegen, ohne Berücksichtigung der Reihenfolge, dann gibt es
\[\bar c_n^k=\binom{n+k-1}{k}=\frac{(n+k-1)!}{k!(n-1)!}\]
viele Möglichkeiten (Kombination von $n$ Elementen zur $k$-ten Klasse mit Wiederholungen).
\item … ohne Zurücklegen, ohne Berücksichtigung der Reihenfolge, dann gibt es
\[c_n^k=\binom{n}{k}=\frac{n!}{k!(n-k)!}\]
viele Möglichkeiten (Kombination von $n$ Elementen zur $k$-ten Klasse ohne Wiederholungen).
\end{anumerate}

\cparagraph{Bemerkungen}
\begin{itemize}
\item $n!=n\cdot (n-1) \cdot \dots \cdot 2\cdot 1$ mit $0!=1$
\item Spezialfall in (b): $n=k$, dann $v_n^k=n!$. Dies beschreibt die Anzahl der möglichen Anordnungen von $n$ Elementen (Permutationen).
\item Spezialfälle in (d): 
\begin{itemize}
\item $n=k$, dann $c_n^k=1=\binom{n}{n}$
\item $k=0$, dann $c_n^0=\binom{n}{0}=1$
\item $k=1$, dann $c_n^1=\binom{n}{1}=n$
\end{itemize}
\end{itemize}

\cparagraph{Beispiel}
\begin{anumerate}
\item Wie viele mögliche Zieleinläufe gibt es beim 100m-Lauf mit 8 Teilnehmern?\\
$8!=40320$
\item Wie viele Möglichkeiten gibt es beim Lotto (6 aus 49)\\
$\binom{49}{6}=13\;983\;816$
\item Wie viele Möglichkeiten gibt es ein Nummernschild der Art „DD-Buchstabe Buchstabe Ziffer Ziffer Ziffer“ zu konstruieren?\\
$26^2\cdot 10^3=676 \; 000$
\item Wie viele Möglichkeiten gibt es 5 (nicht unterscheidbare) Äpfel auf 3 Kinder aufzuteilen?\\
$\binom{3+5-1}{5}=\binom{7}{1}=21$
\end{anumerate}

\subsection{Bedingte Wahrscheinlichkeit}
Frage: Wie verändert sich die Wahrscheinlichkeit eines Ereignisses, falls ich Zusatzwissen mit einfließen lasse? 

\cparagraph{Beispiel} HIV Prävalenz liegt weltweit bei $0,8\%$, also:\\
$\PP_1 (\{\text{zufällig ausgewählte Person ist HIV-positiv\}})=0,008$\\
Modell 1: $\Omega =\{0,1\},\; \PP_1 ( \{1\}) = 0,008, \; \PP_1(\{0\})=0,992$\\
Zusatzwissen: ausgewählte Person ist Europäer und Prävalenz in Europa: $=0,2\%$, also:\\
$\PP_2 (\{\text{zufällig ausgewählte Person ist HIV-positiv\}})=0,002$\\
Modell 2: $\Omega = \{0,1\}, \; \PP_2(\{1\})=0,002=1-\PP(\{0\})$\\
Problem/Frage:
\begin{itemize}
\item Wie kombiniert man beide Modelle?
\item Wir wollen nicht mit 2 verschiedenen $\PP$s rechnen.
\item WK für HIV positiv unter Nicht-Europäern?
\end{itemize}

\cparagraph{Beispiel}
\begin{itemize}
\item Von insgesamt $800$ Schülern besitzen $440$ ein Smartphone.
\item Unter den Smartphone-Besitzern sind $60\%$ männlich.
\item Unter den Nicht-Smartphone-Besitzern sind $35\%$ männlich.
\item Unter allen $800$ Schülern wird ein Smartphone verlost.
\end{itemize}
Fragen:
\begin{anumerate}
\item Wie groß ist die Wahrscheinlichkeit, dass der Gewinner bereits ein Smartphone besitzt?
\item Wie groß ist die WK, dass der Gewinner bereits ein Smartphone besitzt, wenn man schon weiß, dass ein Mädchen gewonnen hat?
\end{anumerate}

\cparagraph{Definition} Sei $(\Omega, \cA, \PP)$ ein Wk-Raum und seien $A, B \subset \Omega$ Ereignisse mit $\PP(B)>0$. Dann definieren wir $$\PP(A|B):=\frac{\PP(A \cap B)}{\PP(B)}$$ und nennen $\PP (A|B)$ die Wahrscheinlichkeit von $A$ bedingt auf $B$.\\
Interpretation: „Wie groß ist die Wk,von $A$, wenn ich schon weiß, dass $B$ eingetreten ist?“

\cparagraph{Beispiel} (Smartphone, s.o.)\\
$\Omega = \{ (S,M), (\bar S, M), (S, W), (\bar S, W)\}$\\
$S$ … Gewinnende Person besitzt Smartphone\\
$\bar S$ … Gewinnende Person besitzt kein Smartphone\\
$M$ … Gewinnende Person ist männlich\\
$W$ … Gewinnende Person ist weiblich\\
\begin{tikzpicture}[scale=2]
\node (v1) at (5,1) {$M/W$ / $S/\bar S$};
\node (v2) at (3.5,0) {$S$};
\node (v3) at (6.5,0) {$\bar S$};
\node (v4) at (3,-1) {$M$};
\node (v5) at (4,-1) {$W$};
\node (v6) at (6,-1) {$M$};
\node (v7) at (7,-1) {$W$};
\node at (v4) [below = 1em, align=center]{$0,33$\\$(=0,55\cdot0,6)$};
\node at (v5) [below = 1em]{$0,22$};
\node at (v6) [below = 1em]{$0,1575$};
\node at (v7) [below = 1em]{$0,2925$};
\draw (v1) -- node[left, pos =.5]{$0,55\left(=\frac{440}{800}\right)$} (v2);
\draw (v1) -- node[right, pos =.5]{$0,45$}(v3);
\draw (v2) -- node[left, pos =.5]{$0,6$}(v4);
\draw (v2) -- node[right, pos =.5]{$0,4$}(v5);
\draw (v3) -- node[left, pos =.5]{$0,35$}(v6);
\draw (v3) -- node[right, pos =.5]{$0,65$}(v7);
\end{tikzpicture}% ABB S1
\\
gegeben: \\
$\PP(\{(S,M)\})=0,33$\\
$\PP(\{(S,W)\})=0,22$\\
$\PP(\{ (\bar S, M )\})=0,1575$\\
$\PP(\{ (\bar S, W )\})=0,2925$\\
Antwort auf Fragen:
\begin{anumerate}
\item $0,55$ (klar)
\item Intuition: Wir wissen, dass nur noch die Stränge mit „W“ interessieren. Die Stränge ohne „W“ sollten wir „streichen“. Wie groß ist die WK der Kombination (S,W) im Vergleich zu allen, wo W vorkommt? Also:$$\frac{\PP(\{(S,W)\})}{\PP(\{(S,W),(\bar S,W)\})}=\frac{0,22}{0,22+0,2925}=0,4293$$
Was hat das mit der bedingten WK aus Def. 1.1.25 zu tun? \\
$A:=\{\text{Person besitzt Smartphone}\}=\{(S,M),(S,W)\}$\\
$B:=\{\text{Person ist weiblich}\} = \{(S,W), (\bar S ,W)\}$ \\
$\PP(A|B)=\frac{\PP(\{(S,W)\})}{\PP(\{(S,W), (\bar S, W)\})}=\dots =0,4293$
\end{anumerate}

\cparagraph{Satz} (Rechnen mit bedingten WK)\\
Sei $(\Omega, \cA, \PP)$ ein WK-Raum und $A, A_1, A_2, B \in \cA$ Ereignisse mit $\PP(B)>0$. Dann gilt:
\begin{itemize}
\item $\PP(B|B)=1$, $\PP(\emptyset|B)=0$
\item Falls $A$ und $B$ disjunkt, gilt $\PP(A|B)=0$
\item $\PP(\bar A | B) = 1-\PP(A|B)$
\item $\PP(A_1 \cup A_2 | B ) =\PP(A_1 | B ) + \PP (A_2|B) - \PP (A_1 \cap A_2 | B)$
\item Falls $B\subseteq A$, so gilt $\PP(A|B)=1$
\item Falls $A \subseteq B$, so gilt $\PP(A|B)=\PP(A)$
\end{itemize}

\cparagraph{Beispiel} Auf einer E-Mail Adresse kommen im Schnitt $80\%$ Spam-Mails und $20\%$ gute Mails.\\
Eine „gute“ Mail enthalte mit $2\%$ WK das Wort „Viagra“. In einer Spam-Mail liegt dieser Anteil bei $60\%$. Berechnen Sie die WK, dass eine Spam-Mail vorliegt, falls man weiß, dass das Wort „Viagra“ enthalten ist.\\
Lösung:\\
$A=\{\text{Mail enthält „Viagra“}\}$\\
$\bar A=\{\text{Mail enthält kein „Viagra“}\}$\\
$B=\{\text{Mail ist Spam}\}$\\
$\bar B=\{\text{Mail ist kein Spam}\}$\\
4-Felder-Tafel:\\
\begin{tabular}{l | c | c | l}
& $B$: Spam & $\bar B$ kein Spam & \\
\hline
$A$, mit Viagra & $0,8\cdot 0,6=0,48$ & $0,2 \cdot 0,002=0,004$ & $0,484$\\
$\bar A$, ohne Viagra & $0,32$ & $0,196$ & $0,516$\\
\hline 
& $0,8$ & $0,2$ & $1$
\end{tabular}\\
Gesucht ist $\PP(B|A)=\frac{\PP(B\cup A)}{\PP(A)}=\frac{0,48}{0,484}=0,9917$
Auch interessant ist die WK, dass die Mail kein Spam ist, wenn man schon weiß, dass „Viagra“ nicht enthalten ist. $\PP(\bar B | \bar A)=\frac{0,196}{0,516}=0,3798$

\cparagraph{Satz} (Multiplikationssatz)\\
Seien $A$ und $B$ Ereignisse mit $\PP(A)>0,\; \PP(B)>0$. Dann gilt:
$$\PP(A\cup B ) = \PP(A ) \cdot \PP(B|A) = \PP(B) \cdot \PP(A|B)$$
Sind $A_1,\dots,A_n$ Ereignisse mit $\PP\left( \bigcap_{i=1}^{n-1} A_i\right) >0$, dann gilt sogar:
$$\PP(A_1\cap A_2 \cap \dots \cap A_n)=\PP(A_1)\cdot \PP(A_2|A_1) \cdot \PP (A_3|A_1 \cap A_2)\cdot \dots \cdot \PP(A_n|A_1 \cap \dots \cap A_{n-1})$$

\cparagraph{Beispiel} In einer Los-Trommel befinden sich $20$ Lose. Jemand zieht $3$ nacheinander. Es gibt insgesamt $5$ Gewinnlose. Wie groß ist die WK, dass alle $3$ gezogenen Lose Gewinnlose sind?\\
$A_k=\{\text{Gewinn beim $k$-ten Los}\}, \; k=1,2,3$\\
Gesucht: $\PP(A_1\cap A_2 \cap A_3)$\\
Satz 1.1.29 liefert: \\
$\PP(A_1 \cap A_2 \cap A_3)=\PP(A_1) \cdot \PP(A_2 | A_1) \cdot \PP(A_3 | A_1 \cap A_2)$\\
$\PP(A_1) = \frac{5}{20}= \frac{1}{4}$ (5 Günstige in 20 Losen)\\
$\PP(A_2 | A_1) = \frac{4}{19}$\\
$\PP(A_3 | A_1 \cap A_2) = \frac{3}{18}$\\
$\Rightarrow \PP(A_1 \cap A_2 \cap A_3)=\frac{1}{4}\cdot \frac{4}{19}\cdot \frac{3}{18}=\frac{1}{114}=0,0087$

\cparagraph{Satz} (Formel der totalen WK)\\
Sei $(\Omega, \cA, \PP)$ ein WK-Raum und seien $B_1,\dots,B_n \in \cA$ mit 
\begin{itemize}
\item $\bigcup_{i=1}^n B_i = \Omega$
\item $B_i \cap B_j = \emptyset $ für $i \not= j$
\item $\PP (B_i) >0$ für alle $i=1,\dots,n$
\end{itemize}
Dann gilt:
$$\PP(A) = \sum_{i=1}^n \PP(A|B_i) \cdot \PP (B_i)$$\\
ABB S2

\cparagraph{Beispiel} (Prävalenz von HIV)
\begin{itemize}
\item HIV-Prävalenz weltweit: $0,8\%$
\item HIV-Prävalenz in Europa: $0,2\%$
\item es gibt $7$ Mrd. Menschen auf der Erde
\item es gibt $740$ Mio Menschen in Europa
\end{itemize}
Gesucht:
\begin{itemize}
\item WK, dass zufällig ausgewählter Europäer HIV-positiv ist.
\item WK, dass zufällig ausgewählter Nicht-Europäer HIV-positiv ist.
\end{itemize}
Lösung:\\
$E:=\{\text{ausgewählte Person ist Europäer}\}$\\
$P:=\{\text{ausgewählte Person ist HIV positiv}\}$\\
Wir wissen: \\
$\PP(P)=0,008$, $\PP(E)=\frac{74}{700}\approx 0,1057$\\
$\PP(P|E)=0,002$.\\
Wir wollen wissen:
\begin{itemize}
\item $\PP(\bar P | E)=1-\PP(P|E)=1-002=0,998$
\item $\PP(P | \bar E)=\PP(B|\bar E) \cdot \PP(E)+\PP(P|E) \cdot \PP(E)$ (mit $B_1=\bar E$ und $B_2=E$)\\
Umstellen liefert:\\
$\PP(P|\bar E) = \frac{\PP(B)-\PP(P|E)\cdot\PP(E)}{\PP(\bar E)}=\frac{0,008-0,002\cdot 0,1057}{1-0,1057}=0,008709$
\end{itemize}

\cparagraph{Satz} (Formel von Bayes)\\
Sei $(\Omega, \cA, \PP)$ WK-Räume und seien $B_1,\dots,B_n \in \cA$ mit 
\begin{itemize}
\item $\bigcup_{i=1}^n B_i = \Omega$
\item $B_i \cap B_j = \emptyset $ für $i \not= j$
\item $\PP (B_i) >0$ für alle $i=1,\dots,n$
\end{itemize}
Dann gilt für beliebige $A \in \cA$ mit $\PP(A) >0$ und beliebiges $j\in \{1,\dots,n\}$:
$$\PP(B_j|A)=\frac{\PP(A|B_j)\cdot \PP(B_j)}{\PP(A)}=\frac{\PP(A|B_j)\cdot \PP(B_j)}{\sum_{i=1}^n \PP(A|B_i) \cdot \PP(B_i)}$$
Formel von Bayes dreht also die Bedingung um.

\cparagraph{Beispiel} (Ziegenproblem)\\
In einer Spielshow steht der Kandidat vor $3$ verschlossenen Türen. Eine Türe verbirgt den Hauptgewinn, ein Auto. Hinter den beiden anderen Türen sind Ziegen. Der Kandidat zeigt auf eine der Türen, der Spielleiter (der weiß, wo das Auto steht) öffnet gemäß der Spielregeln eine der beiden anderen Türen um eine Ziege zu präsentieren. \\
Der Kandidat darf nun seine Wahl ändern. Sollte er das tun?\\
ABB S3\\
Lösung: \\
Wir legen uns fest, dass der Kandidat Tor 1 gewählt hat und Moderator Tor 3 öffnet(ohne Beschränkung der Allgemeinheit(oBdA): sonst Umnummerieren).\\
Ergebnismenge: $\Omega = \{(i,j)\;|\; i,j=1,2,3\}$ mit $(i,j)$ … Gewinn ist hinter Tor $i$, Moderator öffnet Tor $j$.\\
Definiere die Ereignisse \\
$G_i:= \{ \text{Gewinn hinter Tor }i\}=\{(i,1), (i,2), (i,3)\}$ und\\
$M_j:=\{\text{Moderator öffnet Tor }j\}=\{(1,j), (2,q), (3,q)\}$\\
Wir wissen:\\
$\PP(G_i)=\frac{1}{3}$ für alle $i=1,2,3$\\
$\PP(M_3|G_1)=\tfrac{1}{2}$\\
$\PP(M_3|G_2)=1$\\
$\PP(M_3|G_3)=0$\\
Gesucht: $\PP(G_2|M_3)$
\begin{align*}
\PP(G_2|M_3)&=\frac{\PP(M_3|G_2)\cdot \PP(G_2)}{\PP(M_3|G_1)\cdot \PP(G_1)+\PP(M_3|G_2)\cdot \PP(G_2)+\PP(M_3|G_3)\cdot \PP(G_3)}\\
&=\frac{1\cdot \frac{1}{3}}{\frac{1}{2}\cdot \frac{1}{3}+1\cdot \frac{1}{3}+0\cdot \frac{1}{3}}\\
&=\frac{2}{3}
\end{align*}
Dieses scheinbare Paradoxon ist gut zu veranschaulichen, wenn man sich nicht 3 sondern 100 Tore vorstellt. Wenn man eines der 100 auswählt und der Moderator von den restlichen 99 Toren 98 öffnet, ist offensichtlich, dass die Wahrscheinlichkeit zu gewinne höher ist, wenn man das Tor wechselt. Die gesamte Wahrscheinlichkeiten der geöffneten Tore „sammeln“ sich hinter dem nicht geöffneten, nicht ausgewählten Tor.

\cparagraph{Beispiel} (Zuverlässigkeit diagnostischer Tests)\\
Betrachten eines Test zum diagnostizieren einer Krankheit. Dieser kann entweder „positiv“ oder „negativ“ sein.\\
Gegebene Ereignisse:\\
$P:=\{\text{Test positiv}\}$ … Test tippt darauf, dass Krankheit vorliegt.\\
$\bar P:=\{\text{Test negativ}\}$ … Test tippt darauf, dass Krankheit nicht vorliegt.\\
$K:= \{\text{Person ist krank}\}$\\
$\bar K:= \{\text{Person ist nicht krank}\}$
\begin{itemize}
\item $\text{Sensitivität}:=\PP(P|K)$ (WK, dass Test „positiv“ anzeigt, wenn man tatsächlich auch krank ist. D.h. richtig-positiver Test)
\item $\text{Spezifität}:=\PP(\bar P|\bar K)$ (WK, dass Test „negativ“ anzeigt, wenn man tatsächlich gesund ist. D.h. richtig-negativer Test)
\end{itemize}
\begin{tabular}{r | c c}
& krank & gesund\\
\hline
Test positiv & richtig-positiv & falsch-positiv\\
Test negativ & falsch-negativ & richtig-negativ
\end{tabular}

Problem: Typischerweise sind Sensitivität und Spezifität gegeben, aber eigentlich interessieren uns $\PP(K|P)$ oder $\PP(K|\bar P)$.

\subsection{Unabhängigkeit}
Wir untersuchen die Frage, ob sich Ereignisse gegenseitig beeinflussen.

\cparagraph{Definition} Zwei Ereignisse $A,B \in \cA$ heißen (stochastisch) unabhängig, wenn 
$$\PP(A\cup B)=\PP(A) \cdot \PP(B)\text{.}$$
Die Ereignisse $A_1,\dots, A_n$ heißen paarweise (stochastisch) unabhängig, wenn 
$$\PP(A_i\cup A_j) = \PP(A_i)\cdot \PP(A_j)$$
für alle $i\not=j$.\\
Die Ereignisse $A_1,\dots,A_n$ heißen (stochastisch) unabhängig (in ihrer Gesamtheit), wenn 
$$\PP(A_{i_1}\cap A_{i_2}\cap \dots \cap A_{i_k}=\PP(A_{i_1})\cdot \dots \cdot \PP(A_{i_k})$$
für jede beliebige Auswahl von $k \;(2\leq k \leq n)$ der $n$ Ereignisse.

\cparagraph{Bemerkung}
\begin{enumerate}
\item $A_1, \dots , A_n$ (in ihrer Gesamtheit) unabhängig $\Rightarrow A_1, \dots , A_n$ paarweise unabhängig. Rückrichtung gilt im Allgemeinen nicht (siehe Übung).
\item Ist $\PP(B) >0$ so gilt $A$ und $B$ unabhängig $\Leftrightarrow P(A|B) = \PP(A)$\\
Beweis:
\begin{itemize}
\item[„$\Rightarrow$“]
$\PP(A|B) \overset{\text{Def.}}{=}\frac{\PP(A\cap B)}{\PP(B)}=\frac{\PP(A) \cdot \PP(B)}{\PP(B)}=\PP(A)$
\item[„$\Leftarrow$“]
$\PP(A\cap B) = \frac{\PP(A \cap B)}{\PP(B)}\cdot \PP(B) = \PP(A|B) \cdot \PP(B) = \PP(A) \cdot \PP(B)$
\end{itemize}
$A$ und $B$ unabhängig: Die WK für das Eintreten von $A$ hängt nicht von dem Wissen, ob $B$ bereits eingetreten ist, ab.
\item $A$ und $B$ disjunkt und $\PP(A) > 0, \; \PP(B) >0$.\\
$\Rightarrow A$ und $B$ sind stochastisch \emph{abhängig}.\\
\fbox{Sind $A$ und $B$ disjunkt, so sind sie abhängig!}\\
denn: $\PP(A\cap B) = 0 \not = \PP(A) \cdot \PP(B)$
\item Sind $A$ und $B$ stochastisch unabhängig, so sind:
\begin{itemize}
\item $A$ und $\bar B$ stochastisch unabhängig
\item $\bar A$ und $B$ stochastisch unabhängig
\item $\bar A$ und $\bar B$ stochastisch unabhängig
\end{itemize}
Analog für mehr als zwei Ereignisse.
\item $\emptyset$ und $\Omega$ sind zu jedem $A \in \cA$ unabhängig.
\end{enumerate}

\cparagraph{Beispiel} (Münze und Würfel)\\
Werfen faire Münze (Werte $0/1$) und fairen Würfel (Werte $1,\dots,6$). Untersuche auf Unabhängigkeit:
\begin{enumerate}
\item $A=\{\text{Wer der Münze ist }1\}$, $B=\{\text{Würfel }>4\}$
\item $A=\{\text{Wer der Münze ist }1\}$, $C=\{\text{(Würfel + Münze)} >4 \}$
\item $A=\{\text{Wer der Münze ist }1\}$, $D=\{\text{(Würfel + Münze)}\in\{2,3,4\}\}$
\end{enumerate}
Lösung:\\
$\Omega = \{ (0,1), (0,2), (0,3),\dots , (1,6)\}$
\begin{enumerate}
\item $\PP(A) =\frac{|A|}{|\Omega|}=\frac{6}{12}=\frac{1}{2}$,\quad $\PP(B) = \frac{|B|}{|\Omega|}=\frac{4}{12}=\frac{1}{3}$\\
$\PP(A \cap B)=\frac{|A\cap B|}{|\Omega|}=\frac{2}{12}=\frac{1}{6}$\\
$\Rightarrow \PP(A\cap B) = \frac{1}{6}=\frac{1}{2}\cdot \frac{1}{3}= \PP(A)\cdot \PP(B) \checkmark$\\
$\Rightarrow A$ und $B$ unabhängig.
\item $\PP(C) = \frac{5}{12}$\\
$\PP(A \cap C) = \frac{3}{12} \not = \frac{1}{2}\cdot \frac{5}{12} = \frac{5}{24} = \PP(A) \cdot \PP(C)$\\
$\Rightarrow A$ und $B$ nicht unabhängig, also abhängig.
\item $\PP(D)=\frac{1}{2}$\\
$\PP(A \cap D ) = \frac{1}{4} = \frac{1}{2} \cdot \frac{1}{2} = \PP(A) \cdot \PP(D) \checkmark$\\
$\Rightarrow A$ und $B$ unabhängig.
\end{enumerate}

\cparagraph{Beispiel} Eine Maschine besteht aus $2$ Bauteilen. Bauteil 1 ist mit WK $0,05$ defekt, Bauteil 2 mit WK $0,02$.\\
Wir nehmen, dass sie unabhängig voneinander ausfallen.\\
Frage: Wie groß ist die WK, dass mindestens 1 defekt ist?\\
Lösung: $\Omega = \{(0,0), (0,1), (1,0), (1,1)\}$\\
$A=\{\text{Bauteil 1 defekt}\}=\{(0,1),(0,0)\}$\\
$B=\{\text{Bauteil 2 defekt}\}=\{(0,0), (1,0)\}$\\
$\PP(A) = 0,05$ \quad $\PP(B) = 0,02$\\
Gesucht: $\PP(A \cup B)$\\
1. Variante: $\PP(A \cup B) = 1 - \PP(\overline{A \cup B}) = 1 - \PP(\bar A \cap \bar B) = 1 - \PP(\bar A) \cdot \PP(\bar B) = 1-0,95\cdot 0,98 = 0,069$\\
2. Variante: $\PP(A \cup B) = \PP(A) + \PP(B) - \PP(A \cap B) = 0,05 + 0,02 - 0,05\cdot 0,02 = 0,069$

\cparagraph{Satz} Seien $A_1, \dots, A_n$ unabhängige Ereignisse. Dann gilt:
$$\PP(A_1 \cup A_2 \cup \dots \cup A_n) = 1 - \PP(\bar A_1) \cdot \dots \cdot \PP(\bar A_n)$$
Beweis: 
\begin{align*}
\PP(A_1 \cup \dots \cup A_n) &= 1 - \PP(\overline{A_1 \cup \dots \cup A_n})\\
&= 1 - \PP(\bar A_1 \cup \dots \cup \bar A_n)\\
&= 1- \PP(\bar A_1) \cdot \dots \cdot \PP(\bar A_2)
\end{align*}

\cparagraph{Beispiel} Drei Jäger schießen gleichzeitig und unabhängig voneinander auf Bambi.\\
Jäger 1 trifft mit WK $0,85$, Jäger 2 mit $0,75$ und Jäger 3 mit $0,2$.\\
Mit welcher WK wird Bambi getroffen?\\
Lösung: $A=\{\text{Jäger }i\text{ trifft}\;|\; i =1,2,3\}$\\
Gesucht: WK von $A_1 \cup A_2 \cup A_3$ 
\begin{align*}
\PP(A_1 \cup A_2 \cup A_3) &= 1 - \PP(\bar A_1) \cdot \PP(\bar A_2) \cdot \PP(\bar A_3)\\
&= 1 - 0,15\cdot 0,25 \cdot 0,8\\
&= 0,97
\end{align*}

\cparagraph{Beispiel} Parallel- und Reihenschaltung\\
Ein System besteht aus mehreren Elementen.
\begin{itemize}
\item Die Zuverlässigkeit (WK in einem bestimmten Zeitintervall nicht auszufallen) sei für jedes Element bekannt.
\item Die Elemente heißen \emph{in Reihe geschaltet}, wenn das System genau dann funktioniert, wenn alle Elemente funktionieren.
\item Die Elemente heißen \emph{parallel geschaltet}, wenn das System genau dann funktioniert, wenn wenigstens eins der Elemente funktioniert.
\end{itemize}
$F:=\{\text{System funktioniert in betrachtetem Zeitintervall}\}$\\
$F_i= \{\text{Element } i\text{ funktioniert in betrachtetem Zeitintervall}\}$\\
Wir betrachten eine Sicherungsanlage mit 2 Teilsystemen, die beide funktionieren müssen. Zur Erhöhung der Zuverlässigkeit sind bei Teilsystem 1 ein Element und bei Teilsystem 2 zwei Elemente zu den Hauptelementen als Reserve parallel geschaltet. Die Zuverlässigkeit der Elemente in TS 1 beträgt je $0,9$ und die der Elemente in TS 2 je $0,8$. Die Elemente arbeiten unabhängig voneinander.\\
Teilsystem 1 (mit parallelen Elementen $E_1$[Hauptelement] und $E_3$) liegt in Reihe zu Teilsystem 2 (mit parallelen Elementen $E_2$[Hauptelement], $E_4$ und $E_5$).\\
$F_k:= \{ \text{Element }E_k\text{ funktioniert in betrachtetem Zeitintervall}\}$

Lösung:\\
$F=\underbrace{(F_1 \cup F_3)}_{=:F_{13}} \cap \underbrace{(F_2\cup F_4 \cup F_5)}_{=:F_{245}}$\\
$\PP(F) = \PP(F_{13} \cap F_{245} ) = \PP(F_{13} \cdot \PP(F_{245})$\\
$\PP(F_{13})=1-\PP(\bar F_1) \cdot \PP(\bar F_3) = 1- 0,1^2 = 0,99$\\
$\PP(F_{245})=1-\PP(\bar F_2) \cdot \PP(\bar F_4) \cdot \PP(\bar F_5) = 1-0,2^3=0,992$\\
$\Rightarrow \PP(F) = 0,99\cdot 0,992 = 0,98208$

\section{Zufallsvariablen}

\subsection{Grundlagen}

\cparagraph{Definition} Sei $(\Omega,  \cA, \PP)$ ein WK-Raum. Eine Zufallsvariable (ZV) oder Zufallsgröße ist eine Funktion $X$, die jedem Elementarereignis eine reelle Zahl zuordnet (d.h. $X: \Omega \to \RR$) und die Zusatzeigenschaft
$$\text{für jedes Intervall gilt: }\{\omega \in \Omega \;|\;  X(\omega) \in I\} \in \cA$$
erfüllt.

\cparagraph{Bemerkung} Manchmal benötigt man noch allgemeinere Definitionen von ZVen. Auch wenn $X$ nicht zwingend Werte aus $\RR$ annimmt (und eine ähnliche Bedingung wie in Definition 1.2-1 erfüllt) spricht man von ZVen.\\
Bsp.: $X$ nimmt komplexe Zahlen, Farben, Geschlechter usw an.

\cparagraph{Bemerkung}
\begin{itemize}
\item Oft interessiert man sich für WKen:
$$\PP(\omega \in \Omega \;|\; X(\omega) \in I\})$$
bzw. in Kurzschreibweise:
$$\PP(X\in I) \quad \text{für }I \subseteq \RR$$
\item Die Bedingung aus Definition 1.2-1 stellt sicher, dass solche WKen berechnet werden können.
\item Zur effektiven Beschreibung solcher WKen dient die Verteilungnsfunktion.
\end{itemize}

\cparagraph{Beispiel} Gegeben: (idealer) Würfel mit gefärbten Seiten (ohne Zahlen). \\
Ergebnisraum $\Omega = \{$blau, grün, gelb, rot, schwarz, magenta$\}$\\
Um mit den zufälligen Ergebnissen „rechnen“ zu können, führen wir eine ZV $X: \Omega \to \RR$ ein. Wir setzen $X(\text{blau}):=1$, $X(\text{grün}):=2$, $X(\text{gelb}):=3$, $X(\text{rot})=4$, $X(\text{schwarz}):=5$, $X(\text{magenta}):=6$\\
Es gilt dann z.B.:
$$\PP(X=3) = \PP(\underbrace{\{ \omega \in \Omega \;|\; X(\omega) = 3}_{\{\text{gelb}\}} = \frac{1}{6}$$
$$\PP(X \leq 2) = \PP(\underbrace{\{\omega \in \Omega \;|\; X(\omega) = 1 \vee X(\omega) = 2\}}_{\{\text{blau, grün}\}}=\PP(\{\text{blau}\}) + \PP(\{\text{grün}\}) = \frac{2}{6}=\frac{1}{3}$$

\cparagraph{Beispiel} Alfons (A) und Britta (B) spielen ein Würfelspiel. Gewürfelt wird gleichzeitig. Das Ergebnis von Alfons' Würfel sagt, wie viel Euro Alfons von Britta bekommt. Das Ergebnis von Brittas Würfel sagt, wie viel Euro Britta von Alfons bekommt.\\
Gesucht:
\begin{anumerate}
\item Passendes WK-Modell um die ZV, die den Nettogewinn von Alfons beschreibt.
\item WK, dass Alfons (netto) mehr als $3$\euro{} Verlust hat.
\end{anumerate}
Lösung:
\begin{anumerate}
\item Gesucht: $(\Omega, \cA, \PP)$:\\
$\Omega = \{(i,j) \;|\; i,j \in \{1,\dots,6\}\}=\{1,\dots,6\}^2$ (mit $i=$ Brittas Würfel und $j=$Alfons Würfel)\\
$\cA = \cP (\Omega)$\\
$\PP$ … Gleichverteilung auf $\Omega$ (da Laplace-Experiment)\\
Alfons Gewinn ist für $(1,4)$ gerade $4-1$\euro{}. Also definieren wir $X: \Omega \to \RR$ mittels $X((i,j)):=j-i$.
\item Gesucht ist $\PP(X<-3)$:
\begin{align*}
\PP(X < -3) &= \PP(\{(i,j) \;|\; X((i,j)) < -3\}\\
&= \PP(\underbrace{\{(i,j)\;|\; j-i < -3\}}_{(1,5), (1,6), (2,6)})\\
&= \frac{3}{36}=\frac{1}{12}
\end{align*}
\end{anumerate}

\cparagraph{Beispiel} In einer Firma werden auf 3 verschiedenen Anlagen Sandwiches produziert. Wir modellieren die Anzahl der Sandwiches pro Tag mit $\Omega = \{ \underbrace{(x,y,z)}_{\omega} \;|\; x,y,z \in \NN_0\}$ mit $x,y,z$ jeweils Produktionsmenge Anlage 1, 2 und 3 ($(200,45,120)$ heißt also $300$ Sandwiches wurden in Anlage 1 produziert, $200$ in Anlage 2 und $120$ in Anlage 3).\\
Wir interessieren uns für die Gesamtproduktion. Definiere daher: $X:\Omega \to \RR$ mittels $X((x,y,z)) = x+ y+z$.

Frage: Mit welcher WK überschreitet die Gesamtproduktion eine gewisse Mindestanzahl $m$ nicht?\\
Gesucht ist also $\PP(X\leq m)=\PP(\{\omega \in \Omega \;|\; X(\omega) \leq m\})$.

\cparagraph{Definition} Sei $(\Omega, \cA, \PP)$ ein WK-Raum und $X$ eine ZV. Die Funktion
$$F_X: \RR\to [0,1], \quad F_X(x):=\PP(X \leq x)$$
heißt Verteilungsfunktion (VF) von $X$.\\
$F_X(x)$ ist also die WK, dass $X$ einen Wert kleiner oder gleich der Zahl $x$ annimmt.

\cparagraph{Beispiel} A und B spielen immer noch mit den gleichen Regeln wie in Bsp 1.2-6.\\
Wie sieht $F_X$ aus? Dazu die Wertetabelle:\\
\begin{tabular}{L{0.13}|L{0.13}|L{0.13}|L{0.13}|L{0.13}|L{0.13}|L{0.13}}
$x\in$ & $(-\infty,-5)$ & $[-5,4)$ & $[-4,3)$& $[-3,-2)$ & $[-2,-1)$ & $[-1,0)$\\
\hline
$F_X(x)$ & $0$ & $\tfrac{1}{36}$ & $\tfrac{3}{36}$ & $\tfrac{6}{36}$ & $\tfrac{10}{36}$ & $\tfrac{15}{36}$ 
\end{tabular}\smallskip\\
\begin{tabular}{L{0.13}|L{0.13}|L{0.13}|L{0.13}|L{0.13}|L{0.13}|L{0.13}}
$x\in$ & $[0,1)$ & $[1,2)$ & $[2,3)$ & $[3,4)$ & $[4,5)$ & $[5,\infty)$\\
\hline
$F_X(x)$ & $\tfrac{21}{36}$ & $\tfrac{26}{36}$ & $\tfrac{30}{36}$ & $\tfrac{33}{36}$ & $\tfrac{35}{36}$ & $\tfrac{36}{36}$
\end{tabular}\smallskip\\
Denn z.B. gilt:\\
$F_X(-4) = \PP(X \leq -4) = \PP(\{(5,1),(6,1), (6,2)\}) = \frac{3}{36}$\\
$F_X(3) = \PP(X \leq 3 ) = 1- \PP(X>3) = 1 - \PP(\{(1,5),(1,6),(2,6)\})=1-\frac{3}{36}=\frac{33}{36}$\\
Beachte: In $F_X$ können alle rellen Zahlen eingesetzt werden (Gezeichnete Funktion geht also von $-\infty$ mit $0$ bis $-5$ und macht dann unstetige Sprünge bis $5$, wo es bis $\infty$ mit $1$ weiter geht).

\cparagraph{Lemma} Sei $X$ eine ZV und $F_X$ die zugehörige VF. Dann gilt:
\begin{itemize}
\item $0\leq F_X (x) \leq 1$
\item $x_1 \leq x_2 \Rightarrow F_X(x_1) \leq F_X(x_2)$ \tab(Monotonie)
\item $\lim_{x\to -\infty} F_X(x) =0$, $\lim_{x\to\infty} F_X(x) = 1$
\item $\lim_{x \searrow x_0} F_X(x)=F_X(x_0)$ \tab\tab(rechts-stetig)
\item $\PP(a <X\leq b)=F_X(b)-F_X(a)$
\item $\PP(X>a) = 1 - F_X(a)$
\item $\PP(X=a)=F_X(a)-\lim_{x\nearrow a}F_X(x)$ \tab (Sprunghöhe bei $x=a$)
\end{itemize}

\subsection{Diskrete und stetige Zufallsvariable}
Wir betrachten 2 Klassen von ZVen: diskrete und stetige.

\cparagraph{Definition} Eine ZV heißt \emph{diskrete ZV}, falls $X$ nur endlich viele oder abzählbar viele oder abzählbar unendlich viele Werte annehmen kann ($M$ abzählbar unendlich $\Leftrightarrow$ $\exists$ eine bijektive Abbildung $\varphi: M \to \NN$. Sprich: „man kann alle Elemente durchnummerieren“, bspw. rationale Zahlen usw.).

%\addtocounter{cparagraphC}{1}
%\cparagraph{-} nicht relevant

\cparagraph{Bemerkung} Sei $X$ eine diskrete ZV welche nur die Werte $x_1, x_2 , \dots$ annehmen kann.
\begin{anumerate}
\item Wir nenne die Funktion
$$f: x_i\mapsto f(x_i):=p_i:= \PP(X=x_i)$$
Wahrscheinlichkeitsfunktion.
\item $\sum_i f(x_i)=\sum_i p_i =1$
\item $\PP(a < X \leq b) = \sum_{i:\; a<x_i \leq b} f(x_i)$
\item Darstellung mit Verteilungstabelle:\\
\begin{tabular}{r | c | c | c | c | c}
Werte & $x_1$ & $x_2$ & $x_3$& …\\
\hline
WK $f(x_i)$ & $p_1$ & $p_2$ & $p_3$ & …
\end{tabular}
\item Darstellung als Stabdiagramm:\\
ABB S4
\end{anumerate}

\cparagraph{Beispiel} Betrachte unfaire Münze, die mit WK $0,6$ auf Zahl fällt. Dann
\begin{itemize}
\item $\Omega = \{ K, Z\}$
\item $X(K):=0$, $X(Z):=1$
\item $\PP(X=0)=0,4=1-\PP(X=1)$
\end{itemize}
\begin{tabular}{r | c | c}
Wert $x_i$ & 0 & 1\\
\hline 
WK $f(x_i)$ & 0,4 & 0,6
\end{tabular}\\
ABB S5

\cparagraph{Beispiel} Betrachten Wurf mit 2 Würfeln: $\Omega=\{(i,j)\;|\; i,j=1,\dots,6\}$. Augensumme soll als ZV dargestellt werden: $X((i,j)):=i+j$ für $i,j=1,\dots,6$\\
Verteilungstabelle:\\
\begin{tabular}{r | c | c| c| c| c| c| c| c| c| c| c}
$x_i$ & 2 & 3 & 4 & 5 & 6 & 7 & 8 & 9  & 10 & 11 & 12\\
\hline
$f(x_i)$ & 1/36 & 2/36 & 3/36 & 4/36 & 5/36 & 6/36 & 5/36 & 4/36 & 3/36 & 2/36 & 1/36
\end{tabular}
\begin{anumerate}
\item $\PP(X>9) = \PP(X=10) + \PP(X=11) + \PP(X=12) = \frac{6}{36}$
\item $\PP(6\leq X \leq 8) = \frac{16}{36}$
\item $F_X(3) = \PP(X\leq 3) = \frac{3}{36}$
\end{anumerate}

\cparagraph{Definition} Eine ZV heißt \emph{stetige ZV}, falls ihre Verteilungnsfunktion $F_X$ stetig ist.

In dieser Vorlesung betrachten wir nur stetige ZV, bei denen $F_X$ differenzierbar ist.

\cparagraph{Definition} Sei $X$ eine ZV mit differenzierbarer Verteilungsfunktion $F_X$. Dann wird die Ableitung $f:= F'_X$ \emph{(Wahrscheinlichkeits-)Dichte(funktion)} genannt.

\cparagraph{Bemerkung}
\begin{itemize}
\item Ist $f$ die Dichtefunktion zur VF $F_X$, so gilt
$$F_X(x) = \int_{-a}^x f(t) \intd{t} \qquad \text{(Hauptsatz der Differential und Integralrechnung)}$$
\item Nicht jede stetige Funktion $F$ kann als Integral einer Dichtefunktion geschrieben werden.
\item Bilder:\\
ABB S6
\begin{align*}
\PP(X\leq 1)&=F_X(1)\\
&=\PP(\{\omega \in \Omega \;|\; X(\omega)\leq 1 \}) \\
&= \{\text{WK, dass $X$ einen Wert $\leq 1$ annimt}\}\\
&=\{\text{Funktionswert von $F_X$ bei $X=1$}\}\\
&=\int\limits_{-\infty}^1 f(t)\intd{t}\\
&=\{\text{Flächeninhalt des markierten Bereichs der Dichtefunktion}\}
\end{align*}
\end{itemize}

\cparagraph{Satz} Sei $X$ eine stetige ZV mit Dichtefunktion $f$. Dann gilt:
\begin{itemize}
\item $f$ ist auf ganz $\RR$ definiert.
\item $f(x)\geq 0 \quad \forall x \in \RR$
\item $\int\limits_{-\infty}^{\infty}f(x)\intd{x}=1$ (Dichtefunktion ist normiert)
\end{itemize}
Umkehrung des Satzes gilt auch:
\cparagraph{Satz} Sei $f$ eine integrierbare reelwertige Funktion. Dann gilt: 
\begin{itemize}
\item $f$ ist auf ganz $\RR$ definiert.
\item $f(x)\geq 0 \quad \forall x \in \RR$
\item $\int\limits_{-\infty}^{\infty}f(x)\intd{x}=1$ 
\end{itemize}
Dann ist $f$ die Dichte einer Zufallsvariablen $X$. Die zugehörige VF $F_X:\RR\to [0,1]$ ist dann
$$F_X(x):=\int\limits_{-\infty}^{\infty} f(t) \intd{t}$$

\cparagraph{Beispiel} Wir kommen zu einer zufälligen Zeit an der Bushaltestelle an. Der Bus fährt alle 10 Minuten. Die ZV $X$ beschreibe die Wartezeit auf den nächsten Bus, d.h. $X$ kann alle Wert zwischen 0 und 10 annehmen wobei jede Wartezeit gleich-wahrscheinlich sein soll.\\
Die zugehörige Dichtefunktion ist daher:\\
ABB S7\\
$f(x):=\begin{cases}
h & 0 < x < 10\\
0 & \text{sonst}
\end{cases}$
\begin{anumerate}
\item Wie ist $h$ zu wählen?\\
Es muss gelten $1\overset{!}{=}\int\limits_{-\infty}^{\infty}f(x)\intd{x}=\int\limits_0^{10}h\intd{x}=\left[ h\cdot x\right]_0^{10}=10\cdot h \Rightarrow h = \frac{1}{10}$
\item Wie sieht $F_X$ aus?\\
ABB S8\\
$F_X(x)=\int\limits_{-\infty}^x f(t) \intd{t}=\begin{cases}
0 & x\leq 0\\
\tfrac{1}{10} x & 0 < x < 10\\
1 & x \geq 10
\end{cases}$\\
Fall $x\leq 0$: $F_X(x)=\int\limits_{-\infty}^x 0 \intd{t} = 0$\\
Fall $0<x<10$: $F_X(x)= \int\limits_{-\infty}^0 0 \intd{t} + \int\limits_0^x \frac{1}{10} \intd{t} = \frac{1}{10}x$\\
Fall $x \geq 10$: $F_X(x) = \underbrace{\int\limits_{-\infty}^0 0 \intd{t}}_{0}+ \underbrace{\int\limits_0^{10} \frac{1}{10} \intd{t}}_1 + \underbrace{\int\limits_{10}^x 0 \intd{t}}_0 = 1$
\end{anumerate}

\cparagraph{Satz} Sei $X$ eine stetige ZV mit Dichte $f$ und VF $F$. Die WK, dass $X$ einen Wert im Intervall $(a,b)$ (oder $[a,b], [a,b), (a,b]$) annimt ist:
\begin{align*}
\PP(a < X<b) &= \PP(\leq X \leq b)
= \PP(a \leq X <b) 
= \PP(a < X \leq b)\\
&=F(b)-F(a) \\
&= \int\limits_a^b f(x) \intd{x}
\end{align*}

Das entspricht den Flächeninhalt unter $f$ zwischen $a$ und $b$.

\cparagraph{Bemerkung}
\begin{itemize}
\item Für $a=b$ zeigt der Satz: Ist $X$ stetig, so gilt 
$$\PP(X=a) = 0$$
für alle $a \in \RR$
\item Im Satz ist auch $a = - \infty$ und/oder $b=+ \infty$ erlaubt, wobei 
$$F(-\infty) := \lim_{x \to -\infty} F(x) = 0$$
$$F(\infty) := \lim_{x \to \infty} F(x) = 1$$
\end{itemize}

\cparagraph{Beispiel} (Fortsetzung von Beispiel 1.2.19)
\begin{itemize}
\item Wie groß ist die WK maximal 3 Minuten zu warten? Gesucht: $\PP(X \leq 3)$\\
$\PP(X \leq 3) = F(3) = 0,1 \cdot 3 = 0,3$
\item Wie groß ist die WK mindestens 2 Minuten zu warten? Gesucht: $\PP(X \geq 2)$\\
$\PP(X \geq 2 ) = \PP(2 \leq X < \infty) = F(\infty)-F(2) = 1-2\cdot 0,1 = 0,8$
\item Wie groß ist die WK zwischen 5 und 9 Minuten zu warten?\\
$\PP( 5 \leq X \leq 9 ) = F(9) - F(5) = 9 \cdot 0,1 - 5 \cdot 0,1 = 0,4$
\end{itemize}

\subsection{Erwartungswert und Varianz}
\cparagraph{Beispiel} (Würfelspiel) A und B würfeln wieder: 2 Würfel. ZV $X$ beschreibt die Augensumme. Spielregeln:\\
\begin{tabular}{c | c | c}
Ergebnis & WK & Bewertung\\
\hline 
$\{X\leq 3\}$ & 1/12 & A zahlt B 20,10\euro{}\\
$\{4 \leq X \leq 6\}$ & 1/3 & A zahlt B 1,20\euro{}\\
$\{X=7\}$ & 1/6 & niemand zahlt etwas\\
$\{8 \leq X \leq 9\}$ & 1/4 & B zahlt A 3,10\euro{}\\
$\{ 10 \leq X \leq 12\}$ & 1/6 & B zahlt A 7,80\euro{}
\end{tabular}

$Y$… Gewinn von A\\
Verteilungstabelle von $Y$:\\
\begin{tabular}{r | c | c | c | c | c}
Werte $y_i$ & -20,1 & -1,2 & 3,1 & 7,8 & 0\\\hline 
WK $p_i$ & 1/12 & 1/3 & 1/4 & 1/6 & 1/6
\end{tabular}

Frage: Ist das Spiel gerecht?\\
Mittlerer Gewinn: $-20,1 \cdot \frac{1}{12} + (-1,2) \cdot \frac{1}{3}+ 0\cdot \frac{1}{6} + 3,1 \cdot \frac{1}{4} + 7,8 \cdot \frac{1}{6} = 0$\\
Dies motiviert die folgende Definition:
\cparagraph{Definition} Sie $X$ eine ZV. Der Erwartungswert $\EE(X)$ und die Varianz $\var(X)$ sind wie folgt definiert:
\begin{anumerate}
\item Falls $X$ diskret ist, mit Verteilungstabelle:\\
\begin{tabular}{r | c c c c}
Werte & $x_1$ & $x_2$ & $x_3$ & …\\\hline
WK & $p_1$ & $p_2$ & $p_3$ & …
\end{tabular}\\
(bzw. mit WK-Funktion $f$), dann 
$$\EE(X) = \sum_i x_i \cdot p_i = \sum_i x_i \cdot f(x_i)$$
und
$$\var(X)=\sum_i (x_i - \EE(X))^2 \cdot p_i = \sum_i (x_i - \EE(X))^2 f(x_i)$$
\item Falls $X$ stetig ist mit Dicht $f$, dann
$$\EE(X) = \int\limits_{-\infty}^{\infty} x\cdot f(x) \intd{x}$$
und 
$$\var (X) = \int\limits_{-\infty}^{\infty} (x-\EE(X))^2 f(x) \intd{x}$$
\end{anumerate}

\cparagraph{Satz} Sei $X$ eine ZV und $a, b \in \RR$. Dann:
\begin{itemize}
\item $\EE(a+bX)=a+b\EE(X)$ \tab (Linearität des Erwartungswertes)
\item $\var(a+bX) = b^2 \var X$
\item $\var(X)=0 \;\Leftrightarrow\; \exists a \in \RR: \PP(X=a) =1$
\end{itemize}

\cparagraph{Bemerkung} 
\begin{itemize}
\item $\sigma_X=\sqrt{\var X}$ wird \emph{Standardabweichung} genannt.
\item $\var (X)$ ist die mittlere quadratische Abweichung vom Erwartungswert und es gilt:
$$\var (X) = \EE(X^2) - (\EE(X))^2$$
\item Sei $g: \RR \to \RR$ eine beliebige Funktion, dann gilt: \\
(im diskreten) \tab\tab $\EE(g(X))=\sum_i g(x_i) \cdot f(x_i)$\bigskip\\
(im stetigen) \tab\tab $\EE(g(X))=\int\limits_{-\infty}^{\infty} g(x) \cdot f(x) \intd{x}$\\
z.B. für $g(x):=x^2$:\\
$\EE(X^2) = \sum_i x_i^2 f(x_i)$ bzw. $\EE(X^2) = \int\limits_{-\infty}^{\infty}x^2 f(x) \intd{x}$
\end{itemize}

\cparagraph{Beispiel} $X$… Zahl der Einsätze eines Havariedienstes an einem Tag. Erfahrung liefert: \\
\begin{tabular}{r | c c c}
$x_i$ & $0$ & $1$ & $2$\\\hline
$p_i=f(x_i)$ & $0,6$ & $0,3$ & $0,1$
\end{tabular}\medskip\\
$\EE(X)=0\cdot 0,6 + 1 \cdot 0,3 + 2 \cdot 0,1 = 0,5$\\
$\EE(X^2) = 0^2 \cdot 0,6  + 1^2 \cdot 0,3^2 + 2^2 \cdot 0,1 = 0,7$\\
$\var(X)=\EE(X^2) - (\EE(X))^2 = 0,7-0,5^2 = 0,45$\\
$\sigma_X= \sqrt{0,45}=0,671$\bigskip\\
Wir betrachten nun eine ZV $X$ und fragen uns: Welchen Wert $m\in \RR$ muss man wählen, damit $\PP(X\leq m)\geq \frac{1}{2}$ und $\PP(X\geq m) \geq \frac{1}{2}$ gilt?\\
Problem: Antwort nicht eindeutig!\\
ABB S9\\
Hier erfüllt jedes $m\in [1,3)$ diese Bedingung! Welchen dieser Werte wählen wir? Den kleinsten (und nennen ihn \emph{Median})!

\cparagraph{Definition} Ist $F_X$ die Verteilungsfunktion einer ZV $X$, so heißt
$$F_X^{-1}: [0,1]\to \RR, \quad F_X^{-1}(\alpha):= \min\{x\in\RR\;|\; F_X(x) \geq \alpha \}$$
die \emph{verallgemeinerte inverse Verteilungsfunktion}. Der Median $m_X$ der Verteilungsfunktion $F_X$ ist definiert als
$$m_X = F_X^{-1}(0,5)\text{.}$$
Für gegebenes $\alpha \in (0,1)$ heißt
$$q_\alpha = F_X^{-1}(\alpha)$$
das $\alpha$-Quantil zur Verteilung $F_X$.

\cparagraph{Bemerkung} 
\begin{itemize}
\item Daher ist der Median das $0,5$-Quantil der Verteilung: $m_X=q_{0,5}$
\item Im Allgemeinen gilt: Erwartungswert $\not =$ Median.\\
Beispiel:\\
\begin{tabular}{r | l l l l}
$x_1$ & $1$ & $3$ & $6$ & $7$\\\hline
$\PP(X=x_i)$ & $0,2$ & $0,3$ & $0,1$ & $0,4$
\end{tabular}\\
$\EE(X)=4,5$\\
$m_X=\min\{x\in \RR \;|\; F_X(x) \geq 0,5\}= \min[3,\infty) = 3$
\end{itemize}

\subsection{Kovarianz und Unabhängigkeit}

Betrachten nun mehrere ZVen gleichzeitig.\\
Fragen:
\begin{itemize}
\item Haben ZVen „Einfluss aufeinander“?\\
$\rightsquigarrow$ Unabhängigkeit, Unkorreliertheit
\item Kann man das Verhalten mehrerer ZVn gleichzeitig beschreiben?\\
$\rightsquigarrow$ gemeinsame Verteilung
\end{itemize}

\cparagraph{Definition} Sind $X$ und $Y$ ZVen, so heißt 
$$F: \RR^2 \to [0,1], \; F(a,b) = \PP(X \leq a, Y \leq b)$$
gemeinsame Verteilungsfunktion von $X$ und $Y$.
\begin{itemize}
\item Sind beide ZVen diskret, wobei $X$ die Werte $x_1, x_2, \dots$ und $Y$ die Werte $y_1, y_2, \dots$ annehmen kann, dann heißt die Funktion $f$ gegeben durch 
$$f(x_i, y_j):= \PP(X=x_i, Y=y_j)$$
\emph{gemeinsame Verteilungsfunktion}.
\item Sind beide ZVen stetig und existiert eine Funktion $f: \RR^2 \to [0,\infty)$ mit 
$$F(x,y) = \int\limits_{-\infty}^x\int\limits_{-\infty}^x f(s,t) \intd{t} \intd{s}$$
so heißt $f$ \emph{gemeinsame (Wahrscheinlichkeits-)Dichte(-funktion)} von $X$ und $Y$.
\end{itemize}

\cparagraph{Bemerkung} Im diskreten Fall gilt:
$$F_(x,y) = \sum_{i:\; x_i\leq x} \sum_{j:\; y_j \leq y}f(x_i, y_j)$$
\begin{itemize}
\item Die Definition 1.2.30 lässt sich auf beliebig viele ZVen erweitern.
\item ZVen lassen sich zu einem (zufälligen) Vektor zusammenfassen:
\end{itemize}

\cparagraph{Definition} Sind $X_1, \dots, X_n$ ZVen so heißt
$$\mtr{X_1\\X_2\\\vdots\\X_n}$$
\emph{n-dimensionaler Zufallsvektor}.

\cparagraph{Beispiel} (Zufallsvektor mit $n=2$)\\
Seien $X,Y$ diskrete ZVen gegeben durch\\
$X$… Anzahl der technischen Durchsichten eines PKW eines bestimmten Typs zwischen $0$ und $15.000\;\mathrm{km}$.\\
$Y$… Anzahl der Motorpannen dieses PKW zwischen $0$ und $15.000\;\mathrm{km}$.\\
Setzen $Z=\mtr{X\\Y}$
\begin{itemize}
\item Verteilungstabelle:\\
\begin{tabular}{c | c c c c c c c c c c}
$\mtr{X\\Y}$ & $\mtr{0\\0}$ & $\mtr{0\\1}$& $\mtr{0\\2}$& $\mtr{0\\3}$& $\mtr{1\\0}$& $\mtr{1\\1}$& $\mtr{1\\2}$& $\mtr{2\\0}$& $\mtr{2\\1}$\\\hline
$\PP(X=x,Y=y)$ & $0,02$ & $0,04$ & $0,03$ & $0,01$ & $0,05$ & $0,01$ & $0,05$ & $0,53$ & $0,17$
\end{tabular}
\item gemeinsame Wahrscheinlichkeitsfunktion (in Matrixschreibweise):\\
$P=(p_{ij})$ \qquad $p_{ij}:=f(x_i,y_i)=\PP(X=x_i, Y=y_i)$\\
\begin{tabular}{c | c c c c | c}
x$\setminus$y & 0 & 1 & 2 & 3 &\\\hline
0 & 0,02 & 0,04 & 0,04 & 0,01 & 0,1 \\
1 & 0,05 & 0,1 & 0,05 & 0 & 0,2\\
2 & 0,53 & 0,17 & 0 & 0 & 0,7\\\hline
&0,6 & 0,31 & 0,08 & 0,01 & 1
\end{tabular}\\
z.B. $f(0,2)=0,03$
\item gemeinsame Verteilungsfunktion: Es gilt z.B. $F(2,1)=\PP(X\leq 2, Y\leq 1)=0,02+0,04+0,05+0,1+0,53+0,17=0,91$ (entspricht dem „Rechteck“ der WK-Funktion in Matrixschreibweise, wo $x\leq 2$ und $y\leq 1$)
\item Randverteilungen:\\
\begin{tabular}{l | l}
\mpb[.4]
Verteilung von $X$\\
$\PP(X=x_i)=\sum_j p_{i,j}=:p_{i,\cdot}$\\
\begin{tabular}{c | c c c}
$x_i$ & 0 & 1 & 2\\\hline
$p_{i,\cdot}$ & 0,1 & 0,2 & 0,7
\end{tabular}
\mpe &
\mpb[.4]
Verteilung von $Y$\\
$\PP(Y=y_i)=\sum_i p_{i,j}=:p_{\cdot,j}$\\
\begin{tabular}{c | c c c c}
$y_i$ & 0 & 1 & 2 & 3\\\hline
$p_{\cdot,j}$ & 0,6 & 0,31 & 0,08 & 0,01
\end{tabular}
\mpe
\end{tabular}
\end{itemize}

\cparagraph{Bemerkung} Mit der gemeinsamen Verteilung (Dicht, WK-Funktion) lassen sich z.B.
\begin{enumerate}
\item WKen berechnen und
\item Funktionen von ZVen untersuchen.
\end{enumerate}
Seien $X$ und $Y$ ZVen mit gemeinsamer Dichte $f$, dann gilt z.B.:
\begin{enumerate}
\item $\PP(X\in [x_1, x_2], Y\in [y_1, y_2]) = \PP(x_1\leq X \leq x_2, y_i \leq Y \leq y_2)$\\
$\int\limits_{x_1}^{x_2}\int\limits_{y_1}^{y_2} f(s,t) \intd{t}\intd{s}$
\item und für beliebige $g: \RR^2 \to \RR$:\\
$E(g(X,Y)) = \int\limits_\RR\int\limits_\RR g(x,y) f(x,y) \intd{y}\intd{x}$\\
(sofern die Integrale existieren)\\
Insbesondere:\\
$E(X\cdot Y) = \int\limits_{-\infty}^{\infty}\int\limits_{-\infty}^{\infty}x\cdot y f(x,y) \intd{y}\intd{x}$
\end{enumerate}
Analoge Formeln gelten für diskrete ZVen mit der WK-Funktion $f$, z.B. 
$$E(X\cdot Y)=\sum_i \sum_j x_i y_j f(x_i, y_j)$$
falls $X$ die Werte $x_1, x_2, \dots$ annimmt und $Y$ die Werte $y_1, y_2, \dots$.

\cparagraph{Definition} Seien $X$ und $Y$ zwei ZVen. Dann heißen
\begin{anumerate}
\item $\cov(X,Y) = \EE((X-\EE X) ( Y - \EE Y)) = \EE (XY) - \EE X \cdot \EE Y$ die \emph{Kovarianz} von $X$ und $Y$.
\item $\varrho_{X,Y}:=\frac{\cov(X,Y)}{\sqrt{\var(X)}\sqrt{\var(Y)}}$ der \emph{Korrelationskoeffizient}.
\item $X$ und $Y$ \emph{unkorreliert}, wenn $\varrho_{X,Y}=0$ (also wenn $\cov(X,Y) = 0$)
\end{anumerate}

\cparagraph{Definition} Zwei ZVen $X$ und $Y$ heißen (stochastisch) unabhängig, falls für beliebige Intervalle $I_1, I_2 \subseteq \RR$ gilt:
$$\PP(X\in I_1, Y\in I_2)=\PP(X\in I_1) \cdot \PP(Y \in I_2)$$
Mehrere ZVen $X_1, X_2, \dots$ heißen (stochastisch) unabhängig, falls für jede Auswahl $X_{k_1}, \dots , X_{k_m}$ und beliebige Intervalle $I_1, \dots, I_m$ gilt:
$$\PP(X_{k_1}\in I_1 , \dots , X_{k_m}\in I_m)=\prod_{i=1}^m \PP(X_{k_i}\in I_i)$$

\cparagraph{Bemerkung}
\begin{itemize}
\item $X$ und $Y$ stochastisch unabhängig $\Leftrightarrow$ für beliebige Intervalle $I_1$ und $I_2$ sind $\{x\in I_1\}$ und $\{ Y \in I_2\}$ stochastisch unabhängig.
\item $X$ und $Y$ unabhängig $\Rightarrow \EE(XY)=\EE X \cdot \EE Y$
\item $X$ und $Y$ unabhängig $\Rightarrow X$ und $Y$ unkorreliert
\item ABER: $X$ und $Y$ unkorreliert $\not\Rightarrow X$ und $Y$ unabhängig
\item $\cov(X,X) = \var(X)$
\end{itemize}

\cparagraph{Beispiel} (Tetraeder-Würfel)\\
Ein Tetraeder ist mit den Zahlenpaaren $\Omega=\{(1,2),(0,2),(2,1),(0,0)\}$ beschriftet. Jede Seite ist gleich-wahrscheinlich. Die ZV $X$ beschreibt die erste Zahl, $Y$ die Zweite (im Zahlenpaar).\\
Dann:\\
$\PP(X=0)=\tfrac{1}{2}$, $\PP(X=1)=\tfrac{1}{4}$, $\PP(X=2) = \tfrac{1}{4}$,\\ $\PP(Y=0) = \tfrac{1}{4}$,
$\PP(Y=1) = \tfrac{1}{4}$, $\PP(Y=2) = \tfrac{1}{2}$, \\$\PP(X\cdot Y=0) = \tfrac{1}{2}$, $\PP(X\cdot Y = 2) = \tfrac{1}{2}$\\
Und damit:\\
$\EE(X)=0\cdot \frac{1}{2}+1 \cdot \frac{1}{4}+2\cdot \frac{1}{4}=\frac{3}{4}$\\
$\EE(Y)=\frac{5}{4}$\\
$\EE(XY)=1$\\
$\cov(X,Y)=\EE(XY)-\EE(X)\cdot \EE(Y)=1-\frac{3}{4}\cdot\frac{5}{4}=\frac{1}{16}$\\
$\Rightarrow X$und $Y$ nicht unkorreliert\\
$\Rightarrow$ nicht unabhängig\\
z.B. $\underbrace{\PP(X=1)}_{\tfrac{1}{4}}\cdot \underbrace{\PP(Y=0)}_{\tfrac{1}{4}} \not = \underbrace{\PP(X=1,Y=0)}_{0}$
\cparagraph{Satz} Seien $X$ und $Y$ ZVen und $a,b\in \RR$. Dann gilt:
\begin{itemize}
\item $\EE(aX+bY)=a\EE(X)+b\EE(Y)$
\item $\var(X\pm Y) = \var(X)+\var(Y)\pm \cov(X,Y)$
\item $\cov(aX+bY,Z)=a\cov(X,Z)+b\cov(Y,Z)$
\item $\cov(X,Y)=\cov(Y,X)$
\end{itemize}

\cparagraph{Bemerkung} (zu $\varrho_{X,Y}$)
\begin{itemize}
\item $\varrho_{X,Y} \in [-1,1]$
\item $\varrho_{X,Y}$ ist ein Maß für den linearen Zusammenhang zwischen $X$ und $Y$
\item Extremfälle:\\
$\varrho_{X,Y}=\begin{cases}
+1\\
-1
\end{cases} \Leftrightarrow Y=aX+b$ mit $\begin{cases}
a > 0\\
a < 0
\end{cases}$\\
Hier gilt also jeweils ein streng linearer Zusammenhang.
\item Die Gerade $y=a_0+a_1 x$ mit $a_1 = \frac{\sigma_X}{\sigma_Y}\varrho_{X,Y}$, $a_0=\EE Y - a_1 \EE  X$ heißt Regressionsgerade $Y$ bezüglich $X$ (beste lineare Näherung).
\end{itemize} 

\section{Spezielle Verteilungen}
\subsection{Spezielle diskrete Verteilungen}
\subsubsection{Bernoulli Verteilung}
Die Vorstellung einer (un-)fairen Münze liefert eine sehr einfache Zufallsvariable:
\cparagraph{Definition} Eine ZV $X$ welche genau 2 Werte annehmen kann heißt Bernoulli-verteilt.
\cparagraph{Bemerkung}
\begin{itemize}
\item Die möglichen Werte von $X$ werden typischerweise $\{0,1\}$ genannt.
\item Schreibweise: $\PP(X=1)=p, \; \PP(X=0)=1-p=q$ und $X \sim \mathrm{Ber}(p)$
\item Erwartungswert: $\EE(X)=0\cdot q + 1 \cdot p = p$
\item Varianz: $\var (X) = \EE(X^2) - (\EE(X))^2 = 0^2 \cdot q + 1^2 \cdot p - p^2 = pq$
\item Standardabweichung: $\sigma_X=\sqrt{pq}$
\end{itemize}
ABB Skript
\cparagraph{Beispiel} Seien $X,Y \sim \mathrm{Ber}(p)$. Setze $Z_1:= X+Y$, $Z_2=X-Y$ unabhängig.
\begin{anumerate}
\item Wie sind $Z_1$ und $Z_2$ verteilt?
\item Sind $Z_1$ und $Z_2$ unkorreliert?
\item Sind $Z_1$ und $Z_2$ unabhängig?
\end{anumerate}
Lösung:
\begin{anumerate}
\item Mögliche Werte:\\
\begin{tabular}{c c | c c | l}
$X$ & $Y$ & $Z_1$ & $Z_2$ & mit WK\\\hline
0 & 0 & 0 & 0 & $\PP(X=0,Y=0)=\PP(X=0\cdot \PP(Y0=) = q^2$\\
0 & 1 & 1 & -1 & $qp$\\
1 & 0 & 1 & 1 & $pq$\\
1 & 1 & 2 & 0 & $p^2$
\end{tabular}\\
$\Rightarrow$ \begin{tabular}{r | c c c}
$z$ & 0 & 1 & 2\\\hline
$\PP(Z_1=z)$ & $q^2$ & $2pq$ & $p^2$
\end{tabular} \quad \begin{tabular}{r | c c c}
$z$ & -1 & 0 & 1\\\hline
$\PP(Z_2=z)$ & $pq$ & $p^2+q^2$ & $pq$
\end{tabular}\\
\begin{tabular}{l | c c c }
$z$ & -1 &  0 & 1\\\hline
$\PP(Z_1Z_2=z)$ & $pq$ & $p^2+q^2$ & $pq$
\end{tabular}
\item $\cov (Z_1,Z_2)=\EE(Z_1Z_2)-\EE(Z_1) \EE(Z_2) = 0$, denn: \\
$\EE(Z_1)=0\cdot q^2 + 1 \cdot 2 pq + 2 p^2 = 2p(q+p) = 2p$\\
$\EE(Z_2)=-pq+pq = 0 =\EE(Z_1Z_2)$\\
$\Rightarrow Z_1$ und $Z_2$ sind unkorreliert
\item Es müsste bspw. gelten $\underbrace{\PP(Z_1=0, Z_2=1)}_{0}=\underbrace{\PP(Z_1=0)}_{q^2} \underbrace{\PP(Z_2=1)}_{pq}$, ist aber falsch.\\
$\Rightarrow Z_1$ und $Z_2$ nicht unabhängig.
\end{anumerate}
\subsubsection{Binomialverteilung}
\cparagraph{Definition} Die ZV $X$ heißt binomialverteilt mit den Parametern $n$ und $p$ (wobei $n \in \NN, p\in [0,1]$), wenn sie die Werte $0,\dots, n$ mit den WKen
$$p_i=\PP(X=i)=\binom{n}{i}p^i (1-p)^{n-i}, \quad i=0,\dots ,n$$
annimmt.
\cparagraph{Bemerkung} 
\begin{itemize}
\item Kurschreibweise: $X \sim \mathrm{Bin}(n,p)$
\item Erwartungswert: $\EE(X)=np$
\item Varianz: $\var (X) = np (1-p)$
\end{itemize}
ABB Skript
\cparagraph{Satz} Sind $X_1, \dots , X_n$ unabhängige Bernoulliverteilte ZVen (alle mit Parameter $p$), dann 
$$X_1+X_2+\dots + X_n \sim \mathrm{Bin}(n,p)$$

\cparagraph{Beispiel} (Massenproduktion mit Ausschuss)\\
Ein Massenprodukt (Schokoriegel) mit einem Ausschussanteil von $3\%$ wird in 20er Packungen verkauft. Wie groß ist die WK, dass eine Packung maximal 2 Ausschussstücke enthält?\\
Lösung:\\
$X_i$ … ZV mit:\\
$X_i=1 $ … Schokoriegel $i$ in der Packung ist Ausschuss,\\
$X_i = 0 $ … Schokoriegel $i$ ist keine Ausschuss.\\
$Y=\sum_{i=1}^{20}X_i$\\
Wir wissen $X_i \sim \mathrm{Ber}(0,03)$\\
Annahme $X_i$ sind unabhängig.\\
$\overset{\text{Satz 1.3.6}}{\Longrightarrow} Y \sim \mathrm{Bin}(20,\; 0,03)$\\
Gesucht: $\PP(Y \leq 2)$
\begin{align*}
\PP(\leq 2)&= \PP(Y=0)+\PP(Y=1) + \PP(Y=2)\\
&= \binom{20}{0}\cdot 0,03^0 \cdot 0,97^0 + \binom{20}{1} 0,03^1 \cdot 0,97^{19} + \binom{20}{2} 0,03^2 \cdot 0,97^{18}\\
&= 0,979
\end{align*}

\subsubsection{Diskrete Gleichverteilung}

\cparagraph{Definition} Eine ZV $X$ genügt der diskreten Gleichverteilung auf der Menge $T=\{x_1,\dots,x_n\}$, falls sie nur Werte aus $T$ annehmen kann und 
$$\PP(X=x_1) = \dots = \PP(X=x_n) = \frac{1}{n}$$
gilt.

\cparagraph{Bemerkung}
\begin{itemize}
\item Kurzschreibweise: $X\sim U(T)$
\item Erwartungswert: $\EE(X)=\frac{1}{n}\sum_{i=1}^n x_i$
\item Varianz: $\var(X)=\EE(X^2)-(\EE(X))^2 = \frac{1}{n} \sum_{i=1}^n x_i^2+\left(\frac{1}{n}\sum_{i=1}^n x_i\right)^2$
\item Beispiel: faire Münze, fairer Würfel, …
\end{itemize}
ABB Skript

\cparagraph{Bemerkung} (Beziehung zum Laplace-Experiment)
\begin{itemize}
\item Wir betrachten ein Laplace-Experiment mit 
$$\Omega = \{\omega_1, \dots, \omega_n\}$$ 
und dem WK-Maß $\PP$, d.h. 
$$\PP(\{\omega_1\})=\dots= \PP(\{\omega_n\})=\frac{1}{n}$$
\item Die ZV $X:\Omega \to \RR, \; X(\omega) = \omega$ ist damit gleichverteilt. Denn: 
$$\PP(X=\omega_i)=\PP(\{\omega\in \Omega | X(\omega) = \omega_i\})=\PP(\omega_i)=\frac{1}{n}$$
\end{itemize}

\subsubsection{Hypergeometrische Verteilung}
\cparagraph{Definition} Eine ZV $X$ heißt Hypergeometrisch verteilt, mit ganzzahligen Parametern $N$, $M$ und $n$ ($0<M\leq N, 0 < n \leq N$), wenn sie nur die Werte $T=\{\max\{0,n+M-N\}, \dots, \min\{n,M\}\}$ annehmen kann und für jedes $m \in T$ gilt:
$$p_m:=\PP(X=m)=\frac{\binom{M}{n}\binom{N-M}{n-m}}{\binom{N}{n}}$$

\cparagraph{Bemerkung}
\begin{itemize}
\item Kurzschreibweise: $X\sim \mathrm{Hyp}(N,M,n)$
\item Erwartungswert und Varianz: $\EE(X)=n\frac{M}{N}$ und $\var (X)=n\frac{M}{N}\left(1-\frac{M}{N}\right) \frac{N-n}{N-1}$
\item Anwendung: Stichprobe ohne Zurücklegen (bspw. Qualitätskontrolle, Lotto)
\begin{itemize}
\item $N$ Objekte, davon $M$ mit bestimmten Merkmal (bspw. Ausschuss, Gewinnzahl)
\item $n$ Objekte werden entnommen
\item $X$ … Anzahl der Objekte unter den $n$ entnommenen, die das Merkmal besitzen
$$\Rightarrow X\sim \mathrm{Hyp}(N,M,n)$$
\end{itemize}
\end{itemize}
ABB Skript

\cparagraph{Beispiel} In einer Lostrommel befinden sich $20$ Lose, davon $5$ Gewinnlose. Jemand zieht $3$ Lose (ohne Zurücklegen). Wie groß ist die WK, dass sich darunter genau 2 Gewinnlose befinden?\\
Lösung:\\
$X$ … Anzahl der Gewinnlose unter den $3$ gezogenen.\\
Es gilt $X \sim \mathrm{Hy}(20,5,3)$. Daher 
$\PP(X=2)=\frac{\binom{5}{2}\binom{15}{1}}{\binom{20}{3}}=\frac{10 \cdot 15}{1140}=0,1316$

\cparagraph{Bemerkung} Wie kommt man darauf gerade diese Formel zu verwenden?\\
Idee: Modellierung als Laplace-Experiment.\\
$\Omega=\{\{a_1,a_2,a_3\}\;|\; a_i \not = a_j \text{ fals } i \not = j \text{ und }a_1, a_2, a_3 \in \{\underbrace{g_1, \dots, g_5}_{\text{Gewinnlose}}, \underbrace{n_1, \dots, n_{15}}_{\text{Nieten}}\}\}$ $\rightsquigarrow $ Elementarereignisse gleich-wahrscheinlich. Es gilt: $|\Omega|=\binom{20}{3}$.\\
Das Ereignis, das uns interessiert ist: \\
$A=\{\{a_1, a_2, a_3\}\in \Omega \;|\; \{a_1, a_2, a_3\} \text{ enthält genau 2 der }\{g_1, \dots,g_5\}\text{ und genau 1 der }\{n_1,\dots,n_{15}\}\}$\\
Es gilt nun $A=\{X=2\}$ und $|A| = \binom{5}{2}\cdot \binom{15}{1} \Rightarrow \PP(X=2) = \frac{\binom{5}{2}\binom{15}{1}}{\binom{20}{3}}$

\subsubsection{Geometrische Verteilung}
\cparagraph{Definition} Eine ZV $X$ heißt geometrisch verteilt mit dem Parameter $p\in (0,1)$, falls sie nur die Werte $1,2,\dots$ annehmen kann und 
$$p_m:=\PP(X=m)=p(1-p)^{m-1} \quad m=1,2,\dots$$
gilt.
\cparagraph{Bemerkung}
\begin{itemize}
\item Kurzschreibweise: $X\sim \mathrm{Geo}(p)$
\item Varianz: $\var(X)=\frac{1-p}{p^2}$
\item Anwendung: Anzahl der Versuche bis der erste Erfolg eintritt, bei hintereinander ausführen von unabhängigen identischen Bernoulli Zufallsexperimenten.
\end{itemize}
ABB Skript

\cparagraph{Beispiel} Der Postbote hat ein Paket für Petra bei ihrem Nachbarn abgegeben. Petra klopft jeden Nachmittag an seine Tür. Leider ist er nur mit WK $0,3$ zu Hause. Annahme: Anwesenheiten des Nachbarn an verschiedenen Tagen sind unabhängig voneinander. 
\begin{anumerate}
\item Wie groß ist die WK, dass Petra ihr Paket erst beim 5. Klingeln bekommt?
\item Wie groß ist die WK, dass Petra ihr Paket spätestens beim 5. Klingeln bekommt?
\item Wie viele Tage muss sie im Mittel warten, bis sie ihren Nachbarn antrifft?
\end{anumerate} 
Lösung:\\
$Y$ sei die ZV, die beschreibt, ob Petra ihren Nachbarn am $i$-ten Tag antrifft:\\
$\{Y_i=1\}$ … sie trifft ihn am $i$-ten Tag an\\
$\{Y_i=0\}$ … sie trifft ihn am $i$-ten Tag nicht an\\
laut Voraussetzung: $Y_i \quad i=1,2, \dots$ sind unabhängig und $\PP(Y_i=1) = 0,3 = 1-\PP(Y_i=0)$\\
Wir führen also unabhängige, identische Bernoulli-Zufallsexperimente aus und fragen uns nach dem ersten Erfolg.

\begin{anumerate}
\item gesucht: \begin{align*}
\PP(Y_1=0, \ldots, Y_4=0, Y_5=1) &= \PP(Y_1=0) \cdot \ldots \cdot \PP(Y_4=0) \cdot \PP(Y_5=1) \\
&= 0,7 ^4 \cdot 0,3 \\
&= 0,07203
\end{align*}
Setzen wir $X$ … Tag an dem der erste „Erfolg“ eintritt, so gilt $\PP(X=5)=0,7^4\cdot 0,3$\\
Allgemein gilt $P(X=m)=0,7^{m-1}\cdot 0,3 \Rightarrow X$ ist geometrisch verteilt mit Parameter $p=0,3$.
\item Gesucht:
\begin{align*}
\PP(X\leq 5)&=\PP(\{X=1\}\cup \{X=2\} \cup \{X=3\} \cup \{X=4\} \cup \{X=5\}) \\
&= \PP(X=1) + \ldots + \PP(X=5) \\
&= 0,7^0\cdot 0.3 + 0,7^1 \cdot 0.1 + \ldots + 0,7^4 \cdot 0,3 \\
&= (0,7^0+\ldots+0,7^4)\cdot 0,3 ) \\
&= 0,8919
\end{align*}
Diese Rechnung funktioniert für beliebiges $m$. Daher gilt: 
$$F_X(m)=\PP(X\leq m) = 0,3 \sum_{i=0}^{m-1}0,7^i=0,3 \frac{1-0,7^m}{1-0,7}=1-0,7^m$$
\item Gesucht: $\EE(X)=\frac{1}{0,3}=\frac{10}{3}$\\
$\Rightarrow$ erwartete Wartezeit ist $3,\bar{3}$ Tage.
\end{anumerate}

\cparagraph{Bemerkung} Für eine geometrisch verteilte ZV $X$ mit Parameter $p$ gilt 
$$F_X(m)=\PP(X\leq m) = 1-(1-p)^m$$
für $n \in \NN_0$. Dazwischen ist $F_X$ konstant.

\subsubsection{Poisson-Verteilung}
\cparagraph{Definition} Eine ZV $X$ heißt Poisson-verteilt mit dem Parameter $\lambda >0$, falls sie nur die Werte $0,1,2,\dots$ annehmen kann und 
$$p_m:=\PP(X=m)=\frac{\lambda^m}{m!}e^{-\lambda} \quad m=0,1,2,\dots$$
\cparagraph{Bemerkung} 
\begin{itemize}
\item Kurzschreibweise: $X\sim \mathrm{Poi}(\lambda)$
\item Erwartungswert: $\EE(X)=\lambda$
\item Varianz: $\var(X)=\lambda$
\item Anwendung: Bedientheorie, Zuverlässigkeitstheorie
\begin{itemize}
\item Anzahl der Kunden pro Zeiteinheit
\item Anzahl der Störungen im Produktionsprozess eines Betriebs pro Zeiteinheit
\end{itemize}
\end{itemize}

\cparagraph{Beispiel} In einer Fließbandanlage tritt im Durchschnitt alle $5$ Stunden eine Störung auf (d.h. im Mittel $0,2$ Störungen pro Stunde). Die Zahl der Störungen in einer bestimmten Zeiteinheit kann als Poissonverteilt angenommen werden.\\
Wie groß ist die WK, dass in einer 8-Stunden-Schicht mehr also 2 Störungen auftreten?\\
Lösung:\\
$X$… Anzahl der Störungen in 8 Stunden
\begin{itemize}
\item $X\sim \mathrm{Poi}(\lambda)$ mit $\EE X = 8 \cdot 0,2 = 1,6 = \lambda$
\begin{align*}
\Rightarrow \PP(X >2) &= 1- \PP(X\leq 2) \\
&= 1- \PP(X=0) - \PP(X=1) - \PP(X=2)\\
&= 1-e^{-1,6}\left(\frac{1,6^0}{0!}+\frac{1,6^1}{1!}+\frac{1,6^2}{2!}\right)\\
&= 0,2166
\end{align*}
\end{itemize}

\subsection{Spezielle stetige Verteilungen}

\begin{enumerate}[label=(D\arabic*)]
\item stetige Gleichverteilung (Bus-Beispiel)
\item Normalverteilung (Zentraler Grenzwertsatz $\to$ wichtig!)
\item Exponentialverteilung
\item $\chi^2$-Verteilung (Chi-Quadradt-Verteilung)
\item $t$-Verteilung
\item $F$-Verteilung
\end{enumerate}
S4-S5 vor allem für Statistik relevant
\subsubsection{Stetige Gleichverteilung}
\cparagraph{Definition} Eine ZV $X$ heißt stetig gleichverteilt auf dem Intervall $I\subset \RR$, falls für alle Intervalle $J \subset I$ gilt:
$$\PP(X\in J)=\frac{|J|}{|I|}$$
\cparagraph{Bemerkung}
\begin{itemize}
\item Kurzschreibweise: $X \sim U(I)$
\item Sei $a<b$. Ein Intervall $I$ kann die Form $(a,b),\;[a,b],\;[a,b)$ oder $(a,b]$ haben. Dann gilt $|I|=b-a$. Ist $I$ von dieser Form, so gilt:
\item $\EE(X)=\frac{a+b}{2}$, $\var(X)=\frac{1}{12}(b-a)^2$
\item Dichte und Verteilungsfunktion:
$$f(x)=\begin{cases}
\frac{1}{b-a} & a\leq x \leq b\\
0 & \mathrm{sonst}
\end{cases}, \quad F(x)=\begin{cases}
0 & x \leq a\\
\frac{x-a}{b-a} & a<x<b\\
1 & x \geq b
\end{cases}$$
\end{itemize}
ABB Skript
\subsubsection{Normalverteilung}
\cparagraph{Definition} Eine ZV $X$ heißt normalverteilt mit den Parametern $\mu$ und $\sigma^2$, ($\mu \in \RR, \; \sigma > 0$, wenn sie die Dichte
$$f: \RR\to \RR, \qquad f(x)=\frac{1}{\sqrt{2\pi\sigma}}\exp\left(-\frac{(x-\mu)^2}{2\sigma^2}\right)$$
besitzt.

\cparagraph{Bemerkung}
\begin{itemize}
\item Kurzschreibweise: $X\sim \cN(\mu, \sigma^2)$
\item $\EE(X)=\mu$
\item $\var(X) = \sigma^2$
\item Verteilungsfunktion nicht in geschlossener Form angebbar (nur als Integraldarstellung oder unendliche Reihe)
\end{itemize}
ABB Skript

\cparagraph{Satz} Gilt $X\sim \cN(\mu, \sigma^2)$, dann gilt für die transformierte ZV
$$Y=\frac{X-\mu}{\sigma} \sim \cN (0,1)$$
Wir sagen dann: $Y$ ist standardnormalverteilt.

\cparagraph{Bemerkung} Für $Y \sim \cN (0,1)$ gilt:
\begin{itemize}
\item für die Verteilungsfunktion
\begin{align*}
\Phi(x):=F_Y(x)&=\frac{1}{\sqrt{2\pi}}\int\limits_{-\infty}^x \exp\left(-\frac{t^2}{2}\right)\intd{t}\\
&= 0,5 + \frac{1}{\sqrt{2\pi}}\int\limits_0^x \exp\left(-\frac{t^2}{2}\right)\intd{t}
\end{align*}
\item Werte von $\Phi$ lassen sich Tabellen oder Software entnehmen.
\item Jede beliebige Normalverteilung lässt sich auf die Standardnormalverteilung $\Phi$ zurückführen.
\item Symmetrie: $\Phi(-x)=1-\Phi(x)$
\end{itemize}

\cparagraph{Bemerkung} Für $X \sim \cN(\mu, \sigma^2)$ gilt:
\begin{itemize}
\item $F_X(x) = \PP(X\leq x) = \Phi \left(\frac{x-\mu}{\sigma}\right)$
\item $\PP(X\geq a) = 1 - \Phi \left(\frac{a-\mu}{\sigma}\right)$
\item $\PP(a\leq X\leq b)=\Phi \left(\frac{b-\mu}{\sigma}\right)-\Phi \left(\frac{a-\mu}{\sigma}\right)$
\item $\PP(X=a)=0$
\item Anwendung:
\begin{itemize}
\item Messfehler
\item geometrische und physikalische  Kenngrößen von Produkten (Länge, Masse, Widerstand, …)
\item biologische Merkmale
\item allgemein: Summe großer Anzahl von unabhängigen Größen
\end{itemize}
\end{itemize}

\cparagraph{Beispiel} (Drehteil) Ein Drehteil besitzt einen Soll-Durchmesser von $500\unit{mm}$. Die Toleranzgrenzen sind $499,6\unit{mm}$ und $500,3 \unit{mm}$.\\
Die von der Maschine hergestellten Teile besitzen in Wirklichkeit (statistisch überprüft) einen normalverteilten Durchmesser mit $\mu=500$ und $\sigma = 0,2$.\\
Wie groß ist die WK, dass ein solches Teil…
\begin{anumerate}
\item innerhalb der Toleranzgrenzen liegt?
\item einen Durchmesser kleiner als die untere Toleranzgrenze hat?
\item Wie genau muss die Maschine arbeiten (also wie groß darf $\sigma$ sein) damit maximal $1\%$ der produzierten Teile einen Durchmesser von maximal $499,6\unit{mm}$ haben?
\end{anumerate}
Lösung:\\
$X$ … Durchmesser in $\unit{mm}$\\
dann $X \sim \cN(500,\; 0,2^2)$.
\begin{anumerate}
\item 
\begin{align*}
\PP(499,6 \leq X \leq 500,3)&=\Phi \left(\frac{500,3-500}{0,2}\right)-\Phi \left(\frac{499,6-500}{0,2}\right)\\
&=\Phi(1,5)-\Phi(-2)\\
&= \Phi (1,5)-(1-\Phi(2))\\
&= \Phi(1,5)+\Phi(2)-1\\
&= 0,93319+0,97725-1 &&|\;\mathrm{Tabelle}\\
&= 0,91044\\
&\approx 91\%
\end{align*}
\item $\PP(X<499,6) = \Phi\left(\frac{499,6-500}{0,2}\right) = 1-\Phi(2)=1-0,97725=0,02275$
\item Nun ist $\sigma$ unbekannt. Also:\\
$X\sim \cN(500, \sigma^2)$\\
Wir suchen $\sigma$ mit 
\begin{align*}
0,01\geq\PP(X<499,6) &= \Phi\left(\frac{499,6-500}{\sigma}\right)\\
&=\Phi\left(\frac{-0,4}{\sigma}\right)\\
&=1-\Phi\left(\frac{0,4}{\sigma}\right)\\
\Leftrightarrow 0,01 &\overset{!}{=}1-\Phi\left(\frac{0,4}{\sigma}\right)\\
\Leftrightarrow \Phi\left(\frac{0,4}{\sigma}\right) &= 0,99\\
\Leftrightarrow \frac{0,4}{\sigma}&=\Phi^{-1}(0,99) =:z_{0,99} && 0,99\mathrm2{-Quantil}\\
z_{0,99}&=2,326 && |\; \mathrm{Tabelle}\\
\Rightarrow \sigma &=0,172
\end{align*}
Bei ein Standardabweichung von max. $0,172$ wird im Mittel höchstens $1\%$ Ausschuss produziert.
\end{anumerate}

\cparagraph{Bemerkung} Sei $\Phi$ die Verteilungsfunktion zur Standard-Normalverteilung.
\begin{itemize}
\item Für $\alpha \in (0,1)$ benötigt man oft $\Phi^{-1}(\alpha)$.\\
Dies ist das $\alpha$-Quantil $q_\alpha$.
\item Im Fall der Normalverteilung schreibt man oft $q_\alpha = z_\alpha \quad\Big(=\Phi^{-1}(\alpha)\Big)$.
\item Die Werte $z_\alpha$ entnimmt man einer Tabelle (o.ä.).
\item $z_\alpha = - z_{1-\alpha}$
\end{itemize}

\subsubsection{Exponentialverteilung}
\cparagraph{Definition} Die ZV $X$ heißt exponentialverteilt mit dem Parameter $\lambda >0$, wenn sie die folgende Dichte besitzt:
$$f(x)=\begin{cases}
\lambda \exp(-\lambda x) & \mathrm{falls} \; x\geq 0\\
0 & \mathrm{sonst}
\end{cases}
$$
\cparagraph{Bemerkung}
\begin{itemize}
\item Kurzschreibweise: $X\sim \mathrm{Exp}(\lambda)$
\item $\EE(X)=\frac{1}{\lambda}, \quad \var(X)=\frac{1}{\lambda^2}$
\item Verteilungsfunktion:
$$F(x)=\begin{cases}
1-\exp(-\lambda x) & \mathrm{falls}\; x \geq 0\\
0 & \mathrm{sonst}
\end{cases}$$
\item Anwendung: Bedientheorie, Zuverlässigkeitstheorie, Verteilung von Zeitdauern wie Lebenszeiten, Reperaturzeiten, Wartezeiten, …
\end{itemize}

\cparagraph{Beispiel} (Parallelschaltung) Ein System besteht aus 3 unabhängig voneinander arbeitenden, parallel geschalteten Elementen. Es sei bekannt, dass die Lebensdauer der einzelnen Elemente exponentialverteilt ist. Die mittlere Lebensdauer eines Elementes ist $ 1000\unit{[h]} $
\begin{anumerate}
	\item Wie groß ist die WK, dass Element 1 höchstens $ 500\unit{Std.} $ funktioniert?
	\item Wie groß ist die WK, dass das System mindestens $ 500 \unit{Std} $ funktioniert?
	\item Für welchen Zeitraum beträgt die Zuverlässigkeit des Systems $ 99\% $
\end{anumerate}
Lösung:\\
$ X_i $ … zufällige Lebensdauer von Element $ i, \; i=1,2,3 $\\
$ \Rightarrow X_i \sim \exp(\lambda), \; \EE(X_I)=\frac{1}{\lambda}=1000 \Rightarrow \lambda=\frac{1}{1000} $
\begin{anumerate}
	\item ges.: $ \underbrace{\PP(X_1 \leq 500)}_{F_{X_1}(500)} = 1-\exp\left(-\frac{1}{1000}\cdot 500\right)=1-\exp\left(-\frac{1}{2}\right) = 0,3935 $
	\item $ X $ … Lebensdauer des Systems\\
	$ X=\max(X_1,X_2,X_3) $\\
	Wie ist $ X $ verteilt?
	\begin{align*}
	F_X(x)&=\PP(X\leq x)=\PP(\max(X_1,X_2,X_3)\leq x)\\
	&=\PP(\{X_1 \leq x\} \cap \{X_2 \leq x\} \cap \{X_3 \leq x\} )\\
	&=\PP(X_1 \leq x) \cdot \PP(X_2 \leq x) \cdot \PP(X_3 \leq x)\\
	&= \left(1-\exp\left(-\frac{1}{1000}x\right)\right)^3 \qquad \text{für alle }x\geq 0
	\end{align*}
	gesucht: 
	\begin{align*}
	\PP(X\geq 500) &= 1-\PP(X\leq 500)\\
	&=1-\left(1-\exp\left(-\frac{500}{1000}\right)\right)^3\\
	&=0,9391
	\end{align*}
	\item gesucht: Zeit $ t $, so dass $ X\geq t $ mit WK von mind. $ 0,99 $. Also: $ 0,99 \leq \PP(X\geq t) $
	\begin{align*}
	&&0,99 &= \PP(X\geq t)\\
	\Leftrightarrow&& 0,99 &= 1-F_X (t)\\
	\Leftrightarrow&& F_X(t) &= 0,01\\
	\Leftrightarrow&& \left(1-\exp\left(-\frac{t}{1000}\right)\right)^3 &=0,01\\
	\Leftrightarrow&& t &= 242,6 \unit{h}
	\end{align*}
\end{anumerate}

\subsubsection{\texorpdfstring{$ \chi^2 $}{Chi-Quadrat}-Verteilung}

\cparagraph{Definition} Eine stetige ZV heißt $ \chi^2 $-verteilt mit $ n \in \NN $ Freiheitsgraden, falls $ X $ die Diche 
$$f_n(x)=\begin{cases}
\frac{x^{\frac{n}{2}-1}\exp\left(-\frac{x}{2}\right)}{2^{\frac{n}{2}}\Gamma\left(\frac{n}{2}\right)} & \text{falls }x>0\\
0 & \text{sonst}
\end{cases} \quad (x\in \RR)$$
besitzt. Hier ist $\Gamma$ die Gammafunktion, d.h. $\Gamma(x):= \int\limits_{0}^{\infty}t^{x-1}e^{-t}\intd{t}$ für $x>0$.

\cparagraph{Bemerkung}
\begin{itemize}
	\item Kurzschreibweise: $X\sim \chi^{2}$(n)
	\item $\EE(X)=n$, $\var(X)=2n$
	\item Verteilungsfunktion zeigen wir hier nicht (lässt sich mittels Gammafunktion darstellen)
	\item Quantile: Ist $\alpha\in (0,1)$ und $F_X$ die Verteilungsfunktion zu $X \sim \chi^{2}(n)$, so bezeichnen wir das $\alpha$-Quantil $q_\alpha$ mit $\chi^{2}_{n,\alpha}=q_{\alpha}=F_X^{-1}(\alpha)$
	\item Anwendung: Statistik, insbesondere Testtheorie
\end{itemize}
%todo Abb Skript

Ein Grund für die große Bedeutung der $ \chi^2 $-Verteilung (in der Statistik) ist:
\cparagraph{Satz} Seien $ X_1, X_2, \ldots, X_n $ unabhängige standard-normalverteilte ZVen. Dann ist 
$$ X:=X_1^{2} + X_2^{2}+\ldots + X_n^{2} $$
$ \chi^{2} $-verteilt mit $ n $ Freiheitsgraden.

\subsubsection{\texorpdfstring{$ t $}{t}-Verteilung}

\cparagraph{Definition} Eine stetige ZV $X$ heißt $t$-verteilt mit $n\in \NN$ Freiheitsgraden, falls $X$ die Dichte 
\[ f_n(x)=\frac{\Gamma\left(\frac{n+1}{2}\right)}{\sqrt{n \pi}\Gamma\left(\frac{n}{2}\right)}\left(1+\frac{x^2}{n}\right)^{-\frac{n+1}{2}} \quad (x\in \RR) \]
besitzt. Hier ist $\Gamma$ wieder die Gammafunktion.

\cparagraph{Bemerkung}
\begin{itemize}
	\item Kurzschreibweise: $X\sim t(n)$
	\item falls $n>1$: $\EE(X)=0$, für $n=1$ existiert $\EE(X)$ nicht
	\item falls $n>2$: $\var(X)=\frac{n}{n-1}$, für $n=1,2$ existiert $\var(X)$ nicht
	\item Verteilungsfunktion zeigen wir nicht (lässt sich mittels Betafunktion darstellen)
	\item Quantile: Ist $\alpha \in (0,1)$ und $F_X$ die Verteilungsfunktion zu $X\sim t(n)$, so bezeichnen wir das $\alpha$-Quantil $q_\alpha$ mit $t_{n,\alpha}=q_\alpha=F_{X}^{-1}(\alpha)$
	\item Anwendung: Statistik, insbesondere Testtheorie
\end{itemize}

Ein Grund für die große Bedeutung der $ t $-Verteilung (in der Statistik) ist:
\cparagraph{Satz} Seien $ Y $ und $ Z $ unabhängige ZVen mit $ Y\sim \chi^{2} (n) $ und $ Z \sim \cN(0,1) $. Dann ist 
\[ X=\frac{Z}{\sqrt{\frac{Y}{n}}} \]
$ t $-verteilt mit $ n $ Freiheitsgraden.

\subsubsection{\texorpdfstring{$ F $}{F}-Verteilung}

\cparagraph{Definition} Eine stetige ZV $X$ heißt $F$-verteilt mit $m\in \NN$ Freiheitsgraden im Zähler und $n\in \NN$ Freiheitsgraden im Zähler, falls $X$ die Dichte
\[ f_{m,n}(x)=\begin{cases}
m^{\frac{m}{2}}n^{\frac{n}{2}}\frac{\Gamma\left(\frac{m}{2}+\frac{n}{2}\right)}{\Gamma\left(\frac{m}{2}\right)\Gamma\left(\frac{n}{2}\right)}\cdot \frac{x^{\frac{m}{2}-1}}{(mx+n)^{\frac{m+n}{2}}} & \text{falls }x\geq 0\\
0 & \text{sonst}
\end{cases} \] 
besitzt. Hier ist $\Gamma$ wieder die Gammafunktion.
\cparagraph{Bemerkung}
\begin{itemize}
	\item Kurzschreibweise: $X\sim F(m,n)$
	\item falls $n>2$: $\EE(X)=\frac{n}{n-2}$, für $n=1,2$ existiert $\EE(X)$ nicht
	\item falls $n>4$: $\var(X)=\frac{2n^2(m+n-2)}{m(n-2)^2(n-4)}$, für $n=1,2,3,4$ existiert $\var(X)$ nicht
	\item Quantile: Ist $F_X$ die Verteilungsfunktion zu $X\sim F(m,n)$, so bezeichnen wir das $\alpha$-Quantil $q_\alpha$ mit $F_{m,n,\alpha}=q_\alpha=F_{X}^{-1}(\alpha)$
	\item Anwendung: Statistik, insbesondere Testtheorie
\end{itemize}

Ein Grund für die große Bedeutung der $ F $-Verteilung (in der Statistik) ist:
\cparagraph{Satz} Seien $ Y $ und $ Z $ unabhängige ZVen mit $ Y\sim \chi^{2} (m) $ und $ Z \sim \chi^{2}(n) $. Dann ist 
\[ X=\frac{\frac{Z}{m}}{\frac{Z}{n}}\sim F(m,n) \text{.} \]
\section{Grenzwertsätze}

Wir betrachten nun Folgen von ZVen $X_1, X_2, X_3, \ldots$

\cparagraph{Definition} Sind $X_1, X_2, \ldots$ ZVen, welche alle die gleiche Verteilungsfunktion haben, so sagen wir „die ZV sind \emph{identisch verteilt}“.

\subsection{Gesetz der Großen Zahlen}
\cparagraph{Beispiel} Wir werfen eine faire Münze $n$ mal und zählen die Ereignisse „Kopf“ und „Zahl“:\\
\begin{tabular}{c | c | c | c}
	$n$ & Anzahl Kopf & Anzahl Zahl & rel. Anz. Kopf\\\hline
	$50$ & $22$ & $28$ & $0,44$\\
	$200$& $89$& $111$ & $0,445$\\
	$1000$ & $493$& $507$& $0,493$\\
	$100\,000$& $50\,256$&$49\,744$& $0,50256$
\end{tabular}\\
Die relative Anzahl Kopf nähert sich anscheinend der $0,5$ immer weiter an.\\
Diesen Zusammenhang formalisiert das Gesetz der großen Zahlen.

\cparagraph{Satz} Seien $X_1, X_2, \ldots$ unabhängige und identisch verteilte ZVen mit Erwartungswert $\mu$ und Varianz $\sigma^{2}$ und sei
\[ \overline{X_n}=\frac{1}{n}\cdot (X_1 + \ldots + X_n) \]
das arithmetische Mittel der ersten $n$ ZVen.\\
Dann gilt für jede (noch so kleine) Zahl $\varepsilon >0$
\[ \lim_{n\to \infty} \PP(|\overline{X_n}) -\mu| < \varepsilon) = 1 \text{.}\]
Insbesondere gilt
\[ \PP(|\overline{X_n}-\mu | < \varepsilon)\geq 1-\frac{\sigma^{2}}{n \cdot \varepsilon^{2}} \text{.} \]

Um zu verstehen, warum das GdgZ gilt benötigen wir die folgende Ungleichung:

\cparagraph{Satz} (Tschebyschew-Ungleichung) Sei $X$ eine ZV so dass $\var(X)$ existiert: Dann gilt für beliebiges $a>0$:
\[ \PP(|X-\EE X| \geq a) \leq \frac{\var(X)}{a^{2}} \text{.} \]

\cparagraph{Bemerkung} Die $T$-Ungleichung liefert eine obere Schranke an die WK, dass eine ZV um einen Mindestabstand $a$ von ihrem Erwartungswert abweicht.\\
Die Schranke ist klein, falls
\begin{itemize}
	\item $a$ groß ist
	\item $\var(X)$ klein ist
\end{itemize}

\begin{proof}
Sei also $X_1, X_2$ unabhängig identisch verteilt mit Erwartungswert $\mu$ und Varianz $\sigma^2$ und sei $\overline{X}_n=\frac{1}{n}\sum_{i=1}^nX_i$. Dann gilt:
$$ \EE(\overline{X}_n)=\EE\left(\frac{1}{n}\sum_{i=1}^nX_i\right) = \frac{1}{n}\sum_{i=1}^n\underbrace{\EE X_i}_\mu = \mu$$
und wegen der Unabhängigkeit gilt auch:
$$\var(\overline{X}_n)=\var\left(\frac{1}{n}\sum_{i=1}^n X_i\right) = \frac{1}{n^2}\var\left(\sum_{i=1}^nX_i\right) \overset{\substack{\text{da}\\\text{unabh.}}}{=}\frac{1}{n^2}\sum_{i=1}^n \var(X_i)=\frac{\sigma^2}{n}$$
Nun wenden wir Tschebyschew an:
$$\underbrace{\PP(|\overline{X}_n-\EE \overline{X}_n|\geq \varepsilon)}_{\PP(|\overline{X}_n-\mu|\geq \varepsilon)}\leq \underbrace{\frac{\var(\overline{X}_n)}{\varepsilon^2}}_{\frac{\sigma^2}{n \varepsilon^2}}$$
$$\PP(|\overline{X}_n-\mu| < \varepsilon) = 1-\PP(|\overline{X}_n-\mu | \geq \varepsilon) \geq 1-\frac{\sigma^2}{n\varepsilon^2}\overset{n\to \infty}{\longrightarrow} 1$$
\end{proof}

\cparagraph{Beispiel} Gegeben: unabhängige Poisson-verteilte ZVen mit $X_i \sim \mathrm{Poi}(3)$ für alle $i$\\
$\Rightarrow\EE (X_i) = 3 = \var(X_i)$ für alle $i$\\
$\Rightarrow$ für $\varepsilon = 0,1$ und $n=5000$ gilt $\PP(|\overline{X}_n-3|<0,1) \geq 1-\frac{3}{5000-0,1^2}=0,94$ 

\subsection{Der zentrale Grenzwertsatz}

\cparagraph{Satz} (Zentraler Grenzwertsatz)\\
Seien $X_1, X_2, \ldots$ unabhängige und identisch verteilte Zufallsvariablen mit Erwartungswert $\mu$ und Varianz $\sigma^2$. Für $n\in \NN$ setzen wir
$$S_n=X_1+\ldots+ X_n\text{.}$$
Für die standardisierte Zufallsvariable
$$Z_n=\frac{S_n-\EE S_n}{\sqrt{\var S_n}}=\frac{S_n - n \mu}{\sqrt{n}\cdot \sigma}$$
gilt dann
$$\lim_{n\to \infty} \underbrace{\PP(Z_n \leq z)}_{F_{Z_n}(z)} = \Phi (z) \qquad (z \in \RR)$$
wobei $\Phi$ (wie immer) die Verteilungsfunktion der Standardverteilung ist.

\cparagraph{Bemerkung} 
\begin{itemize}
\item Der Satz sagt aus, dass für großes $n$ die ZV $Z_n$ nahezu normalverteilt ist.
\item Wesentlich: es ist \emph{keine} Annahme über die Verteilung der $X_i$ gemacht.
\item mit $\overline{X}_n = \frac{1}{n}\sum_{i=1}^n X_i$ gilt
$$Z_n=\frac{S_n - n \mu}{\sqrt{n}\sigma} = \frac{\overline{X}_n - \mu}{\frac{\sigma}{\sqrt{n}}}$$
\item Sprechweise: „$Z_n$ ist asymptotisch/approximativ (standard-)normalverteilt.“
\item Schreibweise: Die Gleichung
$$\lim_{n\to \infty} \PP(Z_1 \leq z) = \Phi (z) \qquad (z \in \RR)$$
wird als 
$$Z_n \overset{a}{\sim}\cN (0,1)$$
abgekürzt. In diesem Sinne kann man auch 
$$S_n \overset{a}{\sim} \cN(n \mu, n \sigma^2) \text{ und } \overline{X}_n\overset{a}{\sim}\cN\left(\mu, \frac{\sigma^2}{n}\right)$$
verstehen.
\end{itemize}

\cparagraph{Beispiel} Wir werfen einen fairen Würfel mehrmals hintereinander.\\
$X_i$ … Ergebnis des $i$-ten Wurfs\\
$S_n = \sum_{i=1}^n X_i$ … Augensumme der ersten $n$ Würfe\\
ZGWS: $S_n \overset{a}{\sim} \cN (n \mu, n\sigma^2)$\\
$S_n$ ist asymptotisch normalverteilt mit Erwartungswert $n \cdot \mu =3,5$ und Varianz $n\sigma^2 = n \cdot 2,91\bar 6$, denn: \\
$\mu = \EE(X_n) = \frac{1}{6}(1+\ldots+6)=3,5$ und \\
$\sigma^2=\var(X_n)=\underbrace{\frac{1}{6}(1^2+\ldots + 6^2}_{\EE(X_n^2)}-\underbrace{3,5^2}_{(\EE X_n)^2}=2,91\bar 6$

\cparagraph{Beispiel} Es werden Schrauben mit einem zufälligen Gewicht mit EW $4\unit{g}$ und Standardabweichung $0,3\unit{g}$ hergestellt. Berechnen Sie mit dem ZGWS (unter Annahme der Unabhängigkeit):
\begin{anumerate}
\item WK, dass der inhalt einer Packung mit $200$ Schrauben maximal $795\unit{g}$ wiegt.\label{itm:1.4-10-a}
\item Welches Nettogewicht wird eine $200$er Packung mit WK $0,99$ überschreiten?\label{itm:1.4-10-b}
\end{anumerate}
Lösung:\\
$X_i$ … Gewicht der Schraube $i$ in Gramm, $i=1,\ldots, 200$\\
$S=\sum_{i=1}^{200} X_i$\\
$\Rightarrow \EE S = 800 \quad \var S = \var \left( \sum_{i=1}^{200} X_i\right)=\sum_{i=1}^{200} \underbrace{\var X_i}_{0,3^2} = 200 \cdot 0,09 = 18$

\begin{anumerate}
\item
\begin{align*}
\PP(S \leq 795) &= \PP( S - \EE S \leq 795 - \EE S) \\
&= \PP\left(\underbrace{\frac{S - \EE S}{\sqrt{\var S}}}_{Z}\leq \frac{795-\EE S}{\sqrt{ \var S}}\right)\\
&= \PP\left( Z \leq \frac{-5}{\sqrt{18}}\right)\\
&= \PP(Z \leq - 1,1785)\\
&\approx \PP(Z \leq - 1,18) \qquad \text{(runden)}\\
&\approx \Phi(-1,18) \qquad \text{(ZGWS)}\\
&= 1- \Phi(1,18) = 1-0,881 = 0,119
\end{align*}
Wahrscheinlichkeit ist etwa $20\%$.
\item Gesucht: Gewicht $a$ mit $\PP(S > a) = 0,99$
\begin{align*}
0,99 \overset{!}{=}& 1- \PP(S \leq a)\\
=& 1- \PP\left( \frac{S-\EE S}{\sqrt{\var S}} \leq \frac{a-\EE S}{\sqrt{\var S}}\right)\\
=& 1- \Phi\left(\frac{a-800}{\sqrt{18}}\right)\\
\Leftrightarrow 0,01 =& \Phi (\dots)\\
\Leftrightarrow \underbrace{\Phi^{-1} (0,01)}_{-2,3243} =& \frac{a-800}{\sqrt{18}}\\
\Leftrightarrow a =& 790,13
\end{align*}
\end{anumerate}

\cparagraph{Bemerkung}
Bei der Anwendung des ZGWS spielt oft die Gleichung
$$\PP(\sum_{i=1}^n X_i \leq a) = p$$
ein Rolle. Im Beispiel \ref{itm:1.4-10-a} war $p$ gesucht (mit $a$ und $n$ gegeben), in \ref{itm:1.4-10-b} war $a$ gesucht (mit $p$ und $n$ gegeben). 

Es könnte auch mal $n$ gesucht sein (siehe Hausaufgabe).\\
Spezialfall des ZWGS:
\cparagraph{Satz} (von Moivre-Laplace)\\
Gilt $S_n \sim \mathrm{Bin}(n,p)$, so gilt 
$$\lim_{n\to \infty} \PP\left( \frac{S_n - np}{\sqrt{np (1-p)}} \leq z \right) = \Phi(z)$$
bzw.
$$\frac{S_n - np}{\sqrt{np (1-p)}} \overset{a}{\sim} \cN(0,1)\text{.}$$

\cparagraph{Bemerkung}
\begin{itemize}
\item Satz sagt, dass für \emph{großes} $n$ nahezu $S_n \sim \cN(np, np(1-p))$ gilt.
\item \emph{Faustregel} für großes $n$:
$$np(1-p) \geq 9$$
\item Sind $X_1, X_2, \ldots$ unabhängig identisch Bernoulli-verteilte ZVen mit Parameter $p$, dann
$$\EE(X_1)=p, \quad \var (X_1) = p (1-p)$$
und
$$S_n = \sum_{i=1}^n X_i \sim \mathrm{Bin}(n,p)$$
Formel aus Satz 1.4-14 folgt jetzt aus ZGWS.
\end{itemize}

\cparagraph{Beispiel} Betrachten den $12\, 000$-fachen Münzwurf. Frage: Wie groß ist die WK, dass die Anzahl der Ergebnisse „Zahl“ weniger als $20$ vom Erwartungswert abweichen?\\
Lösung:\\
$S$ … Anzahl des Eintretens von Zahl bei $12\, 000$ Würfen\\
$\Rightarrow S\sim \mathrm{Bin}(12\,000,\; 0,5)$\\
$\overset{\text{Moivre-Laplace}}{\Longrightarrow} S \overset{a}{\sim} \cN (6\,000, 3\,000)$\\
Es gilt: $\EE(S)=12\,000 \cdot 0,5 = 6\,000$\\
Gesucht: $\PP(|S-6\,000|\leq 19)$\\
Wir berechnen diese WK approximativ mit Satz von Moivre-Laplace. Dazu: 
$$\PP(|S-6\,000|\leq 19)=\PP(|S-6\,000|\leq 19,99) = \PP(|S-6\,000|\leq 19,5)$$
Diese Werte wären theoretisch gleich (weil Verteilung diskret), in der Approximation (die dann stetig Verteilt ist) dann aber nicht mehr. Daher nehmen wir für die Approximation den Wert zwischen den beiden Extremen: die $19,5$ (Stetigkeits-Korrektur)!\\
Damit gilt:
\begin{align*}
\PP(5\,980,5 \leq S \leq 6\,019,5)&\approx \Phi\left(\frac{6\,019,5-6\,000}{\sqrt{3\,000}}\right) - \Phi \left( \frac{5\,980,5-6\,000}{\sqrt{3\,000}}\right) \\
&= 2 \Phi \left( \frac{19,5}{\sqrt{3\,000}}\right)-1 \\
&= 0,27817416
\end{align*}
Bemerkung: Exakter Wert $\sum_{m=5\,901}^{6\,019} \binom{12\,000}{m}\cdot \left(\frac{1}{2}\right)^{12\,000}=0,2781725$

\chapter{Statistik}
\section{Deskriptive Statistik}
\subsection{Grundbegriffe}
\cparagraph{Definition} (Grundgesamtheit und Merkmale)
\begin{itemize}
\item Grundgesamtheit $\Omega$ … klar festgelegte Menge von gleichartigen Objekten, die hinsichtlich bestimmter Eigenschaften untersucht werden sollen
\item $\omega \in \Omega$ … Merkmalsträger / statistische Einheit / Untersuchungseinheit
\item Merkmal … die in der Grundgesamtheit zu untersuchende Eigenschaft
\item Zustandsraum $S$ … Menge der möglichen Merkmalsausprägungen / unterschiedliche Eigenschaften
\item $s \in S$ … Merkmalsausprägung\\
Mathematische Darstellung:
$$X: \Omega \to S, \; \omega \mapsto x$$
\end{itemize}
Beachte: $X$ ordnet jedem Element aus $\Omega$ ein Merkmal zu. $X$ wird daher oft selbst als \emph{Merkmal} bezeichnet.

\cparagraph{Beispiel} (Notenspiegel)
\begin{itemize}
\item $\Omega = \{ \text{alle Schüler einer Klasse}\}$
\item $S=\{1,2,3,4,5,6\}$
\item $X$ … Funktion, welche jedem Schüler seine Zensur zuordnet, bspw. $X(\omega_1) = 3; \; X(\omega_2) = 5;$
\end{itemize}

\cparagraph{Beispiel} (medizinischer Fragebogen zur Pneumonie)
\begin{itemize}
\item $\Omega = \{ \text{alle Patienten, die in einem bestimmten Jahr an Pneumonie erkrankt sind}\}$
\item abfrage Merkmale: Alter, Geschlecht, Größe, Dauer des Krankenhausaufenthalts
\item Mehrdimensionaler Zustandsraum, z.B.:\\
$X(\omega_1)=(65,"m",182\unit{cm},5\unit{d}) \in S$\\
$X(\omega_2)=(34,"w",162\unit{cm},2\unit{d}) \in S$
\item $X$ … Funktion, welche jedem Patienten seine Merkmals-Vektoren zuordnet
\item Beachte: Mehrdimensionale Merkmale behandelt man in der \emph{multivariaten Statistik}
\end{itemize}

\cparagraph{Bemerkung} Merkmale lassen sich auf verschiedene Weisen in Klassen einteilen. Wir betrachten 3 dieser möglichen Einteilungen:
\begin{enumerate}[label=(\Alph*)]
\item Ein Merkmal heißt
\begin{itemize}
\item \emph{qualitatives Merkmal}, falls die Ausprägungen eine Qualität wiedergeben (und nicht ein Ausmaß). Insbesondere gibt es nur endlich viele Ausprägungen. Für qualitative Merkmale gibt es keine zwingende Ordnung/Reihenfolge.\\
Beispiele: Geschlecht, Religionszugehörigkeit oder Parteipräferenz
\item \emph{quantitatives Merkmal}, falls die Ausprägung ein Ausmaß bzw. eine Intensität wiederspiegeln. Die Ausprägungen sind in diesem Fall Zahlen (mit oder ohne Maßeinheit).\\
Beispiele: Alter, Größe oder Einkommen.
\end{itemize}
\item Ein Merkmal heißt
\begin{itemize}
\item \emph{diskret}, wenn es endlich viele oder abzählbar unendlich viele Ausprägungen annehmen kann.\\
Beispiele: Zensuren, Einwohnerzahl, Produktionszahlen einer Maschine an verschiedenen Tagen
\item \emph{stetig}, wenn überabzählbar viele Ausprägungen angenommen werden können.\\
Beispiele: Gewicht, Zeitmessung in $100\unit{m}$ Lauf, Länge einer Schraube
\end{itemize}
\item Ein Merkmal heißt
\begin{itemize}
\item \emph{nominalskaliert}, genau dann wenn es qualitativ ist (also qualitatives Merkmal = nominalskaliertes Merkmal)\\
Beispiele: Geschlecht, Religionszugehörigkeit oder Parteipräferenz
\item \emph{ordinalskaliert}, wenn es eine Rangordnung der Merkmalausprägung gibt, jedoch die Abstände zwischen den Merkmalsausprägungen nicht interpretiert werden können.\\
Beispiele: Dienstrang beim Militär, Zufriedenheit mit Produkt (gut > mittel > schlecht)
\item \emph{metrisch skaliert (oder karinalskaliert)}, falls es eine Rangordnung der Merkmalsausprägung gibt und die Abstände zwischen den Ausprägungen messbar und interpretierbar sind.\\
Weitere Unterscheidung für metrisch skalierte Merkmale:
\begin{itemize}
\item \emph{Intervallskala:} natürlicher Nullpunkt existiert nicht\\
Beispiele: IQ-Skala, Temperatur in Celsius-Skala, Jahreszahlen
\item \emph{Verhältnisskala:} natürlicher Nullpunkt existiert\\
Beispiele: Zeitdauer, Masse, Preis
\end{itemize}
\end{itemize}
\end{enumerate}

\cparagraph{Bemerkung} Statistisch Sinnvolle Auswertungen
\begin{itemize}
\item \emph{Nominalskala}
\begin{itemize}
\item Häufigkeiten durch Zählen der einzelnen Ausprägungen
\item geeignetes Lagemaß: Modalwert
\item kein sinnvolles Streuungsmaß
\end{itemize}
\item \emph{Ordinalskala}
\begin{itemize}
\item Häufigkeiten durch Zählen der einzelnen Ausprägungen
\item geeignetes Lagemaß: Modalwert, Median
\item geeignetes Streuungsmaß: Spannweweite
\end{itemize}
\item \emph{metrische Skala}
\begin{itemize}
\item Häufigkeiten durch Zählen der einzelnen Ausprägungen
\item geeignetes Lagemaß: Modalwert, Median, arithmetisches Mittel
\item geeignetes Streuungsmaß: Spannweite, Standardabweichung, Varianz, …
\end{itemize}
\end{itemize}

\cparagraph{Bemerkung}
\begin{itemize}
\item Bei Nominal und Ordinalskala sind keine Rechenoperationen wie Addition, Subtraktion, Multiplikation oder Division erlaubt.
\item Bei Intervallskala ist Differenzenbildung erlaubt (jedoch keine Quotienten), da kein natürlicher Nullpunkt existiert.
\item Bei Verhältnisskala ist Quotientenbildung erlaubt (jedoch keine Differenzen), da natürlicher Nullpunkt existiert.
\end{itemize}

Nun wollen wir Stichproben einführen.\\
Vorüberlegung:
\begin{itemize}
\item Ist $X: \Omega \to S, \; \omega \mapsto x$ ein Merkmal mit $S\subseteq \RR$ (metrische Skala), so interessiert uns wie dieses Merkmal auf der Grundgesamtheit (GG) verteilt ist, d.h. 
$$F_X(z) = \PP(X \leq z)$$
(das WK-Maß $\PP$ entsteht durch zufälliges (gleichverteiltes) rausgreifen eines Merkmalsträgers aus $\Omega$)\\
Verteilung des Merkmals in $\Omega \leftrightsquigarrow$ Verteilung $\PP$ bzw. $FX$\\
z.B. ein Viertel der Personen in der GG hat Körpergröße $> 1,8 \unit{m} \leftrightsquigarrow \PP(X > 1,8) = 0,25$
\item Problem: Oft ist $\Omega$ zu groß, als dass man alle Werte $X(\omega), \; \omega \in \Omega$ erheben kann (Gründe sind etwa: Kosten, Zeit, …).
\item Idee: Einschränkung auf möglichst „representative“ Teilmenge von Messungen der Merkmale. Berechnung der Kennzahlen, Eigenschaften, … auf dieser Teilmenge.
\item Hoffnung: Diese Berechnung geben uns Aufschluss über die Zusammensetzung der Merkmale.
\item Ziehen daher Stichprobe aus den Daten.
\end{itemize}

\cparagraph{Definition} Sei ein Merkmal $X$ gegeben und seien $X_1, \ldots, X_n$ unabhängige, identische wie $X$ verteilte Zufallsvariablen. Dann heißt der Vektor 
$$\vec{X} = (X_1, \ldots, X_n)^T$$
mathematische Stichprobe vom Umfang $n$. Jede Realisierung $\vec{x}=(x_1, \ldots, x_n)^T$ von $\vec{X}$ heißt konkrete Stichprobe (Beobachtungsreihe).

\cparagraph{Bemerkung} Sei $X: \Omega \to S, \; \omega \mapsto x$ ein Merkmal
\begin{itemize}
\item Um die Stichprobe vom Umfang $n$ zu modellieren wählen wir $n$ unabhängige identisch (wie $X$) verteilte ZV:
$$X_1, \ldots, X_n \qquad \text{(große Buchstaben)}$$
(Vor der Beobachtung, Mathematische Stichprobe $\rightsquigarrow$ Induktive Statistik)
\item Nach der Auswertung dieser Variablen (einsetzen von $\omega$) erhalten wir Realisierungen dieser Zufallsvariablen:
$$x_1, \ldots, x_n \qquad \text{(kleine Buchstaben)}$$
(Nach der Beobachtung, konkrete Stichprobe $\rightsquigarrow$ Deskriptive Statistik)
\end{itemize}

\subsection{Eindimensionales Datenmaterial}
Erinnerung:\\
\begin{tabular}{C{0.49} C{0.49}}
eindimensional & mehrdimensional\\
\mpb[0.45]
\begin{itemize}[leftmargin=*]
\item $S=\{ 1, \ldots , 6\}$ (Schulnoten, Würfel)
\item $S=\{0,1\}$ (Geschlecht, Münze, …)
\end{itemize}
\mpe
&
\mpb[0.45]
\begin{itemize}[leftmargin=*]
\item $S=\RR^2$ (Körpergröße und Gewicht)
\item $S=\{1,\ldots,6\}^2$ (2 mal würfeln)
\end{itemize}
\mpe
\\
\end{tabular}

\subsubsection{Stichprobenfunktionen}
\cparagraph{Definition} Sei $(X_1, \ldots, X_n)$ eine mathematische Stichprobe. Sei $f$ eine Funktion auf $S^n$, also $f: S^n \to \RR, \; (x_1, \ldots, x_n) \mapsto f(x_1, \ldots, x_n) = y$.\\
Dann heißt die Zufallsvariable 
$$T:= f(X_1, \ldots , X_n)$$
\emph{Stichprobenfunktion}.\\
Es folgen spezielle Stichprobenfunktionen.

\cparagraph{Definition} Sei $(X_1, \ldots, X_n)$ eine mathematische Stichprobe zum Merkmal $X$. Wir definieren:
\begin{itemize}
\item (Stichproben-)Mittelwert:
$$\overline{X}=\frac{X_1+\ldots + X_n}{n}$$
\item (Stichproben-)Streuung/Varianz
$$S^2=\frac{1}{n-1} \sum_{i=1}^n (X_i - \overline{X})^2$$
\item (Stichproben-)Standardabweichung
$$S=\sqrt{S^2}$$
\item Variationskoeffizient
$$V=\frac{S}{\overline{X}}$$
\item Spannweite
$$R=\max (X_1, \ldots, X_n) - \min (X_1, \ldots, X_n) \bigskip$$
Sei $X=(X_1, \ldots, X_n)$ dann bezeichnet 
$$(X_{(1)}, X_{(2)}, \ldots, X_{(n)})$$ 
den Vektor der geordneten Stichproben, d.h. 
$$X_{(1)}\leq X_{(2)} \leq \ldots \leq X_{(n)}\text{.}$$
Wir definieren damit
\item $\alpha$-Quantil $\widetilde{X}_\alpha$ mittels
$$\widetilde{X}_\alpha := \begin{cases}
X_{(k)} & \text{falls }\alpha n\text{ keine ganze Zahl ist und }\\
& k\text{ kleinste ganze Zahle größer }\alpha n\text{.}\\
\frac{1}{2}(X_{(\alpha n)}+X_{\alpha n+1)}) & \text{falls }\alpha n\text{ ganzzahlig.}
\end{cases}$$
dann gilt:
\begin{enumerate}
\item höchstens $\alpha \cdot n$ Stichprobenwerte sind kleiner als $\widetilde{X}_\alpha$.
\item höchstens $(a-\alpha) n$ SP-Werte sind größer als $\widetilde{X}_\alpha$
\end{enumerate}
\item Median $:=\widetilde{X}_{0,5}$
\item Quartilsabstand (Inter-Quartil-Range)
$$IQR = \widetilde{X}_{0,75}-\widetilde{X}_{0,25}$$
\end{itemize}

\cparagraph{Definition} Sei $X_1, \ldots, X_n$ eine mathematische Stichprobe. Dann heißt 
$$S_n: \RR \to \RR, \; S_n(z)= \frac{\text{Anzahl der }X_i\text{ mit } X_1 \leq z}{n}$$
empirische Verteilungsfunktion der Stichprobe.

\cparagraph{Bemerkung} 
\begin{itemize}
\item Bezeichnungen für konkrete SP ($x_1, \ldots ,x_n$) analog, nur mit kleinen Buchstaben:
$$\overline{x},\; s^2,\; s, \; v, \; \tilde{x}_\alpha, \; s_n(z) $$
\item Stichproben-Mittelwert, -Varianz, -Standardabweichung, Variationskoeffizient sind nur sinnvoll für \emph{metrisch} skalierte Merkmale!
\item Quantile, Median, IQR und empirische Verteilungsfunktionen auch sinnvoll für ordinal skalierte Daten.
\item Fur nominal skalierte Merkmale ist keine der oben genannten Funktionen sinnvoll. Hier verwendet man z.B. den Modalwert (Häufigkeit aufgetretener Werte) zur Charakterisierung.
\end{itemize}
Die empirische Verteilungsfunktion $S_n$ ist eine Näherung der theoretischen Verteilungsfunktion $F$ von $X$:
\cparagraph{Satz} (Glivenko-Cantelli, Hauptsatz der Statistik)\\
Sei $X_1, X_2, \ldots$ eine Folge von unabhängigen, identisch mit Verteilungsfunktion F verteilten ZVen und $S_n$ die empirische VF von den ersten $n$ Zufallsvariablen. Dann gilt für jede noch so kleine Zahl $\varepsilon > 0$ und jedes $x \in \RR$:
$$\lim_{n\to \infty} \PP(|S_n(x) - F(x)|<\varepsilon) = 1$$

\subsubsection{Aufbereitung statistischer Daten am Beispiel}

\cparagraph{Beispiel} $X$ … Anzahl der Störungen im Maschinenpark eines Betriebes in einer Woche
\begin{itemize}
\item $n=20$ Beobachtungen ($20$ verschiedene Wochen)
\item konkrete Stichprobe:\\
$(x_1, \ldots , x_{20}) = (4,2,6,3,3,1,5,2,2,1,0,4,2,5,5,3,7,2,1,3)$
\item Beobachtete Ausprägungen $a_j$:\\
$a_1=0, \; a_2 = 1, \ldots, \; a_8=7$
\item Häufigkeitstabelle:\\
\begin{tabular}{L{0.15} | L{0.15} | L{0.2} | L{0.15} | L{0.2}}
Ausprägung $a_j$ & Abs. Häufigkeit $h_j$ & Summen der abs. Häufigkeiten $\sum_{i=1}^j h_i$ & relative Häufigkeit $w_j$ & Summe der rel. Häufigkeiten $s_j = \sum_{i=1}^j w_i$\\\hline
0 & 1 & 1 & 0,05 & 0,05\\
1 & 3 & 4 & 0,15 & 0,2\\
2 & 5 & 9 & 0,25 & 0,45\\
3 & 4 & 13 & 0,2 & 0,65\\
4 & 2 & 15 & 0,1 & 0,75\\
5 & 3 & 18 & 0,15 & 0,9\\
6 & 1 & 19 & 0,05 & 0,95\\
7 & 1 & 20 & 0,05 & 1
\end{tabular}\\
Beachte: bei metrisch oder ordinal skalierten Merkmalen ordnet man die Ausprägungen der Größe nach.\\
Summen sind auch nur für metrisch oder ordinal skalierte Merkmale sinnvoll.
\item Graphische Dartellung mittels Stabdiagramm:\\
ABB R
\begin{itemize}
\item absolute/relative Häufung $h_j$/$w_j$ auf $y$-Achse
\item Ausprägung $a_j$ auf $x$-Achse
\end{itemize}
\end{itemize}







%\newpage
%\printbibliography

\end{document}