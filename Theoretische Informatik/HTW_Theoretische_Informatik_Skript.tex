% Header aus der Vorlage
\input{../LaTeX_master/LaTeX_master_HTW}

\bibliography{../Literatur/HTW_Literatur.bib}

% Definition von Titel, Autor usw.
\DTitel{Theoretische Informatik}
\DUntertitel{Vorlesungsskript}
\DAutor{Falk-Jonatan Strube}
\DNotiz{Vorlesung von Dr. Boris Hollas}

\begin{document}

\maketitle
\newpage
\tableofcontents
\newpage

\chapter*{Inhalte}
Grundlage: Grundkurs Theoretische Informatik \cite{hollas2015grundkurs}
\begin{itemize}
\item Formale Sprachen
\begin{itemize}
\item Reguläre Sprachen
\begin{itemize}
\item Endliche Automaten
\item Reguläre Ausdrücke
\end{itemize}
\item Nichtreguläre Sprachen
\item Kontextfreie Sprachen
\begin{itemize}
\item Kellerautomaten
\item Grammatiken
\end{itemize}
\end{itemize}
\item Berechenbarkeit
\begin{itemize}
\item Halteproblem
\end{itemize}
\item Komplexitätsklassen
\begin{itemize}
\item $P$
\item $NP$
\item $NP$-vollständige Probleme
\end{itemize}
\end{itemize}

\chapter{Automaten und Formale Sprachen}
%\section{Formale Sprachen}
\paragraph{Def.:} Ein Alphabet ist eine Menge $\Sigma \not = \emptyset$ (Symbole in $\Sigma$ -- müssen nicht einzelne Buchstaben sein, auch Wörter usw. [bspw. „if“ oder „else“ im Alphabet der Programmiersprache C]).

\paragraph{Def.:} Für $w_1, ..., w_n \in \Sigma$ ist $w=w_1...w_n$ ein Wort der Länge $n$.\\
$\Sigma^n$ beschreibt alle Worte mit der Länge genau $n$\\
Das Wort $\varepsilon$ ist das \emph{leere Wort}.\\
Die Menge aller Wörter bezeichnen wir mit $\Sigma^*$ (einschließlich dem leeren Wort).

\subparagraph{Bsp.:} $\Sigma = \{a,b,c\}\quad \rightarrow \Sigma^*=\{\varepsilon, a, b, c, aa, ab,a c, aaa, ...\}$
\paragraph{Def.:} Für Wörter $a,b \in \Sigma^*$ ist $ab$ die Konkatenation dieser Wörter.\\
Für ein Wort $w$ ist $w^n$ die $n$-fache Konkatenation von $w$, wobei $w^0=\varepsilon$.

\subparagraph{Bemerkung:} Für alle $w \in \Sigma^*$ gilt $\varepsilon w = w = w \varepsilon$. $\varepsilon$ ist also das neutrale Element der Konkatenation.

\paragraph{Def.:} Eine \emph{formale Sprache} ist eine Teilmenge von $\sigma^*$.

\paragraph{Def.:} Für Sprachen $A, B$ ist $AB=\{ab \;|\; a \in A, \; b \in B\}$ sowie $A^n=\prod_{i=1}^{n}A$, wobei $A^0=\{\varepsilon\}$.
\subparagraph{Bemerkung:} $\emptyset, \varepsilon, \{\varepsilon\}$ sind unterschiedliche Dinge (leere Menge, leeres Wort, Menge mit leerem Wort).

\subparagraph{Bemerkung:} $\Sigma^*$ lässt sich ebenfalls definieren durch $\Sigma^*=\bigcup_{n\geq 0}\Sigma^n$.\\
Ferner ist $\Sigma^+=\Sigma^*-\{\varepsilon\}$.

\section{Reguläre Sprachen}
\subsection{Deterministische endliche Automaten (DFA)}
\subparagraph{Bsp.:} \parskp
\begin{tikzpicture}[-latex,shorten >= .3em,shorten <= .3em,auto,node distance=6em]
\node[initial, initial text =, state] (z0) {$z_0$};
\node[state] (z1) [right of=z0] {$z_1$};
\node[state] (z2) [right of=z1] {$z_2$};
\node[state, double, double distance = .5mm] (zE) [right of=z2] {$z_E$};
\path (z0) edge [loop above] node{$b,c$} (z0);
\path (z1) edge [loop above] node{$a$} (z1);
\path (zE) edge [loop above] node{$a,b,c$} (zE);
\path (z0) edge [bend left=20] node{$a$} (z1);
\path (z1) edge [bend left=20] node{$c$} (z0);
\path (z1) edge [bend left=20] node{$b$} (z2);
\path (z2) edge [bend left=20] node{$a$} (z1);
\path (z2) edge [bend left = 35] node{$b$} (z0);
\path (z2) edge node{$c$} (zE);
\end{tikzpicture}\\
(Pfeil zeigt auf Startzustand, Endzustand ist doppelt umrandet)\\
Dieser DFA akzeptiert alle Wörter über $\Sigma = \{a,b,c\}$, die $abc$ enthalten.\\
Deterministisch: Es gibt genau ein Folgezustand. Von jedem Knoten aus gibt es genau eine Kante für jedes Zeichen, nicht mehrere und nicht keine.
\subparagraph{Bsp.:} \parskp
\begin{tikzpicture}[-latex,shorten >= .3em,shorten <= .3em,auto,node distance=6em]
\node[initial, initial text = , state, double, double distance = .5mm] (zE){};
\path (z0) edge [loop above] node{$a,b,c$} (zE);
\end{tikzpicture}\\
Dieser DFA erkennt die Sprache $\{a,b,c\}^*$.
\paragraph{Def.:} Ein DFA ist ein Tupel $\mathcal{M}=(Z, \Sigma, \delta, z_0, E)$
\begin{itemize}
\item $Z$: Menge der Zustände
\item $\Sigma$: Eingabealphabet
\item $\delta$: Überführungsfunktion $Z\times \Sigma \rightarrow Z$. Dabei bedeutet $\delta (z,a) = z'$, dass $\mathcal{M}$ im Zustand $z$ für das Zeichen $a$ in den Zustand $z'$ wechselt.
\item $z_0\in Z$: Startzustand
\item $E$: Menge der Endzustände
\end{itemize}
$\delta$: \\
\begin{tikzpicture}[-latex,shorten >= .3em,shorten <= .3em,auto,node distance=6em]
\node[initial, state] (z0) {$z$};
\node[state] (z1) [right of=z0] {$z'$};
\path (z0) edge [bend left=20] node{$a$} (z1);
\end{tikzpicture}

\paragraph{Def.:} Die erweiterte Überführungsfunktion $\hat{\delta}:Z\times \Sigma^*\rightarrow Z$ ist definiert durch\\
$\hat{\delta}(z,w)=\begin{cases}
z & \text{für }w = \varepsilon\\
\hat{\delta}(\delta(z,a),x) & \text{für }w=ax \text{ mit } a\in \Sigma ,x \in \Sigma^*
\end{cases}$\\
Dazu vergleichbarer C-Code:
\begin{lstlisting}[language=C]
int $\hat{\delta}$(int z, char* w){
	if ( strlen(w) == 0 )
		return z;
	else
		return $\hat{\delta}$($\delta$(z, w[0]), w[1]);
\end{lstlisting}
Veranschaulichung:\\
\begin{tikzpicture}[-latex,shorten >= .3em,shorten <= .3em,auto,node distance=6em]
\node[initial, state] (z0) {$z$};
\node[state] (z1) [above right of=z0] {$z'$};
\node[state, white] (z2) [below right of=z0] {};
\node[state] (z3) [right of=z1, node distance=10em] {};
\path (z0) edge node{$w[0]$} (z1);
\path (z0) edge node{} (z2);
\path [dashed] (z1) edge (z3);
\end{tikzpicture}\\
Die erweiterte Überführungsfunktion bestimmt den Zustand nach dem vollständingen Lesen eines Wortes.

\subparagraph{Bsp.:} \parskp
\begin{tikzpicture}[-latex,shorten >= .3em,shorten <= .3em,auto,node distance=6em]
\node[initial, state] (z0) {$z_0$};
\node[state, double, double distance = .5mm] (zE) [right of=z0] {$z_E$};
\path (z0) edge node{$b$} (zE);
\path (z0) [loop above] edge node{$a$} (z0);
\path (zE) [loop above] edge node{$a,b$} (zE);
\end{tikzpicture}
\begin{align*}
\hat{\delta}(z_0, aaba) &= \hat{\delta}(\delta(z_0,a),aba)=\\
\hat{\delta}(z_0, aba) &= \hat{\delta}(\delta(z_0,a),ba)=\\
\hat{\delta}(z_0, ba) &= \hat{\delta}(\delta(z_0,b),a)=\\
\hat{\delta}(z_E, a) &= \hat{\delta}(\delta(z_E,a), \varepsilon)=\\
\hat{\delta}(z_E, \varepsilon) &= z_E
\end{align*}
Die von $\mathcal{M}$ \emph{akzeptierte Sprache} ist $L(\mathcal{M})=\{w\in \Sigma^* \;|\; \hat{\delta}(z_0, w) \in E\}$

\subsection{Nichtdeterministischer endliche Automaten (NFA)}
\begin{tikzpicture}[-latex,shorten >= .3em,shorten <= .3em,auto,node distance=6em]
\node[initial, state] (z0) {$z$};
\node[state] (z1) [right of=z0] {};
\node[state] (z2) [above right= 1.5 of z0] {};
\node[state] (z3) [below right= 1.5 of z0] {};
\node[state] (z4) [below of=z0] {};
\path (z0) edge node{$a$} (z1);
\path (z0) edge node{$a$} (z2);
\path (z0) edge node{$a$} (z3);
\path (z0) edge node{$c$} (z4);
\end{tikzpicture}
\\
NFA, der alles akzeptiert, was $abc$ enthält:\\
\begin{tikzpicture}[-latex,shorten >= .3em,shorten <= .3em,auto,node distance=6em]
\node[initial, state] (z0) {};
\node[state] (z1) [right of=z0] {};
\node[state] (z2) [right of=z1] {};
\node[state, double, double distance = .5mm] (z3) [right of =z2] {};
\path (z0) [loop above] edge node{$a,b,c$} (z0);
\path (z3) [loop above] edge node{$a,b,c$} (z0);
\path (z0) edge node{$a$} (z1);
\path (z1) edge node{$b$} (z2);
\path (z2) edge node{$c$} (z3);
\end{tikzpicture}\\
Beispiel: Wort $abaabcab$
\subparagraph{Beispiel:} NFA, der alle Wörter akzeptiert, die auf $001$ enden:\\
\begin{tikzpicture}[-latex,shorten >= .3em,shorten <= .3em,auto,node distance=6em]
\node[initial, state] (z0) {};
\node[state] (z1) [right of=z0] {};
\node[state] (z2) [right of=z1] {};
\node[state, double, double distance = .5mm] (z3) [right of =z2] {};
\path (z0) [loop above] edge node{$0,1$} (z0);
\path (z0) edge node{$0$} (z1);
\path (z1) edge node{$0$} (z2);
\path (z2) edge node{$1$} (z3);
\end{tikzpicture}\\
Akzeptierte Worte unter anderem: $01011001$, $001001$\\
Ein Wort wird vom NFA akzeptiert, wenn es einen Weg, ausgehend von einem Startzustand, gibt, mit den ein End-Zustand erreicht wird.\\
Der NFA „weiß“ nicht, welcher Pfad zu durchlaufen ist; diesen muss der Benutzer ermitteln (wie bei einer Straßenkarte).\\
Ein NFA lässt sich formalisieren durch ein Tupel $\mathcal{M}=(Z, \Sigma, \delta, S, E)$
\begin{itemize}
\item $Z$: Zustände
\item $\Sigma$: Eingabealphabet
\item $\delta$: $Z \times \Sigma \to \mathcal{P}(Z)$ Überführungsfunktion (bildet ab in Potenzmenge von $Z$)
\item $S$: Menge der Startzustände
\item $E$: Menge der Endzustände
\end{itemize}
Dabei bedeutet $\delta(z,a)\ni z'$, dass der NEA im Zustand $z$ für die Eingabe $a$ die Möglichkeit besitzt, in den Zustand $z'$ zu wechseln.\medskip\\
Folgendes ist auch ein NFA (mit $L(\mathcal{M})=\{0,1\}$):\\
\begin{tikzpicture}[-latex,shorten >= .3em,shorten <= .3em,auto,node distance=6em]
\node[initial, state] (z0) {};
\node[state, double, double distance = .5mm] (z1) [right of =z0] {};
\path (z0) edge node{$0$} (z1);

\node[initial, state, below of=z0] (z5) {};
\node[state, double, double distance = .5mm] (z6) [right of =z5] {};
\path (z5) edge node{$1$} (z6);
\draw [dashed] (-2,1) rectangle (3,-3);
\end{tikzpicture}

\subsection{Umwandlung eines NFA in einen DFA}\parskp
Wir wollen den NFA\\
\begin{tikzpicture}[-latex,shorten >= .3em,shorten <= .3em,auto,node distance=6em]
\node[initial, state] (z0) {$z_0$};
\node[state] (z1) [right of=z0] {$z_1$};
\node[state] (z2) [right of=z1] {$z_2$};
\node[state, double, double distance = .5mm] (z3) [right of =z2] {$z_E$};
\path (z0) [loop above] edge node{$a,b,c$} (z0);
\path (z3) [loop above] edge node{$a,b,c$} (z0);
\path (z0) edge node{$a$} (z1);
\path (z1) edge node{$b$} (z2);
\path (z2) edge node{$c$} (z3);
\end{tikzpicture}\\
in einen DFA umwandeln. Der Startzustand des DFA besteht aus den Startzuständen des NFA:\\
\begin{tikzpicture}[-latex,shorten >= .3em,shorten <= .3em,auto,node distance=6em]
\node[initial, state] (z0) {$\{z_0\}$};
\end{tikzpicture}\\
Betrachten die Folgezustände für $a \in \Sigma$:\\
\begin{tikzpicture}[-latex,shorten >= .3em,shorten <= .3em,auto,node distance=6em]
\node[initial, state] (z0) {$\{z_0\}$};
\node[state] (z1) [right of=z0] {$\{z_0,z_1\}$};
\path (z0) edge node{$a$} (z1);
\end{tikzpicture}\\
nächster Schritt:\\
\begin{tikzpicture}[-latex,shorten >= .3em,shorten <= .3em,auto,node distance=6em]
\node[initial, state] (z0) {$\{z_0\}$};
\node[state] (z1) [right of=z0] {$\{z_0,z_1\}$};
\path (z0) [loop above] edge node{$b,c$} (z0);
\path (z0) edge node{$a$} (z1);
\end{tikzpicture}\\
nächster Schritt:\\
\begin{tikzpicture}[-latex,shorten >= .3em,shorten <= .3em,auto,node distance=6em]
\node[initial, state] (z0) {$\{z_0\}$};
\node[state] (z1) [right of=z0] {$\{z_0,z_1\}$};
\path (z0) [loop above] edge node{$b,c$} (z0);
\path (z1) [loop above] edge node{$a$} (z1);
\path (z0) edge node{$a$} (z1);
\end{tikzpicture}\\
weitere Schritte:\\
$z_0,b: \{z_0\}$\\
$z_1,b: \{z_2\}$\\
\begin{tikzpicture}[-latex,shorten >= .3em,shorten <= .3em,auto,node distance=8em]
\node[initial, state] (z0) {$\{z_0\}$};
\node[state] (z1) [right of=z0] {$\{z_0,z_1\}$};
\node[state] (z2) [right of=z1] {$\{z_0,z_2\}$};
\path (z0) [loop above] edge node{$b,c$} (z0);
\path (z1) [loop above] edge node{$a$} (z1);
\path (z0) edge node{$a$} (z1);
\path (z1) edge node{$b$} (z2);
\end{tikzpicture}\\
$z_0,c: \{z_0\}$\\
$z_1,c: \{\}$\\
\begin{tikzpicture}[-latex,shorten >= .3em,shorten <= .3em,auto,node distance=8em]
\node[initial, state] (z0) {$\{z_0\}$};
\node[state] (z1) [right of=z0] {$\{z_0,z_1\}$};
\node[state] (z2) [right of=z1] {$\{z_0,z_2\}$};
\path (z0) [loop above] edge node{$b,c$} (z0);
\path (z1) [loop above] edge node{$a$} (z1);
\path (z0) edge node{$a$} (z1);
\path (z1) edge [bend left=20] node{$c$} (z0);
\path (z1) edge node{$b$} (z2);
\end{tikzpicture}\\
usw.:\\
\begin{tikzpicture}[-latex,shorten >= .3em,shorten <= .3em,auto,node distance=8em]
\node[initial, state] (z0) {$\{z_0\}$};
\node[state] (z1) [right of=z0] {$\{z_0,z_1\}$};
\node[state] (z2) [right of=z1] {$\{z_0,z_2\}$};
\node[state, double, double distance = .5mm] (z3) [right of =z2] {$\{z_0,z_E\}$};
\path (z0) [loop above] edge node{$b,c$} (z0);
\path (z1) [loop above] edge node{$a$} (z1);
\path (z3) [loop above] edge node{$a,b,c$} (z0);
\path (z0) edge node{$a$} (z1);
\path (z1) edge [bend left=20] node{$c$} (z0);
\path (z2) edge [bend left=20] node{$a$} (z1);
\path (z1) edge node{$b$} (z2);
\path (z2) edge [bend left=40] node{$b$} (z0);
\path (z2) edge node{$c$} (z3);
\node [align=left] at (10,-2) {Vereinfachung: \\andere Endzustände werden\\ weg gelassen.};
\end{tikzpicture}\\
Wenn ein Zustand des DFA einen Endzustand des NFA enthält, so ist es ein Endzustand.\\
Der auf diese Weise erhaltene DFA kann Zustände enthalten, die sich zu einem Zustand zusammen fassen lassen. Mit dem Algorithmus Minimalautomat lässt sich ein DFA konstruieren, der minimal bezüglich der Anzahl seiner Zustände ist. Der Minimalautomat ist eindeutig, d.h. Minimalautomaten unterscheiden sich höchstens in der Benennung der Zustände.

\subsection{Reguläre Ausdrücke}
\paragraph{Def.:} Sei $\Sigma$ ein Alphabet. Ein \emph{regulärer Ausdruck} $E$ sowie die durch $E$ \emph{erzeugte Sprache $L(E)$} sind induktiv definiert:
\begin{itemize}
\item $\emptyset$ ist ein regulärer Ausdruck und $L(\emptyset)=\emptyset$.\\
Bsp.: \\
\begin{tikzpicture}[-latex,shorten >= .3em,shorten <= .3em,auto,node distance=6em]
\node[initial, state] (z0) {};
\path (z0) [loop above] edge node{$a,b,c$} (z0);
\end{tikzpicture}\\
$L(\mathcal{M})=\emptyset$
\item Für $a \in \Sigma \cup \{\varepsilon\}$ ist $a$ ein regulärer Ausdruck und $L(a)=\{a\}$.
\item Für reguläre Ausdrücke $E_1, E_2$ sind $(E_1 | E_2), \; (E_1 E_2), \; (E_1^*)$ reguläre Ausdrücke (hier: $|=$„oder“) und $L(E_1|E_2)=L(E_1)\cup L(E_2), \; L(E_1E_2)=L(E_1)L(E_2), \; L(E_1^*)=L(E_1)^*$ die davon erzeugten Sprachen:\\
\begin{tabular}{l | r l}
Ausdruck & Sprache &\\
\hline
$E_1 | E_2$ & $L(E_1|E_2)$&$=L(E_1)\cup L(E_2)$\\
$E_1 E_2$ & $L(E_1E_2)$&$=L(E_1)L(E_2)$\\
$E_1^*$ & $L(E_1^*)$&$=L(E_1)^*$\\
\end{tabular}\medskip\\
Hinweis: $E^+=E E^*$, $E?=\varepsilon|E$\\
$\boxed{\text{Wenn }E_1, E_2 \text{ regulär, dann auch } (E_1 | E_2), \; (E_1 E_2), \; (E_1^*) \text{ regulär}}$
\end{itemize}
\subparagraph{Bsp.:} 
\begin{itemize}
\item $L( (0|1)^*) =(L(0|1))^*=(L(0)\cup L(1))^*=(\{0\}\cup\{1\})^*=\{0,1\}^*$
\item Regulärer Ausdruck über $\Sigma=\{a,b,c\}$, der die gleiche Sprache erzeugt wie der DFA aus dem letzten Automaten-Beispiel:\\
$L((a|b|c)^*abc(a|b|c)^*)=\{a,b,c\}^*\{abc\}\{a,b,c\}^*$
\end{itemize}

\paragraph{Satz:} Reguläre Ausdrücke erzeugen genau die regulären Sprachen.
\subparagraph{Skizze:} Umwandlung eines regulären Ausdrucks in einen endlichen Automaten.
\begin{itemize}
\item $\emptyset$: \\
\begin{tikzpicture}[-latex,shorten >= .3em,shorten <= .3em,auto,node distance=6em]
\node[initial, state] (z0) {};
\end{tikzpicture}
\item $a \in \Sigma$: \\
\begin{tikzpicture}[-latex,shorten >= .3em,shorten <= .3em,auto,node distance=6em]
\node[initial,state] (z0) {};
\node[state, double, double distance = .5mm] (zE) [right of=z0] {};
\path (z0) edge node{$a$} (zE);
\end{tikzpicture}
\item $\varepsilon$: \\
\begin{tikzpicture}[-latex,shorten >= .3em,shorten <= .3em,auto,node distance=6em]
\node[initial,state, double, double distance = .5mm] (zE) {};
\end{tikzpicture}
\item Seien $E_1, E_2$ reguläre Ausdrücke und $\mathcal{M}_1, \mathcal{M}_2$ DFAs mit $L(E_1)=L(\mathcal{M}_1), L(E_2)=L(\mathcal{M}_2)$.
\begin{itemize}
\item $E_1 | E_2$: $\mathcal{M}_1, \mathcal{M}_2$ sind zusammen ein NFA, der $L(\mathcal{M}_1) \vee L(\mathcal{M}_2)$ erkennt.\\
Bsp.: $E_1=a, E_2=b$\\
\begin{tikzpicture}[-latex,shorten >= .3em,shorten <= .3em,auto,node distance=6em]
\node[initial,state] (z0) {};
\node[state, double, double distance = .5mm] (zE) [right of=z0] {};
\path (z0) edge node{$a$} (zE);

\node[initial,state] (z2) [right= 2.5 of zE] {};
\node[state, double, double distance = .5mm] (z3) [right of=z2] {};
\path (z2) edge node{$b$} (z3);
\draw [dashed]  (-2,1) rectangle (9,-1) node[above right]{$E_1|E_2$};
\end{tikzpicture}
\item $E_1 E_2$: $\mathcal{M}_1, \mathcal{M}_2$ müssen hintereinander geschaltet werden, wobei ggf. neue Kanten eingefügt werden müssen. Dazu betrachtet man die Kante nach der neuen Verbindung und erzeugt dem entsprechend die Übergangskanten.\\
\begin{tikzpicture}[-latex,shorten >= .3em,shorten <= .3em,auto,node distance=6em]
\node[initial,state] (z0) {};
\node[state, double, double distance = .5mm] (zE) [right of=z0] {};
\path (z0) edge node{$a$} (zE);

\node[initial,state] (z2) [right= 2.5 of zE] {};
\node[state, double, double distance = .5mm] (z3) [right of=z2] {};
\path (z2) edge node{$b$} (z3);
\end{tikzpicture}\\
$\Downarrow$\\
\begin{tikzpicture}[-latex,shorten >= .3em,shorten <= .3em,auto,node distance=6em]
\node[initial,state] (z0) {};
\node[state] (zE) [right of=z0] {};
\path (z0) edge node{$a$} (zE);

\node[state] (z2) [right of= zE] {};
\node[state, double, double distance = .5mm] (z3) [right of=z2] {};
\path (z2) edge node{$b$} (z3);
\path (zE) edge node{?} (z2);
\end{tikzpicture}\\
$\Downarrow$\\
\begin{tikzpicture}[-latex,shorten >= .3em,shorten <= .3em,auto,node distance=6em]
\node[initial,state] (z0) {};

\node[state] (z2) [right of= z0] {};
\node[state, double, double distance = .5mm] (z3) [right of=z2] {};
\path (z2) edge node{$b$} (z3);
\path (z0) edge node{$a$} (z2);
\draw [dashed] (-2,1) rectangle (5,-1) node[above right]{$E_1\cdot E_2$};
\end{tikzpicture}
\item $E_1^*$: Es müssen Kanten zurück zum Startzustand eingefügt werden\\
Beispiel:\\
\begin{tikzpicture}[-latex,shorten >= .3em,shorten <= .3em,auto,node distance=6em]
\node[initial,state] (z0) {};
\node[state,double, double distance = .5mm] (z1) [right of=z0] {};
\path (z0) edge node{$a$} (z1);
\path (z0) [loop above] edge node{$a$} (z0);
\node[state,initial,double, double distance = .5mm] (z1) [below=.5 of z0] {};
\end{tikzpicture}\\
oder:\\
\begin{tikzpicture}[-latex,shorten >= .3em,shorten <= .3em,auto,node distance=6em]
\node[initial,state] (z0) {};
\node[state] (z1) [right of=z0] {};
\node[state] (z2) [right of=z1] {};
\node[state,double, double distance = .5mm] (z3) [right of=z2] {};
\path (z0) edge node{$a$} (z1);
\path (z1) edge node{$b$} (z2);
\path (z2) edge node{$c$} (z3);
\path (z3) edge [bend right=30] node[above]{$c$} (z0);
\node[state,initial,double, double distance = .5mm] (z1) [below=.5 of z0] {};
\draw [dashed] (-2,1.6) rectangle (7.6,-2) node[above right]{$E_1^*$};
\end{tikzpicture}
\end{itemize}
\end{itemize}
Der Beweis für die umgekehrte Richtung (DFA $\to$ reg. Ausdruck) ist schwierig.
\subparagraph{Bsp.:}
\begin{itemize}
\item $E=0(0|1)^*$\\
\begin{tikzpicture}[-latex,shorten >= .3em,shorten <= .3em,auto,node distance=6em]
\node[initial,state] (z0) {};
\node[state] (z2) [below of=z0] {};
\node[state,double, double distance = .5mm] (z1) [right of=z0] {};
\path (z0) edge node{$0$} (z1);
\path (z0) edge node{$1$} (z2);
\path (z1) [loop above] edge node{$0,1$} (z1);
\path (z2) [loop right] edge node{$0,1$} (z2);
\end{tikzpicture}
\item \raisebox{-\height}{\begin{tikzpicture}[-latex,shorten >= .3em,shorten <= .3em,auto,node distance=6em]
\node[initial,state] (z0) {};
\node[state,double, double distance = .5mm] (z1) [right of=z0] {};
\path (z0) edge[bend left=20] node{$1$} (z1);
\path (z1) edge[bend left=20] node{$0$} (z0);
\path (z0) [loop above] edge node{$0$} (z0);
\path (z1) [loop right] edge node{$1$} (z1);
\end{tikzpicture}}\\
Beobachtungen:
\begin{itemize}
\item um zum Endzustand zu kommen, braucht man eine $1$.
\item vor der $1$ kann $\varepsilon$ stehen, oder beliebig viele $0$en der $1$en.
\end{itemize}
$\Rightarrow E=(0|1)^* 1$
\end{itemize}

\subsection{Das Pumping-Lemma}
Wenn ein DFA ein Wort akzeptiert, das mindestens so lang ist wie die Anzahl seiner Zustände, dann muss er einen Zustand zweimal durchlaufen (Schubfachprinzip). Daraus folgt, dass der DFA dabei eine Schleife durchläuft.
\subparagraph{Bsp.:} Gegeben ist der NFA:\\
\begin{tikzpicture}[-latex,shorten >= .3em,shorten <= .3em,auto,node distance=6em]
\node[initial,state] (z0) {};
\node[state] (z1) [right of=z0] {};
\node[state] (z2) [right of=z1] {};
\node[state] (z3) [right of=z2] {};
\node[state] (z4) [above left=.75 of z3] {};
\node[state] (z5) [right of=z3] {};
\node[state,double, double distance = .5mm] (z6) [right of=z5] {};
\path (z0) edge node{$a$} (z1);
\path (z1) edge node{$b$} (z2);
\path (z2) edge node{$c$} (z3);
\path (z3) edge node[above right]{$d$} (z4);
\path (z4) edge node[above left]{$e$} (z2);
\path (z3) edge node{$f$} (z5);
\path (z5) edge node{$g$} (z6);
\end{tikzpicture}\\
Für $x=abcdecfg$ durchläuft der Automat eine Schleife: $x=ab\,\boxed{cde}\,cfg$. Daher akzeptiert der DFA auch alle Wärter $ab(cde)^k cfg$ für $k \geq 0$.
\paragraph{Satz:} (Pumping Lemma)\\
Für jede reguläre Sprache $L$ gibt es ein $n>0$ ($n$: Anzahl Zustände des Minimalautomaten), so dass es für alle Wörter $x \in L$ mit $|x|\geq n$ eine Zerlegung $x=uvw$ gibt (in vorherigem Bsp.: $u=ab, \; v=cde \; w =cfg$), so dass gilt:
\begin{enumerate}
\item $|v| \geq 1$
\item $|uv|\leq n$ \quad ($u, w$ können auch $\varepsilon$ sein)
\item $uv^kw \in L$ für alle $k\geq 0$.
\end{enumerate}
Ohne Einschränkung ist $n$ die Anzahl Zustände des Minimalautomaten.\\
$\Rightarrow \forall \text{ regulären Sprachen }L\quad \exists \;n>0 \quad\forall \; x \in L, \; |x| \geq n \quad \exists \;u,v,w \text{ mit }x=uvw \text{ und }|v| \geq 1,|uv|\geq n \quad \forall \; k\geq 0 \; uv^kw\in L$.\\
Das Pumping-Lemma lässt sich nutzen, um zu zeigen, dass eine Sprache nicht regulär ist.
\subparagraph{Bsp.:} Wir zeigen, dass $L=\{a^nb^n|n\in \mathbb{N}\}$ nicht regulär ist.\\
Problemstellung: Der Automat kann sich das $n$ nicht „merken“, um nach $n$ $a$s wieder $n$ $b$s zu erzeugen. \\
Beweis (Widerspruch):
\begin{itemize}
\item Angenommen, $L$ sei regulär.
\item Nach Pumping-Lemma gibt es dann ein $n>0$, so dass sich alle $x\in L$ mit $|x|\geq n$ gemäß Pumping-Lemma zerlegen lassen.
\item Sei $x=a^nb^n$. 
\item Angenommen $v$ enthalte ein $b$, dann wäre $|uv| > n$. \\
Aus $|uv|\leq n$ folgt aber, dass $v$ kein $b$ enthält. aus $|v|\geq 1$ folgt, dass $v$ mindestens ein $a$ enthält.\\
\begin{tikzpicture}[scale=.5]
\draw  (-3,1) rectangle (1,-1) node[pos=.5]{u\qquad v};
\draw  (1,1) rectangle (5,-1) node[pos=.5]{w};
\node at (-1,2) {a … a};
\node at (3,2) {b … b};
\draw [decorate, decoration={brace, amplitude=5pt}] (-2.9,3) -- (0.9,3) node[above = .2, pos=.5]{$n$};
\draw [decorate, decoration={brace, amplitude=5pt}] (1.1,3) -- (4.9,3)node[above = .2, pos=.5]{$n$};
\end{tikzpicture}
\item Das Wort $uw$ enthält daher weniger $a$s als $b$s und kann somit nicht in $L$ enthalten sein (denn $w$ enthält $b^n$, da $v$ mindestens ein $a$ enthält, ist durch $uw$ mindestens ein $a$ „verloren gegangen“: $uw=a^{n-|v|}b^n$) und ist deshalb nicht in $L$ enthälten, Widerspruch\,\lightning \; \#
\end{itemize}
Vorgehen:
\begin{itemize}
\item ist regulär
\item Def. Pumping Lemma
\item $x$ finden (gilt für alle $x$, also ein günstiges $x$ aussuchen, mit dem sich Beweis führen lässt)
\item durch 1.) und/oder 2.) einschränken
\item durch 3.) zum Widerspruch führen
\end{itemize}

\subparagraph{Bsp.:} Wir zeigen, dass $L=\{zz|z\in \{a,b\}^*\}$ nicht regulär ist.\\
Intuitiver Hinweis: Kann nicht regulär sein, da sich der Automat nicht merken kann, wie viele $a$s und $b$s im ersten $z$ gelesen wurden, um dann das gleiche im zweiten $z$ zu fabrizieren.\\
Beweis: 
\begin{itemize}
\item Angenommen, $L$ ist regulär.
\item Nach Pumping-Lemma gibt es ein $n>0$, so dass sich alle $x \in L$ mit $|x|\geq n$ zerlegen lassen gemäß Pumping-Lemma.
\item Sei $x=a^nb a^nb$.
\item Wegen $|uv|\leq n$ und $|v|\geq 1$ besteht $v$ aus mindestens einem $a$.\\
\begin{tikzpicture}[scale=.5]
\draw  (-3,1) rectangle (0,-1) node[pos=.5]{u\qquad v};
\draw  (0,1) rectangle (5,-1) node[pos=.5]{w};
\node at (-1.5,2) {a … a};
\node at (0.5,2) {b};
\draw [decorate, decoration={brace, amplitude=5pt}] (-2.9,3) -- (0,3) node[above = .2, pos=.5]{$n$};
\node at (2.4,2) {a … a};
\node at (4.4,2) {b};
\draw [decorate, decoration={brace, amplitude=5pt}] (1,3) -- (3.9,3) node[above = .2, pos=.5]{$n$};
\draw [dashed] (0,2) -- (0,1);
\end{tikzpicture}
\item Dann enthält $uw=a^{n-|v|}ba^nb$ (für $k=0$) weniger $a$s in der vorderen Hälfte als in der hinteren Hälfte. Da sich $uw$ deshalb nicht in die Form $zz$ mit $z\in \{a,b\}^*$ brigen lässt, ist $uw \not \in L$, Widerspruch!
\end{itemize}

\paragraph{Satz:} Seien $L$ regulär und $n$ die Anzahl Zustände des Minimalautomaten zu $L$. Dann gilt $|L| = \infty$ genau dann, wenn es ein $x \in L$ gibt mit $n\leq  |x| < 2n$.\\
Beweis:\\
($\Leftarrow$):\\
Gemäß Pumping Lemma gibt es eine Zerlegung $x=uvw$ mit $|v| \geq 1$ und $uv^kw\in L$ für alle $k \in \mathbb{N}_0$ ($\mathbb{N}$ ist unendlich).\\
Daraus folg $|L|=\infty$.\\
($\Rightarrow$):\\
Da es nur endlich viele Wörter $x$ mit $|x|<n$ gibt, gibt es ein $x\in L$ mit $|x|\geq n$.\\
Sei daher $x\in L$ mit $|x| \geq n$ und $|x|$ minimal.\\
Gemäß PL lässt sich $x$ zerlegen in $x=uvw$.\\
Da $uw \in L$ und $|x|$ minimal ist, gilt $|uw|<n$.\\
Wegen $|x|\geq \underbrace{|uv|}_{<n \text{ gemäß PL}}+\underbrace{|uw|}_{<n \text{ Satz zuvor}}<n+n=2n$ folgt die Behauptung $n \leq |x| \leq 2n$. \\
Regulärer Ausdruck: Generator\\
Automat: Validator
\section{Kontextfreie Sprachen}

\subsection{Kellerautomaten (PDA)}
Ein Kellerautomat (Pushdown Automaton, PDA) besitzt gegenüber einem NFA zwei zusätzliche Eigenschaften:
\begin{itemize}
\item Es gibt $\varepsilon$-Übergänge.
\item Er besitzt einen Stack, auf dem Zeichen abgelegt oder von dem Zeichen gelesen werden können.
\end{itemize}
Zur graphischen Darstellung von PDAs verwenden wir eine erweiterte Automatennotation:\\
\begin{tikzpicture}[shorten >= .3em,shorten <= .3em,auto,node distance=8em]
\node[state] (z1){$z$};
\node[state] (z2) [right of=z1] {$z'$};
\path (z1) edge [-latex] node{$a,\gamma/\gamma'$} (z2);
\draw  (-2,0.5) rectangle (-1,-0.5);
\draw  (-2,-0.5) rectangle (-1,-2);
\draw  (-2,-2) rectangle (-1,-3);
\draw (-2,1) node[above]{stack in $z$:}  -- (-2,0.5) -- (-1,0.5) -- (-1,1);
\node at (-1.5,0) {$\gamma$};
\node at (-1.5,-1) {$\vdots$};
\node at (-1.5,-2.5) {$\#$};
\draw  (4,0.5) rectangle (5,-0.5);
\draw  (4,-0.5) rectangle (5,-2);
\draw  (4,-2) rectangle (5,-3);
\draw (4,1) node[above]{stack in $z'$:} -- (4,0.5) -- (5,0.5) -- (5,1);
\node at (4.5,0) {$\gamma'$};
\node at (4.5,-1) {$\vdots$};
\node at (4.5,-2.5) {$\#$};
\end{tikzpicture}\\
$a$: Eingabezeichen\\
$\gamma$: Top of Stack in $z$\\
$\gamma'$: Top of Stack in $z'$\\
(wenn $\gamma$ auf Stack liegt, wird $\gamma$ runter geholt und $\gamma'$ auf den Stack gelegt)\\
$a,\gamma$: Übergangsvoraussetzung\\
Stack unverändert lassen:$a,\varepsilon/\varepsilon$\\
Stack leeren: $a,\gamma/ \varepsilon$\\
Stack füllen: $a,\varepsilon/\gamma$\\
Unten auf dem Stack liegt das Symbol \#. Dies ist das einzige Symbol, das sich zu Beginn einer Rechnung auf dem Stack befindet.
\subparagraph{Bsp.:} PDA, der $\{a^nb^n|n\in \mathbb{N}\}$ akzeptiert.\\
\begin{tikzpicture}[shorten >= .3em,shorten <= .3em,auto,node distance=8em]
\node[state, initial] (z0){};
\node[state] (z1)[right of=z0]{};
\node[state, double, double distance = .5mm] (z2) [right of=z1] {};
\path (z0) [loop above] edge node{$a,\varepsilon/a$} (z0);
\path (z0) edge [-latex] node{$b,a/\varepsilon$} (z1);
\path (z1) [loop above] edge node{$b,a/\varepsilon$} (z1);
\path (z1) edge [-latex] node{$\varepsilon,\#/\varepsilon$} (z2);
\end{tikzpicture}\\
Wir erlauben nun, dass der PDA in einem Schritt auch mehrere Zeichen auf den Stack schreibt. Dazu erweitern wir die graphische Notation wie folgt:\\
\begin{tikzpicture}[shorten >= 3,shorten <= 3,auto,node distance=100]
\node[state] (z1){$z$};
\node[state] (z2) [right of=z1] {$z'$};
\path (z1) edge [-latex] node{$a,\gamma/\gamma_1'\dots\gamma_n'$} (z2);
\draw  (-2,1.5) rectangle (-1,0.5);
\draw  (-2,0.5) rectangle (-1,-2);
\draw  (-2,-2) rectangle (-1,-3);
\draw (-2,2) node[above]{stack in $z$:}  -- (-2,1.5) -- (-1,1.5) -- (-1,2);
\node at (-1.5,1) {$\gamma$};
\node at (-1.5,0) {$\vdots$};
\node at (-1.5,-2.5) {$\#$};
\draw  (4.5,1.5) rectangle (5.5,0.5);
\draw  (4.5,0.5) rectangle (5.5,-1);
\draw  (4.5,-2) rectangle (5.5,-3);
\draw (4.5,2) node[above]{stack in $z'$:} -- (4.5,1.5) -- (5.5,1.5) -- (5.5,2);
\node at (5,1) {$\gamma_1'$};
\node at (5,0) {$\vdots$};
\node at (5,-2.5) {$\#$};
\draw  (4.5,-1) rectangle (5.5,-2);
\node at (5,-1.5) {$\gamma_n'$};
\node [right] at (-2.5,-3.5) {äquivalent:};
\coordinate (zx) at (-2.5,-3.5);

\node[state] (z01) [below=.5 of zx]{$z$};
\node[state] (z02) [right of=z01] {$z'$};
\path (z01) edge [-latex] node{$a,\gamma/\gamma_n'$} (z02);
\node (z04) [right of=z02]{…};
\path (z02) edge [-latex] node{$\varepsilon,\varepsilon/\gamma_{n-1}'$} (z04);
\node[state] (z05) [right of=z04] {$z'$};
\path (z04) edge [-latex] node{$\varepsilon,\varepsilon/\gamma_1'$} (z05);
\end{tikzpicture}
\subparagraph{Def.:} Ein PDA ist ein Tupel $M=(Z,\Sigma, \Gamma, \delta, z_0, \#, E)$
\begin{itemize}
\item $Z$: Zustände
\item $\Sigma$: Eingabealphabet
\item $\Gamma$: Stackalphabet
\item $\delta$: $Z\times \Sigma_\varepsilon \times \Gamma_\varepsilon \to \mathcal{P}(Z\times \Gamma_\varepsilon)$, wobei $\Sigma_\varepsilon=\Sigma \cup \{\varepsilon\}$, $\Gamma_\varepsilon = \Gamma \cup \{\varepsilon\}$
\item $z_0\in Z$: Startzustand
\item $\# \in \Gamma$: Unterstes Stackzeichen
\item $E \in Z$: Endzustände
\end{itemize}
\begin{tikzpicture}[shorten >= .3em,shorten <= .3em,auto,node distance=8em]
\node[state] (z1){$z$};
\node[state] (z2) [right of=z1] {$z'$};
\path (z1) edge [-latex] node{$a,\gamma/\gamma'$} (z2);
\end{tikzpicture}\\
$a \in \Sigma \cup \{\varepsilon\}$\\
$\gamma \in \Gamma \cup \{\varepsilon\}$\\
$\gamma' \in \Gamma \cup \{\varepsilon\}$

\paragraph{Def.:} Die von einem PDA $M$ akzeptierte Sprache $L(M)$ ist die Menge aller $x \in \Sigma^*$, für die gilt: Der PDA $M$ kann, ausgehend vom Startzustand und dem initialen Stackzustand $\#$, durch das Lesen des Wortes $x$ einen Endzustand erreichen.\bigskip\\
\begin{tikzpicture}[shorten >= 3,shorten <= 3,auto,node distance=100]
\node[state] (z1){$z$};
\node[state] (z2) [above of=z1] {$z'$};
\node[state] (z3) [above right of=z1] {$z'$};
\node[state] (z4) [right of=z1] {$z'$};
\node[state] (z5) [below right of=z1] {$z'$};
\node[state] (z6) [below of=z1] {$z'$};
\path (z1) edge [-latex] node{$a,\gamma/\gamma''$} (z2);
\path (z1) edge [-latex] node{$a,\varepsilon/\varepsilon$} (z3);
\path (z1) edge [-latex] node{$a,\varepsilon/\varepsilon$} (z4);
\path (z1) edge [-latex] node{$a,\gamma/\gamma'$} (z5);
\path (z1) edge [-latex] node{$a,\gamma/\gamma'$} (z6);
\end{tikzpicture}\\
(nicht deterministischer PDA)

\subsection{Kontextfreie Grammatiken}
Eine kontextfreie Grammatik beschreibt, wie durch das Ersetzen von variablen Wörter der Sprache erzeugt werden können. Jede Ersetzungsregel hat die Form „linke Seite $\to$ rechte Seite“ (linke Seite der Regel kann ersetzt werden durch die rechte Seite), wobei „linke Seite“ eine Variable ist. 

Beginnend mit dem Startsymbol werden solange Ersetzungsregeln angewendet, bis alle Variablen durch Terminalsymbole (Elemente aus $\Sigma$) ersetzt wurden.

\subparagraph{Bsp.:}
\begin{itemize}
\item Satz $\to$ NP VP\footnote{Nominalphase, Verbalphase}
\item NP $\to$ Artikel Nomen
\item Artikel $\to$ \tgreen{die}
\item Nomen $\to$ \tgreen{Katze}
\item Nomen $\to$ \tgreen{Maus}
\item VP $\to$ Verb NP
\item Verb $\to$ \tgreen{jagt}
\end{itemize}
Satz $\Rightarrow$ NP VP $\Rightarrow$ Artikel Nomen VP $\Rightarrow$ Artikel Nomen Verb NP $\Rightarrow$ Artikel Nomen Verb Artikel Nomen $\Rightarrow$ … $\Rightarrow$ die Katze jagt die Maus\\
Syntax dazu:\\
\begin{tikzpicture}[shorten >= 3,shorten <= 3,auto,node distance=50]
\node (s) {Satz};
\node (s1) [left of= s]{};
\node (s2) [right of= s]{};
\node (np) [below of=s1]{NP};
\node (vp) [below of=s2]{VP};
\node (np2) [left of= np]{};
\node (vp2) [right of= vp]{};
\node (a) [below of=np2]{Artikel};
\node (n) [below of=np]{Nomen};
\node (v) [below of=vp]{Verb};
\node (np3) [right of=vp]{};
\node (np4) [below of=np3]{NP};
\node (np5) [right of=np4]{};
\node (a2) [below of=np4]{Artikel};
\node (n2) [below of=np5]{Nomen};
\node (e5) [below of = n2]{Maus};
\node (e4) [left of = e5]{die};
\node (e3) [left of = e4]{jagt};
\node (ex) [left of = e3]{};
\node (e2) [left of = ex]{Katze};
\node (e1) [left of = e2]{die};
\path (s) edge (np);
\path (np) edge (a);
\path (np) edge (n);
\path (a) edge (e1);
\path (n) edge (e2);
\path (s) edge (vp);
\path (vp) edge (v);
\path (vp) edge (np4);
\path (v) edge (e3);
\path (np4) edge (a2);
\path (np4) edge (n2);
\path (a2) edge (e4);
\path (n2) edge (e5);
\end{tikzpicture}

\paragraph{Def.:} Eine kontextfreie Grammatik ist ein Tupel $\sigma = (V, \Sigma, P, S)$
\begin{itemize}
\item $V$: Endliche Menge der Variablen oder Nonterminalzeichen
\item $\Sigma$: Alphabet oder Terminalzeichen $V\cap \Sigma = \emptyset$
\item $P$: Regeln oder Produktionen der Form $u \to v$ mit $u \in V$ und $v \in (V\cup \Sigma)^*$
\item $S \in V$
\end{itemize}

Für $x,y\in (V \cup \Sigma)^*$ schreiben wir $x \Rightarrow y$, wenn sich durch das Ersetzen einer Variablen in $x$ die Satzform $y$ erzeugen lässt.
\subparagraph{Bsp.:} die Nomen Verb $\Rightarrow$ die Katze Verb\medskip\\
Die reflexive und transitive Hülle der Relation $\Rightarrow$ bezeichnen wir mit $\Rightarrow^*$. Umgangssprachlich: durch $\Rightarrow^*$ werden nicht alle $\Rightarrow$-Umformungen dargestellt, sondern teils übersprungen.
\subparagraph{Bsp.:} \parskp
Satz $\Rightarrow^*$ die Katze VP, \\
Satz $\Rightarrow^*$ die Katze jagt die Maus.
\paragraph{Def.:} Die von einer Grammatik erzeugte Sprache ist $L(G)=\{w\in \Sigma^* | S \Rightarrow^* w\}$.
\paragraph{Abkürzende Notation:} \parskp
$S\to \varepsilon | 0S1$ für $S\to \varepsilon, \; S \to 0S1$

\subsubsection{Konstruktionsprinzipien für kontextfreie Grammatiken}
Regeln der Form $X\to aXb$ führen zu:\\
\begin{tikzpicture}[auto,node distance=50]
\node (v1) at (-0.5,3) {$X$};
\node (v2) at (-1.5,2) {$a$};
\node (v22) at (0.5,2) {$b$};
\node (v3) at (-0.5,1.5) {$X$};
\node (v4) at (-1.5,0.5) {$a$};
\node (v5) at (0.5,0.5) {$b$};
\node (v6) at (-0.5,0) {$X$};
\draw (v1) -- (v2);
\draw (v1) -- (v22);
\draw (v1);
\draw (v1) -- (v3);
\draw (v3) -- (v4);
\draw (v3) -- (v5);
\draw (v3) -- (v6);
\draw [dotted] (v6) -- (-1.5,-1);
\draw [dotted] (v6) -- (-0.5,-1);
\draw [dotted] (v6) -- (0.5,-1);
\end{tikzpicture}\\
Dies lässt sich für balancierte Strukturen nutzen.\\
Mit der Regel $X\to XX$ wächst der Syntaxbaum in die Breite.\\
\begin{tikzpicture}[auto,node distance=50]
\node (v1) at (0,2.5) {$X$};
\node (v2) at (-1,1.5) {$X$};
\node (v3) at (1,1.5) {$X$};
\node (v6) at (-0.5,0.5) {$X$};
\node (v7) at (-1.5,0.5) {$X$};
\node (v5) at (0.5,0.5) {$X$};
\node (v4) at (1.5,0.5) {$X$};
\draw (v1) -- (v2);
\draw (v1) -- (v3);
\draw (v3) -- (v4);
\draw (v3) -- (v5);
\draw (v2) -- (v6);
\draw (v2) -- (v7);
\end{tikzpicture}\\
Beispiel, die beide Prinzipien anwendet: $S\to [S] | SS | \varepsilon$\\
\begin{tikzpicture}[auto,node distance=50]
\node (v1) at (0,2.5) {$S$};
\node (v2) at (-1,1.5) {$S$};
\node (v3) at (1,1.5) {$S$};
\node (v6) at (-0.5,0.5) {$S$};
\node (v7) at (-1.5,0.5) {$S$};
\node (v5) at (0.5,0.5) {$S$};
\node (v4) at (1.5,0.5) {$S$};
\draw (v1) -- (v2);
\draw (v1) -- (v3);
\draw (v3) -- (v4);
\draw (v3) -- (v5);
\draw (v2) -- (v6);
\draw (v2) -- (v7);
\node (v8) at (-2,-0.5) {$S$};
\node (v9) at (-1,-0.5) {$S$};
\draw (v7) -- (v8);
\draw (v7) -- (v9);
\end{tikzpicture}\\
Damit lässt sich bspw. auch folgendes als Grammatik darstellen: $(3*(4+5)-1)*2+1$.
\subparagraph{Bsp.:} Grammatik für arithmetische Ausdrücke.
\begin{itemize}
\item Zahlen: Lassen sich darstellen durch die Grammatik mit den Regeln:\\
$S_N\to 0S_N\,|\,\dots \,|\, 0S_N \,|\, 0 \,|\, ... \,|\, 9$\\
Beispiel für $123$: \\
\begin{tikzpicture}[auto,node distance=50]
\node (v1) at (0,2.5) {$S_N$};
\node (v2) at (-0.5,1.5) {$1$};
\node (v3) at (0.5,1.5) {$S_N$};

\node (v4) at (1,0.5) {$S_N$};
\node (v5) at (0,0.5) {$2$};
\node (v6) at (1,-0.5) {$3$};
\draw (v1) -- (v2);
\draw (v1) -- (v3);
\draw (v3) -- (v4);
\draw (v3) -- (v5);
\draw (v4) -- (v6);
\end{tikzpicture}
\item Zeichen: Diese Grammatik verwenden wir, um Ausdrücke darzustellen mit folgender Grammatik:\\
$S_E\to S_E+S_E \,|\, S_E - S_E \,|\, S_E*S_E \,|\, S_E/S_E \,|\, (S_E) \,|\, S_N$\\
Damit lassen sich Ausdrücke erstellen, z.B.:\\
\begin{tikzpicture}[auto,node distance=50]
\node (v6) at (-1.5,-3.5) {$1$};
\node (v14) at (-1,-1.5) {$+$};
\node (v17) at (-0.5,-3.5) {$2$};
\node (v19) at (0.5,-2.5) {$3$};
\node (v10) at (1.5,-2.5) {$4$};
\node (v20) at (1,-0.5) {$*$};
\node (v11) at (0,0.5) {$*$};
\node (v1) at (0,1.5) {$S_E$};
\node (v2) at (-1,0.5) {$S_E$};
\node (v7) at (1,0.5) {$S_E$};
\node at (0.5,-0.5) {$S_E$};
\node (v8) at (1.5,-0.5) {$S_E$};
\node (v18) at (0.5,-1.5) {$S_N$};
\node (v9) at (1.5,-1.5) {$S_N$};
\node (v12) at (-1.5,-0.5) {$($};
\node (v3) at (-1,-0.5) {$S_E$};
\node (v13) at (-0.5,-0.5) {$)$};
\node (v4) at (-1.5,-1.5) {$S_E$};
\node (v15) at (-0.5,-1.5) {$S_E$};
\node (v5) at (-1.5,-2.5) {$S_N$};
\node (v16) at (-0.5,-2.5) {$S_N$};
\draw (v1) -- (v2) -- (v3) -- (v4) -- (v5) -- (v6);
\draw (v1) -- (v7) -- (v8) -- (v9) -- (v10);
\draw (v1) -- (v11);
\draw (v2) -- (v12);
\draw (v2) -- (v13);
\draw (v3) -- (v14);
\draw (v3) -- (v15) -- (v16) -- (v17);
\draw (v7) -- (0.5,-0.5) -- (v18) -- (v19);
\draw (v7) -- (v20);
\end{tikzpicture}\\
$(1+2)*3*4$
\end{itemize}

\subsection{Kellerautomaten und kontextfreie Sprachen}
\paragraph{Satz:} Kellerautomaten akzeptieren genau die kontextfreien Sprachen.\\
Beweis: Wir zeigen nur: Für jede kontextfreie Grammatik $G$ gibt es einen PDA $\cM$ mit $L(G)=L(\cM)$.\\
Skizze: \\
Wir konstruieren einen PDA mit drei Zuständen:\\
\begin{tikzpicture}[shorten >= .3em,shorten <= .3em,auto,node distance=8em]
\node[state, initial] (z0){};
\node[state] (z1)[right of=z0]{};
\node[state, double, double distance = .5mm] (z2) [right of=z1] {};
\path (z0) edge [-latex] node{$\varepsilon,\varepsilon/\varepsilon$} (z1);
\path (z1) [loop above] edge node{$\varepsilon,A/\gamma$} (z1);
\path (z1) [loop below] edge node{$a,a/\varepsilon$} (z1);
\path (z1) edge [-latex] node{$\varepsilon,\#/\varepsilon$} (z2);
\end{tikzpicture}\\
Im Startzustand wird das Startsymbol $S$ der Grammatik auf den Stack abgelegt und der PDA wechselt in Zustand $Z$.\\
Wir unterscheiden 3 Fälle: Das oberste Stackzeichen ist…
\begin{itemize}
\item eine Variable $A$.\\
Wenn es eine Regel $A\to \gamma$ der Grammatik gibt, dann kann der PDA $A$ vom Stack entfernen und $\gamma$ auf den Stack schreiben.
\item ein Symbol $a\in \Sigma$.\\
Wenn das nächste Zeichen der Eingabe mit $a$ übereinstimmt, wird $a$ vom Stack entfernt.
\item das Zeichen $\#$.\\
Dann geht der PDA in den Endzustand über.
\end{itemize}
Richtung PDA$\to$kontextfreie Grammatik: Ohne Beweis.
\subparagraph{Bsp.:} Wir betrachten die Sprache $L=\{a^nb^n|n\geq 0\}$, die erzeugt wird von der Grammatik mit den Regeln:\\
$S\to aSb \,|\, \varepsilon$\\
Aus obiger Konstruktion erhalten wir folgenden PDA:\\
\begin{tikzpicture}[shorten >= .3em,shorten <= .3em,auto,node distance=8em, align=left]
\node[state, initial] (z0){};
\node[state] (z1)[right of=z0]{};
\node[state, double, double distance = .5mm] (z2) [right of=z1] {};
\path (z0) edge [-latex] node{$\varepsilon,\varepsilon/\varepsilon$} (z1);
\path (z1) [loop above] edge node{$\varepsilon,S/\varepsilon$\\$\varepsilon, S/aSb$} (z1);
\path (z1) [loop below] edge node{$a,a/\varepsilon$\\$b,b/\varepsilon$} (z1);
\path (z1) edge [-latex] node{$\varepsilon,\#/\varepsilon$} (z2);
\end{tikzpicture}\\
Verhalten für die Eingabe $aabb$:\\
\begin{tikzpicture}[align=left, scale=.8]
\draw (-5,1) -- (-5,-2) -- (-4,-2) -- (-4,1);
\node at (-4.5,-1.5) {$\#$};
\draw (-3,1) -- (-3,-2) -- (-2,-2) -- (-2,1);
\node at (-2.5,-1) {$S$};
\node at (-2.5,-1.5) {$\#$};
\draw (-1,1) -- (-1,-2) -- (0,-2) -- (0,1);
\node at (-0.5,0) {$a$};
\node at (-0.5,-0.5) {$S$};
\node at (-0.5,-1) {$b$};
\node at (-0.5,-1.5) {$\#$};
\draw (1,1)-- (1,-2) node[below right]{1. $a$\\verarbeitet}  -- (2,-2) -- (2,1);
\node at (1.5,-0.5) {$S$};
\node at (1.5,-1) {$b$};
\node at (1.5,-1.5) {$\#$};
\draw (3,1) -- (3,-2) -- (4,-2) -- (4,1);
\node at (3.5,0.5) {$a$};
\node at (3.5,0) {$S$};
\node at (3.5,-0.5) {$b$};
\node at (3.5,-1) {$b$};
\node at (3.5,-1.5) {$\#$};
\draw (5,1) -- (5,-2)node[below right]{2. $a$\\verarb.} -- (6,-2) -- (6,1);
\node at (5.5,0) {$S$};
\node at (5.5,-0.5) {$b$};
\node at (5.5,-1) {$b$};
\node at (5.5,-1.5) {$\#$};
\draw (7,1) -- (7,-2) -- (8,-2) -- (8,1);
\node at (7.5,-0.5) {$b$};
\node at (7.5,-1) {$b$};
\node at (7.5,-1.5) {$\#$};
\draw (9,1) -- (9,-2) node[below right]{1. $b$\\verarb.} -- (10,-2) -- (10,1);
\node at (9.5,-0.5) {};
\node at (9.5,-1) {$b$};
\node at (9.5,-1.5) {$\#$};
\draw (11,1) -- (11,-2) node[below right]{2. $b$\\verarb.} -- (12,-2) -- (12,1);
\node at (11.5,-1.5) {$\#$};
\end{tikzpicture}

\subsubsection{Der CYK-Algorithmus}
\paragraph{Def.:} Eine Grammatik $G=(V,\Sigma, P, S)$ liegt in \emph{Chomsky-Normalform} (CNF), wenn alle Regeln die Form $A\to BC$ oder $A\to a$ für $A,B,C \in V$, $a \in \Sigma$ haben.\\
Jede kontextfreie Grammatik $G$ mit $\varepsilon \not \in L(G)$ kann in CNF umgeformt werden.
\subparagraph{Bsp.:} Wir formen die Grammatik  mit den Regeln $S\to SS \,|\, (S) \,|\, ()$ in CNF um.
\begin{enumerate}[label=\arabic*.]
\item Schritt:\\
Terminalsymbole ersetzen durch neue Variablen: \\
$S\to SS \,|\, LSR \,|\, LR$\\
$L\to ($, $R \to )$
\item Schritt:\\
Mehrfache Variablen auf der rechten Seite ersetzen:\\
$S\to SS \,|\, LA \,|\, LR$\\
$A \to SR$\\
$L\to ($\\
$R\to )$
\end{enumerate}
Der Ableitungsbaum eines Wortes aus einer Grammatik in CNF ist -- bis auf die unterste Ebene -- ein binärer Wurzelbaum.\\
\begin{tikzpicture}
\node (v1) at (0.5,2.5) {S};
\node (v4) at (-2,-1) {};
\node (v9) at (-1,-1) {};
\node (v7) at (-0.5,-1) {};
\node (v11) at (0.5,-1) {};
\node (v18) at (1,-1) {};
\node at (2,-1) {};
\node (v20) at (2.5,-1) {};
\node (v14) at (3.5,-1) {};
\node (v13) at (3.5,0) {};
\node (v19) at (2.5,0) {};
\node (v16) at (2,0) {};
\node (v17) at (1,0) {};
\node (v10) at (0.5,0) {};
\node (v6) at (-0.5,0) {};
\node (v8) at (-1,0) {};
\node (v3) at (-2,0) {};
\node (v2) at (-1.5,1) {};
\node (v5) at (0,1) {};
\node (v15) at (1.5,1) {};
\node (v12) at (3,1) {};
\draw (v1) -- (v2) -- (v3) -- (v4);
\draw (v1) -- (v5) -- (v6) -- (v7);
\draw (v2) -- (v8) -- (v9);
\draw (v5) -- (v10) -- (v11);
\draw (v1) -- (v12) -- (v13) -- (v14);
\draw (v1) -- (v15) -- (v16) -- (2,-1);
\draw (v15) -- (v17) -- (v18);
\draw (v12) -- (v19) -- (v20);
\end{tikzpicture}\\
Wenn ein Wort $x=x_1x_2\dots x_n$ aus $S$ ableitbar ist ($S\Rightarrow^*x$), dann gibt es ein $ k $ und $ A,B $, sodass $ S\Rightarrow AB $ und $ A \Rightarrow* x_1\dots x_k , \; B\Rightarrow^*x_{k+1}...x_n $\\
\begin{tikzpicture}
\node (v1) at (0.5,2.5) {S};
\node (v2) at (-1,1.5) {A};
\node (v3) at (2,1.5) {B};
\draw (v1) -- (v2);
\draw (v1);
\draw (v1) -- (v3);
\draw (-1,1) -- (-2,-1) -- (0,-1) -- cycle;
\draw (2,1) -- (1,-0.5) -- (3,-0.5) -- cycle;
\node (v4) at (-2,-1.5) {$X_1$};
\node (v6) at (0,-1.5) {$X_k$};
\node (v8) at (1,-1) {$X_{k+1}$};
\node (v10) at (3,-1) {$X_n$};
\node (v5) at (-2,-2.5) {$x_1$};
\node (v7) at (0,-2.5) {$x_k$};
\node (v9) at (1,-2.5) {$x_{k+1}$};
\node (v11) at (3,-2.5) {$x_n$};
\draw (v4) -- (v5);
\draw (v6) -- (v7);
\draw (v8) -- (v9);
\draw (v10) -- (v11);
\end{tikzpicture}\\
Der CYK-Algorithmus entscheidet das Wortproblem, indem eine Tabelle konstruiert wird. Der Eintrag $T_{ij}$ ist die Menge der Variablen $X$ mit $X\Rightarrow^* x_i \dots x_j$:\\
\begin{tikzpicture}[scale=1.4]
\draw  (-2,3) rectangle (-1.5,2.5) node[pos=.5]{$T_{15}$};
\draw  (-2,2.5) rectangle (-1.5,2)node[pos=.5]{$T_{14}$};
\draw  (-2,2) rectangle (-1.5,1.5)node[pos=.5]{$T_{13}$};
\draw  (-2,1.5) rectangle (-1.5,1)node[pos=.5]{$T_{12}$};
\draw  (-2,1) rectangle (-1.5,0.5)node[pos=.5]{$T_{11}$} node [below left]{$x_1$};
\draw  (-1.5,2.5) rectangle (-1,2)node[pos=.5]{$T_{25}$};
\draw  (-1.5,2) rectangle (-1,1.5)node[pos=.5]{$T_{24}$};
\draw  (-1.5,1.5) rectangle (-1,1)node[pos=.5]{$T_{23}$};
\draw  (-1.5,1) rectangle (-1,0.5)node[pos=.5]{$T_{22}$} node [below left]{$x_2$};
\draw  (-1,2) rectangle (-0.5,1.5)node[pos=.5]{$T_{35}$};
\draw  (-1,1.5) rectangle (-0.5,1)node[pos=.5]{$T_{34}$};
\draw  (-1,1) rectangle (-0.5,0.5)node[pos=.5]{$T_{33}$} node [below left]{$x_3$};
\draw  (-0.5,1.5) rectangle (0,1)node[pos=.5]{$T_{45}$};
\draw  (-0.5,1) rectangle (0,0.5)node[pos=.5]{$T_{44}$} node [below left]{$x_4$};
\draw  (0,1) rectangle (0.5,0.5)node[pos=.5]{$T_{55}$} node [below left]{$x_5$};
\node (v1) at (2,2.5) {$T_{ij}$};
\node (v2) at (2,0.5) {$x_i$};
\node (v3) at (4,0.5) {$x_j$};
\draw (v1) -- (v2) -- (v3) -- (v1);
\end{tikzpicture}\\
Für $i<j$ wird geprüft, ob sich $x_i\dots x_j$ zerlegen lässt in $x_i\dots x_k,\; x_{k+1} \dots x_j$, so dass gilt:
\begin{enumerate} [label=(\roman*)]
\item es gibt eine Regel $X\to AB$
\item $A\Rightarrow^* x_i \dots x_k$, $B\Rightarrow^* x_{k+1}\dots x_j$.
\end{enumerate} 
Die Menge $T_{ij}$ enthält alle Variablen $x$ mit dieser Eigenschaft. Da (ii) nach Definition von $T_{ij}$ äquivalent ist zu $A \in T_{ik}, \; B\in T_{k+1\,j}$, erhalten wir $T_{(ii)}=\{x| \text{ es gibt eine Regel }X\to x_i\}$.\\
$T_{ij}=\bigcup_{i\leq k<j} \{x | \text{ es gibt eine Regel }X\to AB \wedge A \in T_{ik} \wedge B\in T_{k+1\, j}\}$\\
\begin{tikzpicture}[scale=1.2, align=left]
\draw  (-2,3) rectangle (-1.5,2.5) node[pos=.5]{$ $};
\draw  (-2,2.5) rectangle (-1.5,2)node[pos=.5]{$ $};
\draw  (-2,2) rectangle (-1.5,1.5)node[pos=.5]{$ $};
\draw  (-2,1.5) rectangle (-1.5,1)node[pos=.5]{$ $};
\draw  (-2,1) rectangle (-1.5,0.5)node[pos=.5]{$ $};
\draw  (-1.5,2.5) rectangle (-1,2)node[pos=.5]{$ $};
\draw  (-1.5,2) rectangle (-1,1.5)node[pos=.5]{$T_{ij}$};
\draw  (-1.5,1.5) rectangle (-1,1)node[pos=.5]{$ $};
\draw  (-1.5,1) rectangle (-1,0.5)node[pos=.5]{$A$};
\draw  (-1,2) rectangle (-0.5,1.5)node[pos=.5]{$ $};
\draw  (-1,1.5) rectangle (-0.5,1)node[pos=.5]{$B$};
\draw  (-1,1) rectangle (-0.5,0.5)node[pos=.5]{$ $};
\draw  (-0.5,1.5) rectangle (0,1)node[pos=.5]{$ $};
\draw  (-0.5,1) rectangle (0,0.5)node[pos=.5]{$ $};
\draw  (0,1) rectangle (0.5,0.5)node[pos=.5]{$ $};
\draw [thick, green] (-1.5,1) rectangle (-1,0.5);
\draw [thick, purple] (-1,1.5) rectangle (-0.5,1);
\draw [thick, orange] (-1.5,2) rectangle (-1,1.5);
\draw [thick, orange] (-1.5,0.3) -- (0,0.3);
\draw [thick, purple](-1,0.4) -- (0,0.4);
\draw [thick, green](-1.5,0.4) -- (-1,0.4);
\draw [-latex] (-2,0.1) -- (0.5,0.1) node[pos=.5, below]{1.};
\draw [-latex] (-2.2,0.5) -- (-2.2,3) node[pos=.5, left]{2.};
\node [below right] at (1,3) {Vorgehensweise beim befüllen:\\1. unterste Zeile\\2. obere Zeilen auf Basis der unteren};
\end{tikzpicture}\\
Wenn die Menge $T_{ij}$ in aufsteigender Reihenfolge von $j-i$ berechnet werden, dann können die Einträge der Tabelle aus bereits berechneten Einträgen bestimmt werden (dynamisches Programmieren). Für den Eintrag $T_{ij}$ müssen dabei alle Kombinationen geprüft werden, die den Zerlegungen $x_i \dots x_j=x_i\dots x_k x_{k+1} \dots x_j$ für $i\leq k < j$ entsprechen. Das Wort $x$ liegt genau dann in der Sprache, wenn $S \in T_{1n}$.\\
\begin{tikzpicture}[scale=1.5, align=left]
\draw  (-2,3) rectangle (-1.5,2.5) node[pos=.5]{$T_{15}$};
\draw  (-2,2.5) rectangle (-1.5,2)node[pos=.5]{$T_{14}$};
\draw  (-2,2) rectangle (-1.5,1.5)node[pos=.5]{$T_{13}$};
\draw  (-2,1.5) rectangle (-1.5,1)node[pos=.5]{$T_{12}$};
\draw  (-2,1) rectangle (-1.5,0.5)node[pos=.5]{$T_{11}$} node [below left]{$x_1$};
\draw  (-1.5,2.5) rectangle (-1,2)node[pos=.5]{$T_{25}$};
\draw  (-1.5,2) rectangle (-1,1.5)node[pos=.5]{$T_{24}$};
\draw  (-1.5,1.5) rectangle (-1,1)node[pos=.5]{$T_{23}$};
\draw  (-1.5,1) rectangle (-1,0.5)node[pos=.5]{$T_{22}$} node [below left]{$x_2$};
\draw  (-1,2) rectangle (-0.5,1.5)node[pos=.5]{$T_{35}$};
\draw  (-1,1.5) rectangle (-0.5,1)node[pos=.5]{$T_{34}$};
\draw  (-1,1) rectangle (-0.5,0.5)node[pos=.5]{$T_{33}$} node [below left]{$x_3$};
\draw  (-0.5,1.5) rectangle (0,1)node[pos=.5]{$T_{45}$};
\draw  (-0.5,1) rectangle (0,0.5)node[pos=.5]{$T_{44}$} node [below left]{$x_4$};
\draw  (0,1) rectangle (0.5,0.5)node[pos=.5]{$T_{55}$} node [below left]{$x_5$};
\draw  (-2,3.5) rectangle (-1.5,3)node[pos=.5]{$T_{16}$};
\draw  (-1.5,3) rectangle (-1,2.5)node[pos=.5]{$T_{26}$};
\draw  (-1,2.5) rectangle (-0.5,2)node[pos=.5]{$T_{36}$};
\draw  (-0.5,2) rectangle (0,1.5)node[pos=.5]{$T_{46}$};
\draw  (0,1.5) rectangle (0.5,1)node[pos=.5]{$T_{56}$};
\draw  (0.5,1) rectangle (1,0.5)node[pos=.5]{$T_{66}$} node [below left]{$x_6$};

\draw [thick, orange, opacity=1] (-1.5,3) node [above right]{zu untersuchen} rectangle (-1,2.5);
\draw [very thick, green, opacity=.75] (-1.5,2.5) rectangle (-1,2);
\draw [very thick, green, opacity=.75] (0.5,1) rectangle (1,0.5);
\draw [very thick, brown, opacity=.75] (-1.5,2) rectangle (-1,1.5);
\draw [very thick, brown, opacity=.75] (0,1.5) rectangle (0.5,1);
\draw [very thick, purple, opacity=.75] (-1.5,1.5) rectangle (-1,1);
\draw [very thick, purple, opacity=.75] (-0.5,2)rectangle (0,1.5);
\draw [very thick, red, opacity=.75] (-1.5,1) rectangle (-1,0.5);
\draw [very thick, red, opacity=.75] (-1,2.5) rectangle (-0.5,2);
\draw [thick,green] (-1.5,0.1) -- (0.48,0.1);
\draw [thick,green] (0.52,0.1) -- (1,0.1);
\draw [thick,brown] (-1.5,0) -- (-.02,0);
\draw [thick,brown] (0.02,0) -- (1,0);
\draw [thick,purple] (-1.5,-0.1) -- (-0.52,-0.1);
\draw [thick,purple] (-0.48,-0.1) -- (1,-0.1);
\draw [thick,red] (-1.5,-0.2) -- (-1.02,-0.2);
\draw [thick,red] (-0.98,-0.2) -- (1,-0.2);
\draw [thick,orange] (-1.5,0.2) -- (1,0.2);
\node [right] at (1.2,0) {$\leftarrow T_{26}$ kann potentiell durch diese Kombinationen gebildet werden};
\end{tikzpicture}\\
$T_{26}=\bigcup_{2\leq k<5}\{x| x\to AB \wedge \underbrace{A \Rightarrow^* x_2\dots x_k}_{\Leftrightarrow A \in T_{2k}}, \; \underbrace{B\Rightarrow^* x_{k+1}\dots x_6}_{\Leftrightarrow B \in T_{k+1\, 6}}\}$
\begin{itemize}
\item $k=2$: $A\in T_{22},\; B \in T_{36}$ (rot)
\item $k=3$: $A \in T_{23}, \; B \in T_{46}$ (lila)
\item $k=4$: $A\in T_{24}, \; B \in T_{56}$ (braun)
\item $k=5$: $A \in T_{25}, \; B \in T_{66}$ (grün)
\end{itemize}
\subparagraph{Bsp.:} Wir prüfen $(()()) \in L(G')$ für die Grammatik $G'$ in CNF, die die Sprache der korrekten Klammerung erzeugt (siehe Übung: $S\to SS,\; S \to LA,\; A\to SR$).\\
\begin{tikzpicture}[scale=1.5]
\draw  (-2,3) rectangle (-1.5,2.5);
\draw  (-2,2.5) rectangle (-1.5,2);
\draw  (-2,2) rectangle (-1.5,1.5);
\draw  (-2,1.5) rectangle (-1.5,1);
\draw  (-2,1) rectangle (-1.5,0.5) node [below left]{$($};
\draw  (-1.5,2.5) rectangle (-1,2);
\draw  (-1.5,2) rectangle (-1,1.5);
\draw  (-1.5,1.5) rectangle (-1,1);
\draw  (-1.5,1) rectangle (-1,0.5) node [below left]{$($};
\draw  (-1,2) rectangle (-0.5,1.5);
\draw  (-1,1.5) rectangle (-0.5,1);
\draw  (-1,1) rectangle (-0.5,0.5) node [below left]{$)$};
\draw  (-0.5,1.5) rectangle (0,1);
\draw  (-0.5,1) rectangle (0,0.5) node [below left]{$($};
\draw  (0,1) rectangle (0.5,0.5) node [below left]{$)$};
\draw  (-2,3.5) rectangle (-1.5,3);
\draw  (-1.5,3) rectangle (-1,2.5);
\draw  (-1,2.5) rectangle (-0.5,2);
\draw  (-0.5,2) rectangle (0,1.5);
\draw  (0,1.5) rectangle (0.5,1);
\draw  (0.5,1) rectangle (1,0.5) node [below left]{$)$};
\node (v1) at (-1.75,3.25) {$S$};
\node (v2) at (-1.75,0.75) {$L$};
\node (v3) at (-1.25,2.75) {$A$};
\node (v4) at (-1.25,2.25) {$S$};
\node (v6) at (-1.25,1.25) {$S$};
\node (v8) at (-1.25,0.75) {$L$};
\node (v9) at (-0.75,0.75) {$R$};
\node (v12) at (-0.25,1.75) {$R$};
\node (v7) at (-0.25,1.25) {$S$};
\node (v10) at (-0.25,0.75) {$L$};
\node (v11) at (0.25,0.75) {$R$};
\node (v5) at (0.75,0.75) {$R$};
\draw [green] (v2) -- (v1) -- (v3);
\draw [orange] (v6) -- (v4) -- (v7);
\draw [brown] (v8) -- (v6) -- (v9);
\draw [purple] (v10) -- (v7) -- (v11);
\draw [red] (v7) -- (v12) -- (v5);
\draw [blue] (v4) -- (v3) -- (-0.125,1.875) -- (v5);
\draw [-latex] (-2,0) -- (1,0) node[pos=.5, below, align=center]{1. Wort nach Zeichen\\ aufschreiben};
\draw [-latex] (-2.5,0.5) -- (-2.5,3.5) node[pos=.5, left, align=right]{2. Regeln \\suchen};
\end{tikzpicture}\\
Die Laufzeit des CYK-Algorithmus ergibt sich aus\\
(Größe der Tabelle)$\cdot$(Aufwand pro Tabelleneintrag)$=O(n^2) \cdot O(n)=O(n^3)$.
\begin{lstlisting}[language=C]
$T_{ij}:= \emptyset$
for (k=i; k<j; k++) {
	if (Regel $X\to AB$ $\wedge$ $A \in T_{ik}$ $\wedge$ $B \in T_{k+1\,j}$)
		$T_{ij}$ += {x}
}
\end{lstlisting}

\subsection{Mehrdeutigkeit}
Grammatik für arithmetische Ausdrücke:\\
$E\to E+E \,|\, E - E \,|\, E*E \,|\, E/E \,|\, x \,|\, y \,|\, z$\\
Daraus lässt sich abbilden:\\
\begin{tikzpicture}[scale=1]
\node (v3) at (0,0) {$E$};
\node at (v3) [right=.3, orange] {$x*(y+z)$ \lightning};
\node (v2) at (-1,-1) {$E$};
\node (v7) at (0,-1) {$*$};
\node (v4) at (2,-1) {$E$};
\node at (v4) [right=.3, orange] {$y+z$};
\node (v1) at (-1,-2) {$x$};
\node (v8) at (1,-2) {$E$};
\node (v10) at (2,-2) {$+$};
\node (v5) at (3,-2) {$E$};
\node (v9) at (1,-3) {$y$};
\node (v6) at (3,-3) {$z$};
\draw (v1) -- (v2) -- (v3);
\draw (v3) -- (v4) -- (v5) -- (v6);
\draw (v3) -- (v7);
\draw (v4) -- (v8) -- (v9);
\draw (v4) -- (v10);
\node at (-1,-4) {$x$};
\node at (0,-4) {$*$};
\node at (1,-4) {$y$};
\node at (2,-4) {$+$};
\node at (3,-4) {$z$};
\end{tikzpicture} \quad
\begin{tikzpicture}[scale=1]
\node (v3) at (0,0) {$E$};
\node at (v3) [right=.3, orange] {$(x*y)+z$ \checkmark};
\node (v2) at (1,-1) {$E$};
\node (v7) at (0,-1) {$+$};
\node (v4) at (-2,-1) {$E$};
\node at (v4) [left=.3, orange] {$x*y$};
\node (v1) at (1,-2) {$z$};
\node (v8) at (-3,-2) {$E$};
\node (v10) at (-2,-2) {$*$};
\node (v5) at (-1,-2) {$E$};
\node (v9) at (-3,-3) {$x$};
\node (v6) at (-1,-3) {$y$};
\draw (v1) -- (v2) -- (v3);
\draw (v3) -- (v4) -- (v5) -- (v6);
\draw (v3) -- (v7);
\draw (v4) -- (v8) -- (v9);
\draw (v4) -- (v10);
\node at (1,-4) {$z$};
\node at (0,-4) {$+$};
\node at (-3,-4) {$x$};
\node at (-2,-4) {$*$};
\node at (-1,-4) {$y$};
\end{tikzpicture}\\
Diese Grammatik ist auch mehrdeutig, wenn man sich auf nur einen Operator beschränkt:\\
ABB 112\\
Da $-$ links-assoziativ ist, stellt nur der linke Ableitungsbaum die korrekte Interpretation des Ausdrucks $x-y-z$ dar.\\
$\Rightarrow$ Ableitungsbäume dürfen nicht verdreht werden!\\
Eine Grammatik $G$ heißt \emph{eindeutig}, wenn es für alle Wörter $w \in L(G)$ \emph{genau einen} Ableitungsbaum gibt.\\
Um eine eindeutige Grammatik zu erhalten, müssen zwei Probleme gelöst werden:
\begin{enumerate}
\item Die Priorität der Operatoren
\item Die Assoziativität der Operatoren
\end{enumerate}
… müssen beachtet werden.\\
Lösung für:
\begin{enumerate}
\item Die Grammatik muss so konstruiert werden, dass die Strichoperatoren nur auf der obersten Ebene, die Punktoperatoren nur auf der untersten Ebene erzeugt werden können.\\
$E\to E+E \,|\, E-E \,|\, F \\
F \to F*F \,|\, F/F \,|\, x \,|\, y \,|\, z$
\item Die Grammatik muss so beschaffen sein, dass der Ableitungsbaum, gemäß der Richtung der Assoziativität, bei einem links-assoziativen Operator nur nach links wachsen kann.\\
Basierend auf der Lösung für 1.) (mit $T$: Term, $F$: Faktor):\\
$E\to E+T \,|\, E-T \,|\, T \\
T \to T*F \,|\, T/F \,|\, F\\
F \to x \,|\, y \,|\, z$
\end{enumerate}
Diese Grammatik ist eindeutig.\\
Der Ableitungsbaum für $x*y+z$ ist:\\
ABB 113\\
Der Ableitungsbaum für $x-y-z$ ist:\\
ABB 114

\subsection{Syntaxanalyse}

\begin{lstlisting}[language=C]
if ( x<0 || y<0 ) {
	...
} else if
	...
\end{lstlisting}
$\downarrow$\\
Lexer\\
ABB 115\\
$\downarrow$\\
Parser\\
$\downarrow$\\
Syntaxbaum
\paragraph{Ziel:} Aus einem Wort einer kontextfreien Sprache soll ein soll ein Syntaxbaum erzeugt werden. Der CYK-Algorithmus ist dafür geeignet, besitzt jedoch eine Laufzeit in $O(n^3)$. Für deterministische kontextfreie Sprachen lässt sich das Wortproblem in Zeit $O(n)$ entscheiden.\\
Wir erlauben dem Parser, die nächsten $k$ Zeichen der Eingabe (\emph{lookahead}) zu sehen, um abhängig davon Entscheidungen zu treffen.

\subsubsection{Top-Down-Parser}
Ein Top-Down-Parser baut den Syntaxbaum von oben nach unten auf. Ein \emph{Recursive Descent Parser} ist ein Top-Down-Parser, der die Regeln der kontextfreien Grammatik als rekursive Funktionen implementiert.

Beispiel für Sprache $a^nb^n$:
\begin{lstlisting}[language=java]
public class Parser {
	String input;
	int pos;
	
	boolean parse (String inptu0) {
		input = input0 + "#";
		pos = 0;
		return S() && match('#');
	}
	
	boolean S() {	
		if( next() == 'a' )
			return match('a') && S() && match('b');	// entspricht S$\to$aSb
		else return true;	// entsrpicht S$\to$$\varepsilon$
	}
	
	char next() {
		return input.charAt(pos);
	}
	
	boolean match(char c) {	// entspricht Schleife im Kellerautomat: a,a/$\varepsilon$ und b,b/$\varepsilon$ bzw. S,$\varepsilon$/aSb
		if( next() == c ){
			pos++;
			return true;
		}
		else return false;
	}
	
	public static void main(String[] args){
		Parser p = new Parser();
		System.out.println(p.parse("aabb"));	// true
		System.out.println(p.parse("aaabb"));	// false
		System.out.println(p.parse("aabbb"));	// false
	}
}
\end{lstlisting}
Ablauf des Programms für \emph{aabb}:\\
ABB 116\\
Achtung: nicht alle Grammatiken lassen sich mit einem rekursiven Abstiegsparser darstellen. Bsp.: $E\to E+T$:
\begin{lstlisting}[language=java]
boolean E() {
	return E() && match('+') && T();	// Endlosschleife durch Selbstaufruf
}	
\end{lstlisting}
Aus der bereits behandelten Grammatik für arithmetische Ausdrücke kann kein Recursive Descent Parser erzeugt werden, weil die Grammatik linksrekursiv ist. Mögliche Abhilfe: Beseitigung der linksrekursion durch Umbau der Grammtik.\\
Ansatz:\\
$E \to T \tred{(}+E \tred{)} \,|\, T \tred{(}-E\tred{)} \,|\, T$\\
$T \to F \tred{(}*T\tred{)} \,|\, F \tred{(}/T \tred{)} \,|\, F \tred{(\varepsilon)}$\\
$\Rightarrow$\\
$E \to T E'\\
E' \to \varepsilon \,|\, + E \,|\, -E\\
T \to FT'\\
T' \to \varepsilon \,|\, *T \,|\, /T\\
F \to x\,|\,y\,|\,z$\\
Diese Grammatik erzeugt die gleiche Sprache wie die vorherige Grammatik und ist nicht linksrekursiv. Aber die Ableitungsbäume wachsen nach rechts, d.h. alle Operatoren sind rechts-assoziativ.\\
ABB 117\\
Das Problem lässt sich für Recursive Descent Parser nicht befriedigend lösen, Man kann links-assoziative Operatoren durch Schleifen verarbeiten. Dazu: EBNF (Extended Backus-Naur-Form).\\
Obige Grammatik in EBNF:\\
$E\to T \{ \{+|-\} T \}$\\
$T \to F \{ (*|/)F\}\\
F \to x\,|\,y\,|\,z$\\
Dabei bedeutet $\{ +T \}$, dass beliebig viele $+T$ folgen können. $\{...\}$ entspricht $(...)^*$.\\
Problem: Aus dieser Grammatik geht die Assoziativität der Operatoren nicht hervor. Diese muss festgelegt werden. Links-assoziative Operatoren können mit einer Schleife verarbeitet werden:
\begin{lstlisting}[language=C]
E() {
 T();
 while (next() == '+') {	// while-Schleife entspricht $\{+T\}$
 	match ('+');
 	T();
 }
}
\end{lstlisting}
(SimpleInfixCalc.java)


\subsubsection{Bottom-Up-Parser}
Ein \emph{Bottom-Up-Parser} baut einen Ableitungsbaum von unten nach oben auf und kontrolliert dabei die Rechtsableitung der Eingabe. Bottom-Up-Parser lassen sich effizient durch LR-Parser implementieren. Ein LR-Parser liest die Eingabe von links nach rechts und erzeugt den Ableitungsbaum der Rechtsableitung. Ein LR-Parser führt in jedem Schritt eine von vier möglichen Aktionen aus:
\begin{itemize}
\item \textbf{Shift}: Das nächste Zeichen der Eingabe wird auf den Stack geschoben.
\item \textbf{Reduce}: Ein oder mehrere Symbole von der Spitze des Stack entsprechen der rechten Seite $A \to \gamma$ einer Regel und werden durch $A$ ersetzt.
\item \textbf{Accept}: Die Eingabe wurde verarbeitet, der Stock enthält nur das Startsymbol.
\item \textbf{Error}: Ein Syntaxfehler wird gemeldet.
\end{itemize}
\subparagraph{Bsp.:} Wir betrachten die Grammatik für arithmetische Ausdrücke:\\
$E \to E + T \,|\, E-T \,|\, T\\
T \to T*F \,|\, T/F \,|\, F\\
F \to x \,|\, y \,|\, z$\\
Für die Eingabe $x+y*z$ führt ein LR-Parser folgende Schritte aus:\\
\begin{tabular}{l r c}
Stack & restl. Eingabe &Aktion\\
\hline
& $x+y*z$ & shift\\
$x$ & $+y*z$ & reduce\\
$F$ & $+y*z$ & reduce\\
$T$ & $+y*z$ & reduce\\
$E$ & $+y*z$ & shift \\
$E+$ & $y*z$ & shift \\
$E+y$ & $*z$ & reduce\\
$E+F$ & $*z$ & reduce\\
$E+T$ & $*z$ & shift\footnotemark\\
$E+T*$ & $z$ & shift \\
$E+T*z$ & & reduce \\
$E+T*F$ & & reduce \\
$E+T$ & & reduce \\
$E$ & & accept
\end{tabular}
\footnotetext{hier würde reduce stecken bleiben, weil es keine Regel für $E+E$ geben würde. Der Parser „weiß“ das aus Ableitungstabellen.}\\
Der vom Parser erzeugte Ableitungsbaum der Rechtsableitung (Rechtsableitung ersichtlich dadurch, dass sich rechts alle Änderungen passieren, und die linke Seite unberührt bleibt) ergibt sich aus den ersten beiden Spalten, von unten nach oben gelesen.
\begin{lstlisting}[language=C]
%{
#include "calc.tab.h"
%}

integer [0-9]+
real {integer}("."{integer})?([eE][+-]?{integer})?

%%

{real}			{yylval.number = atof(yytext); return NUM;}
[ \t]+			;
\n					{return NL;}
...

// Mit diesem Code kann mit Bison ein C-Programm erzeugt werden, dass diesen Parser implementiert
\end{lstlisting}


\subsection{OL-Systeme}
Zur Darstellung benötigen wir Turtle-Grafik:\\
ABB 136\\
Befehle:\\
$forward (l)$ \\
$left (\alpha)$ bzw. $right(\alpha)$

Im Unterschied zu einer kontextfreien Grammatik wird in einem OL-System in jedem Ableitungsschritt jede Variable ersetzt. Jede Variable wird dabei durch die gleiche Regel ersetzt. Anstelle eines Startsymbols gibt es eine initiale Satzform.
\subparagraph{Bsp.:} \parskp
Variable: $F$\\
Symbole: $+,-$\\
Regel: $F\to F+F--F+F$\\
$F\Rightarrow F+F --F + F \\
\Rightarrow \underbrace{F + F -- F + F}_{1.\,F} + \underbrace{F + F -- F + F}_{2.\,F} -- \underbrace{F + F -- F + F}_{usw.} + \underbrace{F + F -- F + F}$\\
Graphische Darstellung:\\
$F= forward$\\
$+=left(60^\circ)$\\
$-=right(60^\circ)$\\
ABB 137
\section{Die Chomsky Hierarchie}
Für Grammatiken:\\
\begin{tabular}{L{0.3} L{0.5} L{0.2}}
Typ & in aller Regeln $u\to r$ gilt & Beispiele\\
\hline
0 (rekursiv aufzählbar) & $u,r$ beliebig & $ab\to c$\\
1 (kontext sensitiv) & $u=\alpha X \beta, \; v = \alpha \gamma \beta$ mit $\alpha, \beta \in (V\cup \Sigma)^*, \; x \in V, \; \gamma \in (V\cup \Sigma)^+$ & $aAb \to aBb$\\
2 (kontextfrei) & $u \in V, \; v\in (V \cup \Sigma)^*$ & $A \to aBb$\\
3 (regulär) & $u\in V, \; v \in \Sigma \cup \{\varepsilon\} \cup \Sigma V$ & $A \to a$, $A\to aB$
\end{tabular}\\
weitere Beispiele:
\begin{enumerate}[start=0]
\item $(a+b) \cdot c \to a\cdot c + b \cdot c$
\item Artikel$_m$ Nomen $\to$ Artikel$_m$ Kater\\
Artikel$_f$ Nomen $\to$ Artikel$_f$ Katze
\item - 
\item (ist linear im rechten Teilbaum entartet)
\end{enumerate}
Chomsky-Hierarchie mit Beispielsprachen:\\
ABB 138\\
Eine Sprache hat mindestens die gleiche Klasse wie seine Grammatik, kann aber auch eine höhere haben. Für eine reguläre Sprache muss ein regulärer Ausdruck konstruierbar sein.
\chapter{Berechenbarkeit und Komplexität}
Frage: Was können Computer berechnen, was können Computer effizient berechnen?\\
ABB 139 (Turing Maschine)
\section{Entscheidbarkeit}
Entscheidungsproblem: Gegeben eine Sprache $L$ und ein Wort $w\in \Sigma^*$. Gehört $w$ zu $L$ ($w\in L$)?

Wir kennen bereits entscheidbare Probleme:
\begin{itemize}
\item Wenn $L$ als regulärer Ausdruck gegeben ist, dann ist $w\in L$ entscheidbar durch folgendes Verfahren: 
\begin{itemize}
\item Regulären Ausdruck in DFA umwandeln.
\item DFA die Eingabe $w$ übergeben.
\item Wenn DFA einen Endzustand erreicht gilt $w\in L$, sonst $w\not \in L$.
\end{itemize}
\item $L=\emptyset$ ist entscheidbar, durch ein Entscheidungsverfahren, das immer „falsch“ liefert.
\item $L=\Sigma^*$ ist entscheidbar, durch ein Entscheidungsverfahren, das immer „richtig“ liefert.
\item Wenn $L$ als kontextfreie Grammatik gegeben ist, ist $L$ entscheidbar über:
\begin{itemize}
\item Umformung in CNF
\item Anwendung des CYK-Algorithmus
\end{itemize}
\end{itemize}

\paragraph{Def.:} Eine Sprache $L$ heißt \emph{entscheidbar}, wenn es ein Programm $P_L$ (Entscheidungsverfahren) gibt, wenn gilt
\begin{itemize}
\item für $w\in L$ liefert $P_L$ die Ausgabe $true$
\item für $w \not \in L$ liefert $P_L$ die Ausgabe $false$.
\end{itemize}

\subparagraph{Bsp.:}
\begin{itemize}
\item Wenn $L$ eine kontextfreie Sprache, ist, dann ist $L$ entscheidbar durch den CYK-Algorithmus.
\item Die Sprache $L= \{ (M,w) \;|\; M \text{ ist ein DFA mit }w\in L(M)\}$ ist entscheidbar durch ein Programm des aus der Eingabe $(M,w)$ eine Repräsentation des DFA erstellt und damit $M$ für die Eingabe $w$ simuliert (vgl. Darstellung eines Interpreters in Zusammenhang mit der erweiterten Überführungsfunktion $\tilde{\delta}$).
\item Die Sprache $\{ M \;|\; M \text{ ist ein DFA mit }L(M)=\Sigma^*\}$ ist entscheidbar (siehe Übung).
\item Allgemein: $\{(P,w)\;|\;P \text{ hält für }w\}$. Im Beispiel: Collatz-Problem.
\end{itemize}
\section{Halteproblem}
Das Halteproblem ist die Sprache $H=\{ (P,w) \;|\; \text{Das Programm $P$ hält für die Eingabe }w\}$. Die Frage, ob ein Programm $P$ für eine gegebene Eingabe $w$ hält, ist damit gleichwertig zur Frage $(P,w)\in H$. Wir beweisen zunächst die Unentscheidbarkeit eines Spezialfalls.
\paragraph{Satz:} Das spezielle Halteproblem $K=\{P\;|\;\text{das Programm $P$ hält für die Eingabe }P\}$ ist unentscheidbar.
\subparagraph{Bsp.:}
\begin{itemize}
\item für ein Programm $P \in K$:\begin{lstlisting}[language=C]
void P( Input w ) {
	return;
}
\end{lstlisting}
\item für ein Programm $P \not \in K$:
\begin{lstlisting}[language=C]
void P( Input w ) {
	while(true);
}
\end{lstlisting}
\end{itemize}
Beweis (Widerspruch):\\
Angenommen, $K$ sei entscheidbar durch ein Entscheidungsverfahren $P_K$. Daraus konstruieren wir ein Programm $P_K^*$, das $P_K$ als Unterprogramm verwendet und das
\begin{itemize}
\item in eine Endlosschleife übergeht, wenn $P_K$ $true$ liefert
\item hält, wenn $P_K$ $false$ liefert.
\end{itemize}
ABB 148\\
Nach Konstruktion gilt dann:
\begin{itemize}
\item Für die Eingabe $P$ hält $P_K^*$ genau dann, wenn $P_k$ false enthält.
\end{itemize}
Da nach Annahme $P_K$ ein Entscheidungsverfahren für $K$ ist, bedeutet das:
\begin{itemize}
\item Für die Eingabe $P$ hält $P_K^*$ genau dann, wenn $P$ für die Eingabe $P$ nicht hält.
\end{itemize}
Für $P=P_K^*$ folgt:
\begin{itemize}
\item Für die Eingabe $P_K^*$ hält $P_K^*$ genau dann, wenn $P_K^*$ für die Eingabe $P_K^*$ nicht hält.
\end{itemize}
Widerspruch!\medskip\\
Folgerung: Das Halteproblem $H$ ist unentscheidbar.\\
Beweis: Angenommen, $H$ wäre entscheidbar durch $P_H$. Dann können wir folgendes Entscheidungsverfahren für $K$ konstruieren:
\begin{lstlisting}[language=C]
bool P_K ( Programm P ) {
	return P_H(P,P);
}
\end{lstlisting}
Widerspruch!

\subsection{Weitere unentscheidbare Probleme}
Um die Unentscheidbarkeit weiterer Probleme zu zeigen, verwenden wir einen Beweis durch Widerspruch nach folgender Bauart:
\begin{itemize}
\item Um die Unentscheidbarkeit einer Formalen Sprache $B$ zu zeigen, verwenden wir eine unentscheidbare Sprache $A$.
\item Wir nehmen an, dass die Sprache $B$ entscheidbar ist. Folglich gibt es ein Entscheidungsverfahren für $B$.
\item Wir zeigen, dass sich damit ein Entscheidungsverfahren für A konstruieren lässt.\\
Widerspruch!
\end{itemize}

Anwendung:
\paragraph{Satz:} Das Halteproblem $H$ ist nicht entscheidbar.\\
$H=\{(P,w)\;|\; P \text{ hält für }w \}$\\
$K=\{P\;|\;P \text{ hält für } P\}$
\begin{proof}
Angenommen $H$ ist entscheidbar. \\
Dann gibt es ein Entscheidungsverfahren $P_H$ für $H$. \\
Dann können wir folgendes Programm konstruieren:
\begin{lstlisting}[language=Java]
boolean $P_K$ (Program P) {
	return $P_H$(P,P);
}
\end{lstlisting}
Dann gilt: $\underline{P\in K} \Leftrightarrow P \text{ hält für } P \Leftrightarrow (P,P) \in H \Leftrightarrow \underline{P_H(P,P) \text{ ist true}}$\\
Widerspruch, da $K$ unentscheidbar ist.
\end{proof}
\paragraph{Satz:} $H_\varepsilon = \{P \;|\; P \text{ hält für die Eingabe }\varepsilon\}$
\begin{proof}
Angenommen, $H_\varepsilon$ ist entscheidbar.\\
Dann gibt es Entscheidungsverfahren $P_{H_\varepsilon}$ für $H_\varepsilon$.\\
Damit können wir folgendes Programm konstruieren:
\begin{lstlisting}[language=Java]
boolean $P_H$ (Program P, Input w){
	void F() {
		P(w);
	}
	return $P_{H_\varepsilon}$(F);
}
\end{lstlisting}
Dann gilt: $(P,w) \in H \Leftrightarrow P \text{ hält für }w \Leftrightarrow F \text{ hält für }\varepsilon \Leftrightarrow F \in H_\varepsilon$\\
Widerspruch, da $H$ unentscheidbar ist.
\end{proof}
\paragraph{Satz:} $H^*=\{P \;|\; P \text{ hält für jede Eingabe}\}$ ist nicht entscheidbar.
\begin{proof}
Angenommen, $H^*$ ist entscheidbar durch ein Entscheidungsverfahren $P_{H^*}$.\\
Dann können wir folgendes Programm konstruieren:
\begin{lstlisting}[language=Java]
boolean $P_{H_\varepsilon}$(Program P) {
	void F(Input w){
		P($\varepsilon$);
	}
	return $P_{H^*}$(F);
}
\end{lstlisting}
Dann gilt: $P\in H_\varepsilon \Leftarrow P \text{ hält für die Eingabe }\varepsilon\Leftrightarrow F \text{ hält für jede Eingabe }w \Leftrightarrow F \in H^*$\\
Widerspruch, da $H_\varepsilon$ nicht entscheidbar.
\end{proof}

\paragraph{Satz:} $\ddot{A}=\{(P_1, P_2) \;|\; P_1, P_2 \text{ berechnen die gleichen Funktionen}\}$ ist nicht entscheidbar.
\begin{proof}
Angenommen $\ddot{A}$ ist entscheidbar durch $P_{\ddot{A}}$.\\
Dann konstruieren wir das Programm:
\begin{lstlisting}[language=Java]
boolean $P_{H^*}$(Program P){
	int F(Input w){
		return 0;
	}
	int G(Input w){
		P(w);	// hält P(w) immer? Nur dann ist G 0.
		return 0;
	}
	return $P_{\ddot{A}}$(F,G);
}
\end{lstlisting}
Dann gilt: $P\in H^* \Leftrightarrow P \text{ hält für jede Eingabe }w \Leftrightarrow G \text{ berechnet }w\mapsto 0\\
\Leftrightarrow F,G \text{ berechnen die gleiche Funktion}\Leftrightarrow (F,g)\in \ddot{A}$ (genau dann, wenn ich $H^*$ entscheiden kann, kann ich $\ddot{A}$ entscheiden)\\
Widerspruch, da $H^*$ unentscheidbar. 
\end{proof}

\subsubsection{Unentscheidbarkeit der Programmverifikation}
ABB 170\\
Aus der Unentscheidbarkeit des Halteproblems folgt:\\
$\{ (P,S) \; | \; $Das Programm $P$ erfüllt die Spezifikation $S\}$ ist unentscheidbar.\\
Auch unentscheidbar:
\begin{itemize}
\item $\{P\;|\;P$ verursacht keine Division durch $0\}$
\item $\{P\;|\;P$ verursacht keine Array-out-Bound-Fehler$\}$
\item $\{P\;|\;P$ dereferenziert keine Nullpointer$\}$
\end{itemize}
Möglicher Ausweg:\\
Verifizierer liefert ja, nein \emph{oder} unbekannt.

\chapter{Komplexität}
Frage: Gibt es Probleme, die zwar lösbar (entscheidbar) sind, aber dazu einen sehr großen Rechenaufwand erfordern?\medskip\\
Kostenmaße:
\begin{itemize}
\item Uniforme Kostenmaß:\\
Alle Operationen erfordern konstanten Aufwand (LZ in $O(1)$)
\item Logarithmisches Kostenmaß:\\
Alle Operationen erfordern logarithmischen Aufwand (LZ in $O(\log n)$)
\end{itemize}
Im folgenden verwenden wir das uniforme Kostenmaß, wo angemessen.

\section{Die Klasse P}
\paragraph{Def.:} $P=\bigcup_{k>0} \{ L\;|\; L$ ist entscheidbar durch ein Programm LZ in $O(n^k)\}$
\subparagraph{Bsp.:} Folgende Sprachen bzw. Probleme liegen in $P$:
\begin{itemize}
\item $\emptyset$, $\Sigma^*$ (LZ $O(1)$)
\item $\{a^n\;| \; n\geq 0\}$ (muss maximal $n$ Zeichen überprüfen: LZ $O(n)$)
\item Jede kontextfreie Sprache $L$, da $L$ duch den CYK-Algorithmus in Zeit $O(n^3)$ entschieden werden kann.
\end{itemize}
\subparagraph{Bsp.:} Das Problem $PFAD=\{(G,n_1,n_2)\;|\; G$ ist ein Graph, in dem es einen Pfad von $n_1$ nach $n_2$ gibt $\}$ liegt in $P$.\\
Veranschaulichung:\\
ABB 171\\
Der Graph $G$ sei dabei als Adjazenzliste gegeben.
\begin{proof}
Da die Adjazenzliste von $G=(V,E)$ mindestens $|V|+|E|$ Elemente enthält, gilt für die Länge $n$ der Eingabe: $n\geq |V|+|E|$.\\
Ein Entscheidungsverfahren für $PFAD$ ist eine in $n_1$ gestartete Breitensuche nach $n_2$, die die LZ $O(|V|+|E|)$ besitzt. Folglich ist die LZ des Entscheidungsverfahrens $\leq c \cdot (|V|+|E|) \leq c \cdot n \in O(n)$. 
\end{proof}
Das gleiche Ergebnis erhalten wir, wenn die LZ nur in $|V|$ gemessen wird: Denn es gilt $n \geq |V|$. Für die LZ der Breitensuche gilt: LZ$\in O(|V|+|E|)\subseteq O (|V|+|V|^2)=O(|V|^2)\subseteq O(n^2)$.  Auch damit folgt $PFAD \in P$.\medskip\\
Die Klasse $P$ wird betrachtet als Klasse der effizient lösbaren Probleme.

\section{Die Klasse NP}
Die Klasse $NP$ (nicht deterministisch polynomiell) enthält alle Probleme, die in polynomieller Zeit verifizierbar sind.
\subparagraph{Bsp.:} $PFAD \in NP$, denn mit Hilfe eines Zertifikates lässt sich prüfen, dass es in $G$ einen Pfad von $n_1$ nach $n_2$ gibt und die LZ dafür ist polynomiell:\\
Das Zertifikat ist der Pfad selbst, die LZ liegt in $O(|V|^2)$.
\subparagraph{Bsp.:} $SAT=\{F\;|\;F$ ist eine erfüllbare Formel der Aussagenlogik$\}$. Zum Beispiel gilt $x\vee y \in SAT$, $x\wedge \neg x \not \in SAT$.\\
$SAT$ ist entscheidbar durch die Konstruktion einer Wahrheitstabelle. Wenn $F$ $n$ Variablen enthält, benötigt dies die LZ $O(2^n)$ (liegt also nicht in $P$).\\
$SAT$ lässt sich jedoch effizient (d.h. in polynomieller Zeit) verifizieren, wenn als Zertifikat eine erfüllende Belegung für $F$ gegeben ist. Die LZ für die Verifikation liegt dann in $O(|F|)$. Deshalb gilt $SAT \in NP$.\\
ABB 176\\
LZ des Entscheidungsverfahrens polynomiell $\Rightarrow A \in P$ \\
ABB 177\\
LZ des Verifizierungsverfahrens polynomiell $\Rightarrow A \in NP$
\paragraph{Def.:} $NP = \bigcup_{k\geq 1}\{L\;|\; L$ ist verifizierbar in Zeit $O(n^k)\}$, wobei $n$ die Länge der Eingabe ist.

\paragraph{Satz:} $P \subseteq NP$.
\begin{proof}
(Skizze) Sei $L \in P$. Dann kann $L$ in polynomieller Zeit entschieden werden. Ein Entscheidungsverfahren ist aber auch ein Verifizierungsverfahren, das kein Zertifikat (oder das Zertifikat $\varepsilon$) verwendet. Folglich gilt $P \in NP$.
\end{proof}
Unbekannt ist, ob $P=NP$ gilt.\\
Weiterhin gibt es Sprachen, von denen nicht bekannt ist, ob sie in $NP$ liegen. Ein Beispiel ist $TAUT=\{F\;|\; F$ ist eine Tautologie$\}$. Es wird $TAUT \not \in NP$ vermutet.

\subsection{NP-Vollständigkeit}
Die $NP$-vollständigen Probleme sind eine Klasse von Problemen innerhalb von $NP$, für die keine effizienten (polynomielle) Entscheidungsverfahren bekannt sind. Die $NP$-vollständigen Probleme sind mindestens so schwierig wie alle anderen Probleme in $NP$.

„Halbformal“ bedeutet das:\\
Eine Sprache $L$ ist $NP$-vollständig, wenn gilt:
\begin{enumerate}
\item $L \in NP$
\item Für jede Sprache $A\in NP $ lässt sich das Entscheidungsproblem für $A$ effizient übersetzen in ein Entscheidungsproblem für $L$.
\end{enumerate}
ABB 178\\
Folgerung: Aus $L\in P$ folgt dann auch $A \in P$.\medskip\\
Weitere Folgerung: Wenn es eine $NP$-vollständige Sprache $L$ gibt mit $L\in P$, dann gilt $P=NP$.\medskip\\
Trotz jahrzehnte währender Suche wurde bisher kein $NP$-vollständiges Problem $L\in P$ gefunden. Deswegen wird $P\not = NP$ vermutet (nur vermutet, nicht bewiesen).\\
Vermutete Lage der Komplexitätsklassen (Fall $P \not = NP$):\\
ABB 179

\paragraph{Satz:} Die Sprache $SAT=\{F\;|\; F$ ist eine erfüllbare Formel der Aussagenlogik$\}$ ist $NP$-vollständig.\\
Dies bedeutet, dass kein effizientes (polynomielles) Entscheidungsverfahren bekannt ist. Alle bekannten Entscheidungsverfahren besitzen exponentielle Laufzeit. Das naive Verfahren besitzt eine Laufzeit in $O(p(n)\cdot 2^n)$. Das beste bekannte Verfahren besitzt eine Laufzeit in $O(1,308^n\cdot p(n))$ für $3 SAT$ (Formel in $KNF$ mit 3 Literalen pro Klausel, z.B. $(x\vee y \vee \neg z ) \wedge (\neg x \vee a \vee z) \wedge (\neg y \vee z \vee b) \wedge \dots$).\\
Nicht alle Elemente in $SAT$ sind schwierige Instanzen. Z.B. ist $2 SAT=\{F\;|\; F$ ist eine Formel in $KNF$ mit 2 Literalen pro Klausel$\}$ effizient entscheidbar (d.h. $2 SAT \in P$).\\
ABB 180
\subparagraph{Anwendungen von SAT} 
\begin{itemize}
\item Äquivalenz von Schaltkreisen\\
Da Schaltkreise durch logische Gatter ($\vee$, $\wedge$, $\neg$) dargestellt werden, lassen sich Schaltkreise durch logische Formeln beschreiben.\\
ABB 181\\
Zwei Schaltkreise $S_1$, $S_2$ sind äquivalent genau dann, wenn $S_1\leftrightarrow S_2$ eine Tautologie ist genau dann, wenn $\neg(S_1 \leftrightarrow S_2)$ unerfüllbar genau dann, wenn $\neg (S_1\leftrightarrow S_2) \not \in SAT$.
\item Software-Paketverwaltung\\
Installationsproblem (lässt sich ein Paket installieren? Geht bspw. nicht bei Ringabhängigkeiten): Angenommen, ein Paket $A$ benötigt die Pakete $B,C$ sowie eins der Pakete $D,E$ und ist unverträglich mit $F$, dann kann dies dargestellt werden durch $A \to B \wedge C \wedge (D \vee E) \wedge \neg F$ ($\to$ bedeutet „benötigt“).\\
Jedes der Pakete $B,C,D,E$ besitzt wiederum Abhängigkeiten, die entsprechend durch Formeln dargestellt werden können. Sei $G$ die $\wedge$-Verknüpfung aller dadurch entstehenden Formeln mit $A$ und entsprechenden Atomformeln für die bereits auf dem System installierten Paketen. $A$ ist genau dann installierbar, wenn $G$ erfüllbar ist. Die erfüllende Belegung liefert die zu installierenden Pakete.
\item Software Model Checking
\begin{lstlisting}[language=C]
int a[2];
if(i== 0) j = 1;
else j = 2;
x = a[j];
\end{lstlisting}
Es besteht die Gefahr eines Index-out-of-Bounds Fehlers. Dieser muss abgefangen werden.\\
$\Downarrow$
\begin{lstlisting}[language=C]
int a[2];
if(i==0) j=1;
else j = 2;
assert ( 0<=j && j<2);
x=a[j];
\end{lstlisting}
Aus dem Programmcode wird die Formel $C=(i=0 \to j=1)\wedge ( i \not = 0 \to j = 2)$ erzeugt, aus der Spezifikation die Formel $P=0\leq j \wedge j <2$.
\end{itemize}


Hinweis: Travelling-Salesman-Problem (möglichst kurzer Rundweg durch Graph) (vgl. Hammilton Kreis) hat LZ $O(n^2\cdot 2^n)$.

\section{Wiederholung (Klausur)}
\subsection{CYK}
$\{a^nb^n|n>0\}$\\
$S\to aSb \;|\; ab$\\
Umformen in CNF:
\begin{enumerate}
\item $S\to ASB \;|\; AB$\\
$A\to a$\\
$B\to b$
\item $S\to XB \;|\; AB$\\
$X\to AS$\\
$A \to a$\\
$B \to b$
\end{enumerate}
Prüfen, ob $aabb$ drin liegt:
ABB 189
\subsection{Entscheidbarkeit}
Die Frage ist, ob es für die Menge ein oder mehrere Entscheidungsverfahren gibt. Die Frage ist nicht, welches das richtige ist, sondern nur, dass es umfassend entscheidbar ist (Vergleich: Frage nach Gott -- es gibt Entscheidungsverfahren, ober wir wissen nicht, welches das richtige ist, weil wir nicht wissen, ob Gott existiert).\\
NP-Vollständigkeit!

\subsection{Automaten}
In der Klausur müssen bei bspw. DFA keine Tupel angegeben werden, der vollständig beschriftete Graph reicht.\\
Reguläre Ausdrücke (Definition!)\\
DFA Konstruieren!\\
Kontextfreie Grammatiken (konstruieren)\\
Pumping-Lemma!

\subsection{Recursive Descent Parser}
Grammatik zu Problem ausdenken und in rekursive Prozeduren umsetzen.

\subsection{OL-Systeme}
Voraussichtlich keine Aufgabe dazu.
\newpage
\printbibliography
\end{document}
